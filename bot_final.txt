# main.py

# main.py — точка входа для запуска gui
import sys
import os
# os.environ["QT_QPA_PLATFORM"] = "wayland-egl"  # или "wayland-egl"
os.environ["XDG_SESSION_TYPE"] = "x11"

from PyQt5.QtWidgets import QApplication
from gui.app import create_main_window
from config.settings import Settings

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = create_main_window()
    window.mainloop()
    sys.exit(app.exec_())



# reverse.py

import os

def parse_bot_final(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    file_blocks = {}
    current_file = None
    current_lines = []

    for line in lines:
        if line.startswith("# ") and line.strip().endswith(".py"):
            if current_file:
                file_blocks[current_file] = ''.join(current_lines).strip() + '\n'
            current_file = line.strip()[2:]  # удаляем "# " в начале
            current_lines = []
        else:
            if current_file:
                current_lines.append(line)

    if current_file and current_lines:
        file_blocks[current_file] = ''.join(current_lines).strip() + '\n'

    return file_blocks


def write_files_from_blocks(blocks):
    for file_path, content in blocks.items():
        dir_name = os.path.dirname(file_path)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"✅ Перезаписан файл: {file_path}")


if __name__ == "__main__":
    bot_final_path = "bot_final.txt"
    if not os.path.exists(bot_final_path):
        print("❌ Файл bot_final.txt не найден.")
    else:
        file_blocks = parse_bot_final(bot_final_path)
        write_files_from_blocks(file_blocks)
        print("🎉 Все файлы успешно восстановлены из bot_final.txt")



# run_full.py

import asyncio
import logging
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
import os
from services.worker           import SignalWorker
from services.identifier        import PairIdentifier
from services.collector         import DataCollector
from services.level_engine      import LevelAnalyzer
from services.indicator_engine  import IndicatorEngine
from services.trend_engine      import TrendAnalyzer
from services.signal_engine     import SignalEngine
from services.deep_an           import MarketCapTracker
from database.database          import DatabaseManager



logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ──────────────────────────────────────────────────────────────
def wait_for_candles(target=50, timeout=10):
    """Блокирует поток до появления достаточного числа свечей."""
    db = DatabaseManager()
    for _ in range(timeout):
        if any(len(c) >= target for c in db.get_all_candles().values()):
            logger.info("✅ Свечи успешно загружены")
            return True
        logger.info("⏳ Ожидание загрузки свечей...")
        time.sleep(1)
    logger.warning("❌ Свечи не появились за отведённое время")
    return False

# ──────────────────────────────────────────────────────────────
async def update_market_data():
    # ① сперва заполняем pairs_cache
    await PairIdentifier().update_pairs_cache()

    # ② затем уже параллельно всё остальное
    await asyncio.gather(
        # DerivativesEngine().update_metrics_for_all(),   # требует pairs_cache
        # SentimentEngine().update_for_all(),             #   —//—
        DataCollector().update_all_timeframes(),        #   —//—
        MarketCapTracker().fetch_total_market_cap(),
    )

def analyze():
    LevelAnalyzer().analyze_levels()
    IndicatorEngine().compute_indicators()
    TrendAnalyzer().analyze_trends()

def run_worker():
    return SignalWorker().process_all_pairs()

# ──────────────────────────────────────────────────────────────
async def main():
    logger.info("🚀 Полный запуск: обновление + оценка сигналов")
    DatabaseManager().clear_old_candles()

    # Шаг 1. сетевые обновления
    await update_market_data()

    # Шаг 2. ждём появления свечей
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(None, wait_for_candles)

    # Шаг 3. аналитика (CPU)
    with ThreadPoolExecutor() as pool:
        await loop.run_in_executor(pool, analyze)

        # Шаг 4. генерация «сырых» сигналов (AlertSystem внутри)
        SignalEngine().generate_signals()

        # Шаг 5. «глубокая» оценка всех сигналов
        signals = await loop.run_in_executor(pool, run_worker)

    if signals:
        logger.info(f"✅ Обновлённая таблица сигналов: {len(signals)} записей")
    else:
        logger.info("⚠️ Нет подходящих сигналов после оценки")



# ──────────────────────────────────────────────────────────────
if __name__ == "__main__":
    DatabaseManager.init_schema_once()
    asyncio.run(main())



# run_tasks.py

import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor

from services.identifier      import PairIdentifier
from services.collector       import DataCollector
from services.level_engine    import LevelAnalyzer
from services.indicator_engine import IndicatorEngine
from services.trend_engine    import TrendAnalyzer
from services.alert_engine    import AlertSystem
from services.deep_an         import MarketCapTracker
from database.database        import DatabaseManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ──────────────────────────────────────────────────────────────
async def update_market_data():
    # ① сперва заполняем pairs_cache
    await PairIdentifier().update_pairs_cache()

    # ② затем уже параллельно всё остальное
    await asyncio.gather(
        # DerivativesEngine().update_metrics_for_all(),   # требует pairs_cache
        # SentimentEngine().update_for_all(),             #   —//—
        DataCollector().update_all_timeframes(),        #   —//—
        MarketCapTracker().fetch_total_market_cap(),
    )

def sync_tasks():
    """CPU-bound анализ выполняем в пуле потоков."""
    LevelAnalyzer().analyze_levels()
    IndicatorEngine().compute_indicators()
    TrendAnalyzer().analyze_trends()
    AlertSystem().check_alerts()

# ──────────────────────────────────────────────────────────────
async def main():
    logger.info("🚀 Обновление данных рынка (без сигналов)")
    DatabaseManager().clear_old_candles()

    # ① сетевые задачи
    await update_market_data()

    # ② синхронные / тяжёлые задачи
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor() as pool:
        await loop.run_in_executor(pool, sync_tasks)

    logger.info("✅ Все данные обновлены (без сигналов)")

# ──────────────────────────────────────────────────────────────
if __name__ == "__main__":
    asyncio.run(main())



# run_worker.py

import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from services.worker import SignalWorker

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def main():
    logger.info("📊 Запуск пересчёта сигналов по текущим данным")
    loop = asyncio.get_running_loop()

    def run_signals():
        worker = SignalWorker()
        return worker.process_all_pairs()

    with ThreadPoolExecutor() as pool:
        results = await loop.run_in_executor(pool, run_signals)

    if results:
        logger.info(f"✅ Сигналы обновлены: {len(results)}")
        for signal in results:
            logger.info(f"🟢 {signal['symbol']} {signal['timeframe']} — {signal['signal_type']} @ {signal['current_price']:.4f}")
    else:
        logger.info("⚠️ Ни одного сигнала не прошло фильтрацию")

if __name__ == "__main__":
    asyncio.run(main())



# gui/_init_.py





# gui/app.py

import tkinter as tk
from tkinter import ttk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import subprocess
from gui.chart_drawer import ChartDrawer
from gui.indicators_drawer import IndicatorDrawer
from gui.tables_drawer import TableDrawer
from database.database import DatabaseManager
import logging
logger = logging.getLogger(__name__)


def create_main_window():
    def run_analysis():
        try:
            ttk.Label(control_frame, text="⏳ Анализ...").pack(side=tk.LEFT, padx=5)
            subprocess.run(["python", "run_full.py"], check=True)
            update_chart()
            logger.info("✅ Анализ завершён")
        except Exception as e:
            logger.error(f"❌ Ошибка при запуске анализа: {e}")

    root = tk.Tk()
    root.title("Crypto Market")
    root.geometry("1500x900")

    db = DatabaseManager()
    symbols = db.get_symbols_from_cache()
    timeframes = ["1d", "4h", "1h", "15m"]

    chart_drawer = ChartDrawer()
    tables = TableDrawer(root)

    symbol_var = tk.StringVar()
    tf_var = tk.StringVar()
    show_levels = tk.BooleanVar(value=True)
    show_indicators = tk.BooleanVar(value=True)
    show_signals = tk.BooleanVar(value=True)
    show_trend = tk.BooleanVar(value=True)
    show_stochastic = tk.BooleanVar(value=False)
    show_fibo = tk.BooleanVar(value=False)

    control_frame = ttk.Frame(root)
    control_frame.pack(fill=tk.X, pady=10, padx=10)
    ttk.Checkbutton(control_frame, text="Stochastic", variable=show_stochastic, command=lambda: update_chart()).pack(
        side=tk.LEFT, padx=5)

    ttk.Label(control_frame, text="Пара:").pack(side=tk.LEFT)
    symbol_combo = ttk.Combobox(control_frame, textvariable=symbol_var, values=symbols, width=15)
    symbol_combo.pack(side=tk.LEFT, padx=5)

    ttk.Label(control_frame, text="Таймфрейм:").pack(side=tk.LEFT, padx=(10, 0))
    tf_combo = ttk.Combobox(control_frame, textvariable=tf_var, values=timeframes, width=5)
    tf_combo.pack(side=tk.LEFT, padx=5)

    ttk.Checkbutton(control_frame, text="Уровни", variable=show_levels, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="Индикаторы", variable=show_indicators, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="Сигналы", variable=show_signals, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="Тренд", variable=show_trend, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="Фибоначчи", variable=show_fibo, command=lambda: update_chart()).pack(
        side=tk.LEFT, padx=5)

    ttk.Button(control_frame, text="Обновить график", command=lambda: update_chart()).pack(side=tk.LEFT, padx=10)
    ttk.Button(control_frame, text="Перезапустить анализ", command=run_analysis).pack(side=tk.LEFT, padx=10)
    ttk.Button(control_frame, text="Сигналы", command=lambda: tables.draw_signals_table(on_select=handle_select)).pack(side=tk.LEFT)
    ttk.Button(control_frame, text="Алерты", command=lambda: tables.draw_alerts_table(on_select=handle_select)).pack(side=tk.LEFT)
    ttk.Button(control_frame, text="Очистить базу", command=lambda: db.truncate_all_tables() or update_chart()).pack(side=tk.RIGHT, padx=5)

    fig_frame = ttk.Frame(root)
    fig_frame.pack(fill=tk.BOTH, expand=True)

    fig_canvas = None


    def update_chart():
        nonlocal fig_canvas
        symbol = symbol_var.get()
        tf = tf_var.get()
        if not symbol or not tf:
            return

        fig, ax = chart_drawer.draw_candles(
            symbol,
            tf,
            show_levels=show_levels.get(),
            show_indicators=show_indicators.get(),
            show_signals=show_signals.get(),
            show_trend=show_trend.get(),
            show_stochastic = show_stochastic.get(),
            show_fibo = show_fibo.get()
        )
        if not fig:
            return

        for w in fig_frame.winfo_children():
            w.destroy()

        # Добавляем кнопки управления
        control_btn_frame = tk.Frame(fig_frame)
        control_btn_frame.pack(side=tk.TOP, pady=5)

        tk.Button(control_btn_frame, text="<", width=3, command=chart_drawer.pan_left).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text=">", width=3, command=chart_drawer.pan_right).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text="+", width=3, command=chart_drawer.zoom_in).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text="-", width=3, command=chart_drawer.zoom_out).pack(side=tk.LEFT, padx=2)

        fig_canvas = FigureCanvasTkAgg(fig, master=fig_frame)
        fig_canvas.draw()
        fig_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)



    def handle_select(symbol, timeframe):
        symbol_combo.set(symbol)
        tf_combo.set(timeframe)
        root.after(100, update_chart)

    if symbols:
        symbol_var.set(symbols[0])
    tf_var.set("4h")
    update_chart()

    symbol_combo.bind("<<ComboboxSelected>>", lambda e: update_chart())
    tf_combo.bind("<<ComboboxSelected>>", lambda e: update_chart())

    return root



# gui/chart_drawer.py

# chart_drawer.py — финальная версия с уровнями перекупленности/перепроданности на стохастике

import matplotlib.pyplot as plt
import pandas as pd
import mplfinance as mpf
import logging

from database.database import DatabaseManager
from gui.indicators_drawer import IndicatorDrawer
from gui.levels_drawer import LevelDrawer
from gui.signals_drawer import SignalDrawer
from gui.fibo_drawer import FiboDrawer

logger = logging.getLogger(__name__)


class ChartDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.fig = None
        self.ax = None

    def draw_candles(self, symbol, timeframe,
                     show_levels=True, show_indicators=True,
                     show_signals=True, show_trend=True,
                     show_stochastic=False, show_fibo=False):

        candles = self.db.get_candles(symbol, timeframe)
        if not candles:
            logger.warning(f"❌ Нет свечей для {symbol} {timeframe}")
            return None, None

        df = pd.DataFrame(candles)
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df.set_index("date", inplace=True)
        df = df.sort_index()
        df.rename(columns={
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume"
        }, inplace=True)

        offset_hours = 10
        last_index = df.index[-1]
        future_index = pd.date_range(start=last_index, periods=offset_hours, freq="1h")
        df = df.reindex(df.index.union(future_index))

        apds = []
        drawer = IndicatorDrawer()

        if show_indicators:
            indicators = drawer.get_indicator_series(df)
            colors = drawer.colors
            for name, series in indicators.items():
                apds.append(mpf.make_addplot(series, color=colors.get(name, "gray"),
                                             width=1.2, linestyle="-" if "EMA" in name else "--"))

        if show_levels:
            levels = self.db.get_levels()
            levels = [lvl for lvl in levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]
            for lvl in levels:
                line = pd.Series(lvl["price"], index=df.index)
                apds.append(mpf.make_addplot(line,
                                             color=LevelDrawer().colors.get(lvl["type"], "gray"),
                                             linestyle="--", width=2))

        if show_signals:
            sig_drawer = SignalDrawer()
            df_signals = sig_drawer.get_signal_points(symbol, timeframe, df.index)

            if not df_signals.empty:
                long_series = pd.Series(index=df.index, dtype=float)
                short_series = pd.Series(index=df.index, dtype=float)

                for i, row in df_signals.iterrows():
                    if row["type"] == "long":
                        long_series.at[i] = row["price"]
                    elif row["type"] == "short":
                        short_series.at[i] = row["price"]

                if not long_series.dropna().empty:
                    apds.append(mpf.make_addplot(long_series, type='scatter', marker='^',
                                                 markersize=100, color='green'))
                if not short_series.dropna().empty:
                    apds.append(mpf.make_addplot(short_series, type='scatter', marker='v',
                                                 markersize=100, color='red'))

        if show_stochastic:
            k, d = drawer._stochastic(df)
            apds.append(mpf.make_addplot(k, panel=1, color='blue', ylabel='Stoch'))
            apds.append(mpf.make_addplot(d, panel=1, color='orange'))

            # Добавим уровни перекупленности и перепроданности
            overbought = pd.Series(80, index=df.index)
            oversold = pd.Series(20, index=df.index)
            apds.append(mpf.make_addplot(overbought, panel=1, color='green', linestyle='--'))
            apds.append(mpf.make_addplot(oversold, panel=1, color='red', linestyle='--'))

        if show_fibo:
            fibo_drawer = FiboDrawer()
            fibo_drawer.draw_fibo(apds, df, symbol, timeframe)

        self.fig, axes = mpf.plot(
            df,
            type='candle',
            addplot=apds,
            returnfig=True,
            panel_ratios=(8, 2) if show_stochastic else (1,),
            volume=False,
            figsize=(20, 10),
            xrotation=20,
            tight_layout=True,  # добавим авто-уплотнение
            # style="yahoo"  # более компактная тема оформления
        )

        self.ax = axes[0] if isinstance(axes, list) else axes

        if show_fibo:
            fibo_drawer.draw_fibo_labels(df, symbol, timeframe, ax=self.ax)

        if show_trend:
            self._draw_trend_box(self.ax, symbol)


        return self.fig, self.ax

    def _draw_trend_box(self, ax, symbol):
        trend_data = self.db.get_trend(symbol)
        if not trend_data:
            return

        trend = trend_data.get("direction", "").upper()
        color = "green" if trend == "BULLISH" else "red"
        text = f"Trend: {trend}"

        ax.text(
            0.99, 0.99, text,
            transform=ax.transAxes,
            fontsize=10,
            color="white",
            bbox=dict(facecolor=color, alpha=0.7, boxstyle="round,pad=0.3"),
            horizontalalignment='right',
            verticalalignment='top'
        )

    def pan_left(self):
        if not self.ax: return
        dx = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.1
        self.ax.set_xlim(self.ax.get_xlim()[0] - dx, self.ax.get_xlim()[1] - dx)
        self.fig.canvas.draw_idle()

    def pan_right(self):
        if not self.ax: return
        dx = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.1
        self.ax.set_xlim(self.ax.get_xlim()[0] + dx, self.ax.get_xlim()[1] + dx)
        self.fig.canvas.draw_idle()

    def zoom_in(self):
        if not self.ax: return
        center = sum(self.ax.get_xlim()) / 2
        width = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.8
        self.ax.set_xlim(center - width / 2, center + width / 2)
        self.fig.canvas.draw_idle()

    def zoom_out(self):
        if not self.ax: return
        center = sum(self.ax.get_xlim()) / 2
        width = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 1.2
        self.ax.set_xlim(center - width / 2, center + width / 2)
        self.fig.canvas.draw_idle()



# gui/fibo_drawer.py

import logging
import pandas as pd
import mplfinance as mpf
from services.fibo_engine import FiboEngine

logger = logging.getLogger(__name__)

class FiboDrawer:
    def __init__(self):
        self.fibo_engine = FiboEngine()  # 1 раз создаём

    def draw_fibo(self, apds, df, symbol, timeframe):
        try:
            fibo_data = self.fibo_engine.calculate_for_pair(symbol, timeframe)
            if not fibo_data:
                return

            for level_val in fibo_data["fibo_levels"].values():
                line = pd.Series(level_val, index=df.index)
                apds.append(mpf.make_addplot(
                    line,
                    color="purple",
                    linestyle="--",
                    width=1.5
                ))

        except Exception as e:
            logger.error(f"❌ Ошибка отрисовки Фибоначчи: {e}")

    def draw_fibo_labels(self, df, symbol, timeframe, ax):
        try:
            fibo_data = self.fibo_engine.calculate_for_pair(symbol, timeframe)
            if not fibo_data:
                return

            levels = fibo_data["fibo_levels"]
            x_pos = df.index[-1]

            for level_name, level_val in levels.items():
                ax.text(
                    x_pos,
                    level_val,
                    f"{level_name:.3f}",
                    color="purple",
                    fontsize=8,
                    verticalalignment="bottom",
                    horizontalalignment="right",
                    alpha=0.7
                )
        except Exception as e:
            logger.error(f"❌ Ошибка подписей Фибоначчи: {e}")



# gui/indicators_drawer.py

import pandas as pd
import logging
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class IndicatorDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.colors = {
            "EMA20": "#FFD54F",
            "EMA50": "#64B5F6",
            "EMA200": "#AB47BC",
            "BB_UPPER": "#FF5252",
            "BB_LOWER": "#448AFF"
        }

    def get_indicators_data(self, symbol, timeframe):
        """Возвращает все значения индикаторов для масштабирования"""
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            return None

        df = pd.DataFrame(candles)
        df["close"] = pd.to_numeric(df["close"], errors="coerce")
        df = df.dropna(subset=["close"])

        if df.empty:
            return None

        try:
            # Вычисляем все индикаторы
            ema20 = df["close"].ewm(span=20, adjust=False).mean()
            ema50 = df["close"].ewm(span=50, adjust=False).mean()
            ema200 = df["close"].ewm(span=200, adjust=False).mean()

            bb_mid = df["close"].rolling(window=20).mean()
            bb_std = df["close"].rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            # Собираем все значения в один список
            all_values = []
            all_values.extend(ema20.dropna().tolist())
            all_values.extend(ema50.dropna().tolist())
            all_values.extend(ema200.dropna().tolist())
            all_values.extend(bb_upper.dropna().tolist())
            all_values.extend(bb_lower.dropna().tolist())

            return all_values
        except Exception as e:
            logger.error(f"Ошибка расчета индикаторов для масштабирования: {e}")
            return None

    def get_indicator_series(self, df):
        """Возвращает словарь Series для make_addplot"""
        try:
            close = pd.to_numeric(df["Close"], errors="coerce")
            ema20 = close.ewm(span=20, adjust=False).mean()
            ema50 = close.ewm(span=50, adjust=False).mean()
            ema200 = close.ewm(span=200, adjust=False).mean()

            bb_mid = close.rolling(window=20).mean()
            bb_std = close.rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            return {
                "EMA20": ema20,
                "EMA50": ema50,
                "EMA200": ema200,
                "BB_UPPER": bb_upper,
                "BB_LOWER": bb_lower
            }
        except Exception as e:
            logger.error(f"Ошибка get_indicator_series: {e}")
            return {}

    def draw_indicators(self, ax, symbol, timeframe):
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            logger.warning(f"📉 Недостаточно данных для индикаторов {symbol} {timeframe}")
            return

        df = pd.DataFrame(candles)
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df.set_index("date", inplace=True)
        df.sort_index(inplace=True)

        df = df[df["close"].notnull()]
        if df.empty:
            logger.warning(f"⚠️ Нет пригодных данных (close) для индикаторов {symbol}")
            return

        try:
            close = pd.to_numeric(df["close"], errors="coerce")
            ema20 = close.ewm(span=20, adjust=False).mean()
            ema50 = close.ewm(span=50, adjust=False).mean()
            ema200 = close.ewm(span=200, adjust=False).mean()

            bb_mid = close.rolling(window=20).mean()
            bb_std = close.rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            df_ind = pd.DataFrame({
                "ema20": ema20,
                "ema50": ema50,
                "ema200": ema200,
                "bb_upper": bb_upper,
                "bb_lower": bb_lower
            }, index=df.index).dropna()

            if df_ind.empty:
                logger.warning(f"⚠️ Все индикаторы пусты после dropna для {symbol}")
                return

            # Отладка
            logger.debug(f"📊 Индикаторы для {symbol}: точек={len(df_ind)}")
            logger.debug(f"EMA20 min={df_ind['ema20'].min()}, max={df_ind['ema20'].max()}")

            ax.plot(df_ind.index, df_ind["ema20"], label="EMA20", color=self.colors["EMA20"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["ema50"], label="EMA50", color=self.colors["EMA50"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["ema200"], label="EMA200", color=self.colors["EMA200"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["bb_upper"], linestyle="--", color=self.colors["BB_UPPER"], label="BB Upper", alpha=0.3)
            ax.plot(df_ind.index, df_ind["bb_lower"], linestyle="--", color=self.colors["BB_LOWER"], label="BB Lower", alpha=0.3)

        except Exception as e:
            logger.error(f"❌ Ошибка в отрисовке индикаторов для {symbol}: {e}")

    def draw_stochastic(self, fig, df):
        from matplotlib.gridspec import GridSpec

        k, d = self._stochastic(df)
        if k.isnull().all() or d.isnull().all():
            return

        gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.05)
        ax_main = fig.axes[0]
        ax_stoch = fig.add_subplot(gs[1], sharex=ax_main)

        ax_stoch.plot(df.index, k, label="%K", color="blue", linewidth=1)
        ax_stoch.plot(df.index, d, label="%D", color="orange", linewidth=1)
        ax_stoch.axhline(80, color="green", linestyle="--", alpha=0.4)
        ax_stoch.axhline(20, color="red", linestyle="--", alpha=0.4)
        ax_stoch.set_ylim(0, 100)
        ax_stoch.set_yticks([0, 20, 50, 80, 100])
        ax_stoch.set_ylabel("Stoch")
        ax_stoch.legend(loc="upper left", fontsize=8)

    def _stochastic(self, df, k_period=14, d_period=3):
        low_min = df["Low"].rolling(window=k_period).min()
        high_max = df["High"].rolling(window=k_period).max()
        k = 100 * (df["Close"] - low_min) / (high_max - low_min)
        d = k.rolling(window=d_period).mean()
        return k, d



# gui/levels_drawer.py

import logging
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class LevelDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.colors = {
            "support": "#00C853",
            "resistance": "#FF6D00",
            "ema50": "#1E88E5",
            "ema200": "#9C27B0",
        }

    def draw_levels(self, ax, symbol, timeframe):
        levels = self.db.get_levels()
        levels = [lvl for lvl in levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]

        for level in levels:
            y = float(level["price"])
            t = level["type"]
            color = self.colors.get(t, "gray")
            strength = level.get("strength", 1)
            touched = level.get("touched", 0)
            broken = level.get("broken", False)

            linestyle = ":" if broken else "--" if touched < 2 else "-"
            linewidth = max(1, min(4, strength))

            ax.axhline(y=y, color=color, linestyle=linestyle, linewidth=linewidth, alpha=0.8, clip_on=True)

            try:
                ax.text(
                    ax.get_xlim()[0], y,
                    f"{y:.4f}",
                    fontsize=8,
                    color=color,
                    verticalalignment="bottom",
                    horizontalalignment="right"
                )
            except:
                continue



# gui/main_layout.py

import tkinter as tk
from tkinter import ttk


class MainLayout:
    def __init__(self, root, symbols, timeframes):
        self.root = root
        self.symbols = symbols
        self.timeframes = timeframes

        # State variables
        self.symbol_var = tk.StringVar()
        self.tf_var = tk.StringVar()
        self.show_levels = tk.BooleanVar(value=True)
        self.show_indicators = tk.BooleanVar(value=True)
        self.show_signals = tk.BooleanVar(value=True)

        # Placeholders for callbacks
        self.on_update = None
        self.on_signals = None
        self.on_alerts = None
        self.on_clear_db = None

        self.control_frame = ttk.Frame(root)
        self.control_frame.pack(fill=tk.X, pady=10, padx=10)

        self._create_controls()

        self.chart_frame = ttk.Frame(root)
        self.chart_frame.pack(fill=tk.BOTH, expand=True)

    def _create_controls(self):
        ttk.Label(self.control_frame, text="Пара:").pack(side=tk.LEFT)
        self.symbol_combo = ttk.Combobox(self.control_frame, textvariable=self.symbol_var, values=self.symbols, width=15)
        self.symbol_combo.pack(side=tk.LEFT, padx=5)

        ttk.Label(self.control_frame, text="Таймфрейм:").pack(side=tk.LEFT, padx=(10, 0))
        self.tf_combo = ttk.Combobox(self.control_frame, textvariable=self.tf_var, values=self.timeframes, width=5)
        self.tf_combo.pack(side=tk.LEFT, padx=5)

        # Переключатели
        ttk.Checkbutton(self.control_frame, text="Уровни", variable=self.show_levels).pack(side=tk.LEFT, padx=5)
        ttk.Checkbutton(self.control_frame, text="Индикаторы", variable=self.show_indicators).pack(side=tk.LEFT, padx=5)
        ttk.Checkbutton(self.control_frame, text="Сигналы", variable=self.show_signals).pack(side=tk.LEFT, padx=5)

        # Кнопки
        ttk.Button(self.control_frame, text="Обновить график", command=self._call_update).pack(side=tk.LEFT, padx=10)
        ttk.Button(self.control_frame, text="Сигналы", command=self._call_signals).pack(side=tk.LEFT)
        ttk.Button(self.control_frame, text="Алерты", command=self._call_alerts).pack(side=tk.LEFT)
        ttk.Button(self.control_frame, text="Очистить базу", command=self._call_clear_db).pack(side=tk.RIGHT, padx=5)

    # --- Callback proxies ---
    def _call_update(self):
        if self.on_update:
            self.on_update()

    def _call_signals(self):
        if self.on_signals:
            self.on_signals()

    def _call_alerts(self):
        if self.on_alerts:
            self.on_alerts()

    def _call_clear_db(self):
        if self.on_clear_db:
            self.on_clear_db()



# gui/signals_drawer.py

import logging
import pandas as pd
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class SignalDrawer:
    def __init__(self):
        self.db = DatabaseManager()

    def get_signal_points(self, symbol, timeframe, index_range):
        try:
            conn = self.db.get_connection()
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT signal_type, price, time
                    FROM signals
                    WHERE symbol = %s AND timeframe = %s
                    ORDER BY time DESC
                    LIMIT 50
                """, (symbol, timeframe))
                signals = cur.fetchall()
        except Exception as e:
            logger.error(f"❌ Ошибка загрузки сигналов: {e}")
            return pd.DataFrame()
        finally:
            self.db.release_connection(conn)

        if not signals:
            return pd.DataFrame()

        df = pd.DataFrame(signals, columns=["type", "price", "time"])
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df = df.set_index("date").sort_index()

        df = df[df.index.isin(index_range)]

        return df



# gui/tables_drawer.py

import tkinter as tk
from tkinter import ttk, messagebox
import logging
from datetime import datetime
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class TableDrawer:
    def __init__(self, master):
        self.signals_map = {}
        self.master = master
        self.db = DatabaseManager()

    def draw_signals_table(self, on_select=None):
        win = tk.Toplevel(self.master)
        win.title("Сигналы")
        win.geometry("1200x600")

        # ① список колонок (добавлены новые метрики)
        self.columns = [
            "symbol", "timeframe", "signal_type", "current_price",
            "recommendation", "score", "created_at",
            "rsi", "macd", "stoch_k", "stoch_d",
            "atr", "adx", "oi", "fund_rate",
            "supertrend", "vwap", "poc", "sentiment",
            "details"                                     # оставляем в самом конце
        ]

        # ② обёртка + scrollbar
        frame = tk.Frame(win); frame.pack(fill=tk.BOTH, expand=True)
        xscroll = tk.Scrollbar(frame, orient=tk.HORIZONTAL)
        xscroll.pack(side=tk.BOTTOM, fill=tk.X)

        # ③ создаём Treeview ДО настройки колонок
        self.tree = ttk.Treeview(frame,
                                 columns=self.columns,
                                 show="headings",
                                 xscrollcommand=xscroll.set)
        self.tree.pack(fill=tk.BOTH, expand=True)
        xscroll.config(command=self.tree.xview)

        # ④ заголовки / ширины
        for col in self.columns:
            self.tree.heading(col, text=col.upper(),
                              command=lambda c=col: self.sort_by_column(c, False))
            self.tree.column(col, anchor="w", width=140, stretch=True)

        ttk.Button(win, text="Обновить",
                   command=self._refresh_signals).pack(pady=5)

        # ⑤ callbacks
        if on_select:
            self.tree.bind("<<TreeviewSelect>>",
                           lambda e: self._handle_select(on_select))
        self.tree.bind("<Double-1>", self._on_double_click)

        self._refresh_signals()   # первая отрисовка

    # ------------ обновление таблицы -----------------------------
    def _refresh_signals(self):
        for row in self.tree.get_children():
            self.tree.delete(row)

        try:
            for rec in self.db.get_signals():
                key = (rec["symbol"], rec["timeframe"], rec["signal_type"])
                self.signals_map[key] = rec["details"]

                # порядок значений строго = self.columns
                self.tree.insert("", "end", values=[
                    rec.get("symbol"),
                    rec.get("timeframe"),
                    rec.get("signal_type"),
                    float(rec.get("current_price", 0)),
                    rec.get("recommendation"),
                    float(rec.get("score", 0)),
                    datetime.fromtimestamp(rec["created_at"]).strftime("%Y-%m-%d %H:%M"),
                    round(rec.get("rsi", 0), 1)   if rec.get("rsi") else "",
                    round(rec.get("macd", 0), 4)  if rec.get("macd") else "",
                    round(rec.get("stoch_k", 0), 1) if rec.get("stoch_k") else "",
                    round(rec.get("stoch_d", 0), 1) if rec.get("stoch_d") else "",
                    round(rec.get("atr", 0), 6)  if rec.get("atr") else "",
                    round(rec.get("adx", 0), 1)  if rec.get("adx") else "",
                    round(rec.get("oi", 0))      if rec.get("oi") else "",
                    round(rec.get("fund_rate", 0), 6) if rec.get("fund_rate") else "",
                    rec.get("supertrend"),
                    round(rec.get("vwap", 0), 6) if rec.get("vwap") else "",
                    round(rec.get("poc", 0), 6)  if rec.get("poc") else "",
                    round(rec.get("sentiment", 0), 1) if rec.get("sentiment") else "",
                    "…"           # details в отдельном окне; здесь placeholder
                ])
        except Exception as e:
            logger.error(f"Ошибка при загрузке сигналов: {e}")

    # ------------ сортировка -------------------------------------
    def sort_by_column(self, col, reverse):
        data = [(self.tree.set(k, col), k) for k in self.tree.get_children("")]
        try:
            data.sort(key=lambda t: float(t[0]), reverse=reverse)
        except ValueError:
            data.sort(key=lambda t: str(t[0]), reverse=reverse)

        for idx, (_, k) in enumerate(data):
            self.tree.move(k, "", idx)

        self.tree.heading(col,
                          command=lambda: self.sort_by_column(col, not reverse))

    # ------------ вспомогательные callbacks ----------------------
    def _handle_select(self, on_select):
        sel = self.tree.selection()
        if sel:
            vals = self.tree.item(sel[0])["values"]
            on_select(vals[0], vals[1])       # symbol, timeframe

    def _on_double_click(self, _event):
        sel = self.tree.selection()
        if not sel:
            return
        vals = self.tree.item(sel[0], "values")
        key  = (vals[0], vals[1], vals[2])    # symbol, timeframe, type
        details = self.signals_map.get(key, [])
        if isinstance(details, str):
            import ast
            try: details = ast.literal_eval(details)
            except: pass

        top = tk.Toplevel(self.tree)
        top.title(f"Детали сигнала: {vals[0]} ({vals[1]})")
        txt = tk.Text(top, wrap=tk.WORD)
        txt.insert(tk.END,
                   "\n".join(details) if isinstance(details, list) else str(details))
        txt.config(state=tk.NORMAL)
        txt.pack(expand=True, fill=tk.BOTH)
        tk.Button(top, text="Закрыть", command=top.destroy).pack(pady=5)



# ai/_init_.py





# strategies/_init_.py





# strategies/risk_profiles.py





# config/_init_.py





# config/constants.py

import os

# config/constants.py (добавь)
BINANCE_TICKER_URL = "https://api.binance.com/api/v3/ticker/24hr"

DB_CONFIG = {
    "dbname": os.getenv("DB_NAME", "postgres"),
    "user": os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", "123"),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432"),
}

CANDLE_SETTINGS = {
    "1d": {"interval": "1d", "limit": 900, "update_freq": 86400},
    "4h": {"interval": "4h", "limit": 800, "update_freq": 14400},
    "1h": {"interval": "1h", "limit": 700, "update_freq": 3600},
    "15m": {"interval": "15m", "limit": 500, "update_freq": 900},
}



# config/settings.py

class Settings:
    def __init__(self):
        self.exchange = "Binance"
        self.api_key = ""
        self.api_secret = ""
        self.leverage = 1
        self.stop_loss = 0.0
        self.take_profit = 0.0



# database/_init_.py





# database/database.py

import os
import logging
import psycopg2
from psycopg2 import pool
from datetime import datetime, timedelta
from psycopg2.extras import execute_values
import json
import numpy as np
from datetime import datetime
import time
import re
MAX_CONN = 50

from config.constants import DB_CONFIG  # теперь так

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



class DatabaseManager:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, "_initialized"):
            return
        self._initialized = True

        self.db_config = {
            'dbname': os.getenv('DB_NAME', 'postgres'),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', '123'),
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', '5432')
        }

        self.connection_pool = psycopg2.pool.ThreadedConnectionPool(
            minconn=10,
            maxconn=30,
            **self.db_config
        )

        logger.debug("✅ Успешное подключение к БД")

    @classmethod
    def init_schema_once(cls):
        instance = cls()
        instance._create_tables()
        instance._create_indexes()
        logger.info("✅ База инициализирована один раз")
        return instance
        # Теперь можно безопасно создавать таблицы
        self._create_tables()
        self._create_indexes()
        logger.info("Таблицы созданы/проверены")

    def get_connection(self):
        return self.connection_pool.getconn()

    def release_connection(self, conn):
        self.connection_pool.putconn(conn)

    def _create_tables(self):
        """Создание и изменение структуры таблиц, очистка содержимого в конце"""
        # --- Шаг 1: Создание и изменение структуры таблиц ---
        start_time = time.time()
        ddl_queries = [
            # Таблица collected_candles
            """
            CREATE TABLE IF NOT EXISTS collected_candles (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                candles JSONB NOT NULL,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE (symbol, timeframe)
            );
            """,

            # Таблица levels
            """
            CREATE TABLE IF NOT EXISTS levels (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                price DECIMAL(20,8) NOT NULL,
                type VARCHAR(10) NOT NULL,
                strength INT NOT NULL,
                upper DECIMAL(20,8),
                lower DECIMAL(20,8),
                distance DECIMAL(10,4),
                touched INT DEFAULT 0,
                broken BOOLEAN DEFAULT FALSE,
                last_touched TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # Таблица alerts
            """
            CREATE TABLE IF NOT EXISTS alerts (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20),
                level_price DECIMAL(20,8),
                current_price DECIMAL(20,8),
                type VARCHAR(20),
                distance DECIMAL(10,4),
                strength INT,
                timeframe VARCHAR(10),
                source VARCHAR(20),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE alerts
            ADD COLUMN IF NOT EXISTS source VARCHAR(20);
            """,

            # Таблица pairs_cache
            """
            CREATE TABLE IF NOT EXISTS pairs_cache (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                volume DECIMAL(20,8) NOT NULL,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                missing_periods INT DEFAULT 0
            );
            """,

            # Таблица trend_cache
            """
            CREATE TABLE IF NOT EXISTS trend_cache (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL UNIQUE,
                direction VARCHAR(10) NOT NULL,
                ema50 DECIMAL(20,8),
                ema200 DECIMAL(20,8),
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # Таблица indicators
            """
            CREATE TABLE IF NOT EXISTS indicators (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                indicator_type VARCHAR(20) NOT NULL,
                value DECIMAL(20,8),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE IF EXISTS indicators
            ALTER COLUMN value TYPE VARCHAR(50)
            USING value::VARCHAR(50);
            """,
            # В метод _create_tables, в список ddl_queries добавьте:
            """
            CREATE TABLE IF NOT EXISTS market_cap (
                id SERIAL PRIMARY KEY,
                total_cap DECIMAL(20,2) NOT NULL,
                fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # Таблица signals
            """
            CREATE TABLE IF NOT EXISTS signals (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                signal_type VARCHAR(10) NOT NULL,
                price DECIMAL(20,8) NOT NULL,
                time BIGINT NOT NULL,
                indicator VARCHAR(50),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE signals
            ADD COLUMN IF NOT EXISTS score INT,
            ADD COLUMN IF NOT EXISTS details TEXT,
            ADD COLUMN IF NOT EXISTS recommendation VARCHAR(50),
            ADD COLUMN IF NOT EXISTS current_price DECIMAL(20,8),
            ADD COLUMN IF NOT EXISTS rsi DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS macd DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS ema50 DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS ema200 DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS bb_position DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS stoch_k DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS stoch_d DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS atr DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS adx DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS vwap DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS poc DOUBLE PRECISION;

            """,
        ]

        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for i, query in enumerate(ddl_queries):
                    table_name = self._extract_table_name(query)
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    logger.info(f"[{timestamp}] ⏳ Создание таблицы: {table_name}")
                    cur.execute(query)
            conn.commit()
            duration = round(time.time() - start_time, 2)
            logger.info(
                f"[{datetime.now().strftime('%H:%M:%S')}] ✅ Всего создано {len(ddl_queries)} таблиц за {duration} сек.")
        except Exception as e:
            logger.error(f"❌ Ошибка при создании таблиц: {e}", exc_info=True)
            conn.rollback()
        finally:
            self.release_connection(conn)

    def _extract_table_name(self, query: str) -> str:
        import re
        match = re.search(r"(CREATE|ALTER)\s+TABLE(?: IF NOT EXISTS)?\s+(\w+)", query, re.IGNORECASE)
        return match.group(2) if match else "неизвестно"

    def _create_indexes(self):
        """Создание индексов для оптимизации запросов"""
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_candles_symbol_timeframe ON collected_candles (symbol, timeframe);",
            "CREATE INDEX IF NOT EXISTS idx_candles_last_updated ON collected_candles (last_updated);",
            "CREATE INDEX IF NOT EXISTS idx_levels_symbol_timeframe ON levels (symbol, timeframe);",
            "CREATE UNIQUE INDEX IF NOT EXISTS idx_signals_unique ON signals (symbol, timeframe, signal_type, time);"
            "CREATE INDEX IF NOT EXISTS idx_levels_price ON levels (price);"
            "CREATE INDEX IF NOT EXISTS idx_indicators_sym_tf ON indicators(symbol, timeframe);"
        ]
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for idx in indexes:
                    cur.execute(idx)
            conn.commit()
        except Exception as e:
            logger.error(f"Ошибка создания индексов: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def upsert_candles(self, symbol, timeframe, new_candles):
        logger.debug(f"🔄 Обновление свечей {symbol} {timeframe}")
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                # Получаем текущие свечи
                cur.execute("""
                            SELECT candles
                            FROM collected_candles
                            WHERE symbol = %s
                              AND timeframe = %s
                            """, (symbol, timeframe))
                result = cur.fetchone()
                # Убираем json.loads, так как данные уже десериализованы
                current_candles = result[0] if result else []
                # Фильтрация новых свечей
                existing_times = {candle['time'] for candle in current_candles}
                filtered_new = [
                    candle for candle in new_candles
                    if candle['time'] not in existing_times
                ]
                if not filtered_new:
                    logger.debug("Нет новых свечей для добавления")
                    return len(current_candles)
                # Объединение и сортировка
                merged = current_candles + filtered_new
                merged.sort(key=lambda x: x['time'])
                # Ограничение количества
                max_candles = {
                    '1d': 900,
                    '4h': 800,
                    '1h': 700,
                    '15m': 500
                }.get(timeframe, 500)
                if len(merged) > max_candles:
                    merged = merged[-max_candles:]
                # Обновление или вставка
                if result:
                    cur.execute("""
                                UPDATE collected_candles
                                SET candles      = %s,
                                    last_updated = CURRENT_TIMESTAMP
                                WHERE symbol = %s
                                  AND timeframe = %s
                                """, (json.dumps(merged), symbol, timeframe))
                else:
                    cur.execute("""
                                INSERT INTO collected_candles (symbol, timeframe, candles)
                                VALUES (%s, %s, %s)
                                """, (symbol, timeframe, json.dumps(merged)))
                conn.commit()
                return len(merged)
        except Exception as e:
            logger.error(f"❌ Ошибка обновления свечей {symbol} {timeframe}: {e}", exc_info=True)
            conn.rollback()
            return 0
        finally:
            self.release_connection(conn)

    def get_candles(self, symbol, timeframe):
        """Получение свечей для конкретной пары и таймфрейма"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                            SELECT candles
                            FROM collected_candles
                            WHERE symbol = %s
                              AND timeframe = %s
                            """, (symbol, timeframe))
                result = cur.fetchone()
                # Возвращаем список напрямую
                return result[0] if result else []
        except Exception as e:
            logger.error(f"Ошибка получения свечей {symbol} {timeframe}: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_all_candles(self, timeframe=None):
        """Получение всех свечей (по всем парам и таймфреймам)"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                if timeframe:
                    cur.execute("""
                                SELECT symbol, timeframe, candles
                                FROM collected_candles
                                WHERE timeframe = %s
                                """, (timeframe,))
                else:
                    cur.execute("SELECT symbol, timeframe, candles FROM collected_candles")
                result = cur.fetchall()
                # Убираем json.loads, так как данные уже десериализованы
                return {(row[0], row[1]): row[2] for row in result}
        except Exception as e:
            logger.error(f"Ошибка получения всех свечей: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def clear_old_candles(self):
        """Очистка устаревших свечей с защитой от NULL"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # Очищаем 1d старше 3 месяцев
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '3 months') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe = '1d'
                """)

                # Очищаем 4h и 1h старше 1 месяца
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '1 month') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe IN ('4h', '1h')
                """)

                # Очищаем 15m старше 2 недель
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '2 weeks') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe = '15m'
                """)

            conn.commit()
        except Exception as e:
            logger.error(f"Ошибка очистки старых свечей: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def save_levels(self, levels):
        """Сохранение уровней в БД"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # Очищаем старые уровни
                cur.execute("DELETE FROM levels")
                # Вставляем новые
                insert_query = """
                               INSERT INTO levels
                               (symbol, timeframe, price, type, strength,
                                upper, lower, distance, touched, broken, last_touched)
                               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) \
                               """
                for level in levels:
                    # Преобразуем numpy.float64 в float
                    price = float(level['price'])
                    distance = float(level.get('distance', 0.0))  # Добавить
                    cur.execute(insert_query, (
                        level['symbol'],
                        level['timeframe'],
                        price,
                        level['type'],
                        int(level['strength']),
                        float(level.get('upper')) if level.get('upper') else None,
                        float(level.get('lower')) if level.get('lower') else None,
                        distance,  # Исправлено
                        int(level.get('touched', 0)),
                        bool(level.get('broken', False)),
                        datetime.fromtimestamp(level['last_touched']) if level.get('last_touched') else None
                    ))
                conn.commit()
        except Exception as e:
            logger.error(f"Ошибка сохранения уровней: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_levels(self):
        """Получение уровней из БД"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT * FROM levels")
                columns = [desc[0] for desc in cur.description]
                return [dict(zip(columns, row)) for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"Ошибка получения уровней: {e}")
            return []
        finally:
            self.release_connection(conn)

    def _get_unique_symbols(self):
        """Получение уникальных торговых пар из БД"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                cur.execute("SELECT DISTINCT symbol FROM collected_candles")
                symbols = [row[0] for row in cur.fetchall()]
                return symbols
        except Exception as e:
            logger.error(f"❌ Ошибка получения уникальных пар: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_symbols_from_cache(self):
        """Получение уникальных торговых пар из кэша"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                cur.execute("SELECT symbol FROM pairs_cache")
                return [row[0] for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"Ошибка получения пар из кэша: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_all_trends(self):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT symbol, direction, ema50, ema200 FROM trend_cache")
                rows = cur.fetchall()
                return [
                    {"symbol": row[0], "direction": row[1], "ema50": float(row[2]), "ema200": float(row[3])}
                    for row in rows
                ]
        except Exception as e:
            logger.error(f"Ошибка получения всех трендов: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_trend(self, symbol: str):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT direction, ema50, ema200
                    FROM trend_cache
                    WHERE symbol = %s
                    ORDER BY last_updated DESC
                    LIMIT 1
                """, (symbol,))
                row = cur.fetchone()
                if row:
                    return {
                        "direction": row[0],
                        "ema50": float(row[1]),
                        "ema200": float(row[2])
                    }
                return {}
        except Exception as e:
            logger.error(f"Ошибка получения тренда для {symbol}: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def save_trends(self, trends):
        """Сохранение трендов в БД"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # Используем UPSERT для обновления или вставки
                insert_query = """
                               INSERT INTO trend_cache (symbol, direction, ema50, ema200, last_updated)
                               VALUES (%s, %s, %s, %s, TO_TIMESTAMP(%s)) ON CONFLICT (symbol)
                    DO \
                               UPDATE SET
                                   direction = EXCLUDED.direction, \
                                   ema50 = EXCLUDED.ema50, \
                                   ema200 = EXCLUDED.ema200, \
                                   last_updated = EXCLUDED.last_updated \
                               """
                for symbol, data in trends.items():
                    cur.execute(insert_query, (
                        symbol,
                        data['direction'],
                        float(data['ema50']),
                        float(data['ema200']),
                        data['last_updated']
                    ))
                conn.commit()
        except Exception as e:
            logger.error(f"Ошибка сохранения трендов: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_current_price(self, symbol, timeframe):
        """Получение текущей цены закрытия"""
        candles = self.get_candles(symbol, timeframe)
        if candles:
            return candles[-1]['close']
        return None

    def save_alerts(self, alerts):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for alert in alerts:
                    cur.execute("""
                                INSERT INTO alerts (symbol, level_price, current_price, type, distance, strength,
                                                    timeframe, source)
                                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                                """, (
                                    alert["symbol"],
                                    alert["level_price"],
                                    alert["current_price"],
                                    alert["type"],
                                    alert["distance"],
                                    alert["strength"],
                                    alert["timeframe"],
                                    alert.get("source", "level")
                                ))
            conn.commit()
        except Exception as e:
            logger.error(f"Ошибка сохранения алертов: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_alerts(self):
        """Получение последних алертов"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT symbol, level_price AS price, type AS signal_type, timeframe
                    FROM alerts
                    ORDER BY created_at DESC
                    LIMIT 200
                """)
                columns = [desc[0] for desc in cur.description]
                return [dict(zip(columns, row)) for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"Ошибка получения алертов: {e}")
            return []
        finally:
            self.release_connection(conn)

    def save_signals(self, signals):
        if not signals:
            logger.info("📭 Нет сигналов для сохранения")
            return

        query = """
        INSERT INTO signals (
            symbol, timeframe, signal_type, price,
            recommendation, score, details, current_price, time,
            rsi, macd, ema50, ema200, bb_position, stoch_k, stoch_d,
            atr, adx, vwap, poc
        )
        VALUES %s
        ON CONFLICT (symbol, timeframe, signal_type, time) DO UPDATE
        SET current_price = EXCLUDED.current_price,
            recommendation = EXCLUDED.recommendation,
            score = EXCLUDED.score,
            details = EXCLUDED.details,
            rsi = EXCLUDED.rsi,
            macd = EXCLUDED.macd,
            ema50 = EXCLUDED.ema50,
            ema200 = EXCLUDED.ema200,
            bb_position = EXCLUDED.bb_position,
            stoch_k = EXCLUDED.stoch_k,
            stoch_d = EXCLUDED.stoch_d,
            atr = EXCLUDED.atr,
            adx = EXCLUDED.adx,
            vwap = EXCLUDED.vwap,
            poc = EXCLUDED.poc
        """

        for s in signals:
            for key in ["current_price", "rsi", "macd", "ema50", "ema200", "bb_position", "stoch_k", "stoch_d"]:
                if isinstance(s.get(key), np.generic):
                    s[key] = float(s[key])

        values = [
            (
                s["symbol"],
                s["timeframe"],
                s["signal_type"],
                float(s.get("price", s.get("current_price", 0.0))),
                s.get("recommendation", ""),
                int(s.get("score", 0)),
                s.get("details", ""),
                float(s.get("current_price", 0.0)),
                int(time.time() * 1000),
                s.get("rsi"),
                s.get("macd"),
                s.get("ema50"),
                s.get("ema200"),
                s.get("bb_position"),
                s.get("stoch_k"),
                s.get("stoch_d"),
                s.get("atr"),
                s.get("adx"),
                s.get("vwap"),
                s.get("poc"),
            )
            for s in signals
        ]

        conn = self.connection_pool.getconn()
        try:
            with conn.cursor() as cur:
                execute_values(cur, query, values)
            conn.commit()
            logger.info(f"💾 Сохранено {len(signals)} сигналов в базу данных")
        finally:
            self.connection_pool.putconn(conn)


    def get_signals(self, limit=100):
        query = """
        SELECT symbol, timeframe, signal_type, current_price, recommendation, score,
               details, time, rsi, macd, ema50, ema200, bb_position, stoch_k, stoch_d
        FROM signals
        ORDER BY time DESC
        LIMIT %s
        """
        conn = self.connection_pool.getconn()
        try:
            with conn.cursor() as cur:
                cur.execute(query, (limit,))
                rows = cur.fetchall()
        finally:
            self.connection_pool.putconn(conn)

        result = []
        for row in rows:
            result.append({
                "symbol": row[0],
                "timeframe": row[1],
                "signal_type": row[2],
                "current_price": row[3],
                "recommendation": row[4],
                "score": row[5],
                "details": row[6],
                "created_at": int(row[7]) // 1000,
                "rsi": row[8],
                "macd": row[9],
                "ema50": row[10],
                "ema200": row[11],
                "bb_position": row[12],
                "stoch_k": row[13],
                "stoch_d": row[14],
            })
        return result

    def get_indicators(self, symbol, timeframe):
        """Получение всех индикаторов по паре и таймфрейму"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT indicator_type, value
                    FROM indicators
                    WHERE symbol = %s AND timeframe = %s
                    ORDER BY created_at DESC
                """, (symbol, timeframe))
                rows = cur.fetchall()
                return {row[0]: row[1] for row in rows}
        except Exception as e:
            logger.error(f"Ошибка получения индикаторов: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def get_market_cap(self, days=30):
        """Получение капитализации за последние N дней"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT total_cap, fetched_at
                    FROM market_cap
                    WHERE fetched_at >= NOW() - INTERVAL '%s days'
                    ORDER BY fetched_at ASC
                """, (days,))
                return cur.fetchall()
        except Exception as e:
            logger.error(f"Ошибка получения капитализации: {e}")
            return []
        finally:
            self.release_connection(conn)

    def truncate_all_tables(self):
        """Очистка содержимого всех таблиц"""
        logger.info("⏳ Начало очистки таблиц...")
        tables = [
            "collected_candles", "levels", "alerts",
            "pairs_cache", "trend_cache", "indicators", "signals"
        ]
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for table in tables:
                    cur.execute(f"TRUNCATE TABLE {table};")
                    logger.debug(f"✅ Таблица {table} очищена")
            conn.commit()
            logger.info("✅ Все таблицы успешно очищены")
        except Exception as e:
            logger.error(f"❌ Ошибка очистки таблиц: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)



# database/schema.py





# trading/_init_.py





# trading/executor.py





# trading/order.py





# services/_init_.py





# services/alert_engine.py

import logging
from datetime import datetime

from database.database import DatabaseManager

EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}
logger = logging.getLogger(__name__)


class AlertSystem:
    def __init__(self):
        self.db = DatabaseManager()

    def check_alerts(self, distance_threshold=1.0):
        """
        Возвращает список алертов по близости к уровням.
        """
        levels = self.db.get_levels()
        alerts = []

        for lvl in levels:
            symbol = lvl["symbol"]
            timeframe = lvl["timeframe"]
            price_level = float(lvl["price"])

            # Исключаем стейблкоины
            if any(stable in symbol for stable in EXCLUDED_STABLES):
                continue

            current_price = self.db.get_current_price(symbol, timeframe)
            if current_price is None:
                continue

            distance_pct = abs(current_price - price_level) / price_level * 100
            if distance_pct > distance_threshold:
                continue

            alert = {
                "symbol": symbol,
                "timeframe": timeframe,
                "level_price": price_level,
                "current_price": current_price,
                "type": lvl["type"],
                "strength": lvl["strength"],
                "distance": distance_pct,
                "source": "level",
                "created_at": datetime.now()
            }

            alerts.append(alert)

        logger.info(f"🔔 Обнаружено алертов: {len(alerts)}")
        self.db.save_alerts(alerts)
        return alerts



# services/cache.py

from database.database import DatabaseManager

def build_candle_cache():
    db = DatabaseManager()
    symbols = db.get_symbols_from_cache()
    timeframes = ["15m", "1h", "4h", "1d"]

    cache = {}
    for symbol in symbols:
        for tf in timeframes:
            candles = db.get_candles(symbol, tf)
            if candles:
                cache[(symbol, tf)] = candles
    return cache



# services/collector.py

import asyncio
import aiohttp
import logging
import json
from datetime import datetime

from database.database import DatabaseManager
from config.constants import BINANCE_TICKER_URL, CANDLE_SETTINGS

logger = logging.getLogger(__name__)

TIMEFRAMES = ["1d", "4h", "1h", "15m"]
EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}


class DataCollector:
    def __init__(self):
        self.db = DatabaseManager()

    # -------------------------------------------------
    # 1. Загрузка свечей для одной пары-таймфрейма
    # -------------------------------------------------
    async def fetch_candles(self, session, symbol: str, interval: str):
        url = f"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit=500"
        try:
            async with session.get(url, timeout=10) as resp:
                if resp.status != 200:
                    logger.error(f"❌ Ошибка загрузки {symbol} {interval}: {resp.status}")
                    return symbol, interval, []

                data = await resp.json()
                candles = [
                    {
                        "time":   int(c[0]),
                        "open":   float(c[1]),
                        "high":   float(c[2]),
                        "low":    float(c[3]),
                        "close":  float(c[4]),
                        "volume": float(c[5])
                    }
                    for c in data
                ]
                return symbol, interval, candles

        except Exception as e:
            logger.error(f"❌ Ошибка подключения {symbol} {interval}: {e}")
            return symbol, interval, []

    # -------------------------------------------------
    # 2. Основной метод: обновляем ВСЕ таймфреймы
    # -------------------------------------------------
    async def update_all_timeframes(self):
        symbols = self.db.get_symbols_from_cache()
        if not symbols:
            logger.warning("⚠️ Нет символов для загрузки")
            return

        # Исключаем стейблкоины
        symbols = [s for s in symbols if not any(stable in s for stable in EXCLUDED_STABLES)]

        need_update = []
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                for s in symbols:
                    for tf, cfg in CANDLE_SETTINGS.items():
                        cur.execute(
                            """
                            SELECT last_updated
                              FROM collected_candles
                             WHERE symbol = %s
                               AND timeframe = %s
                            """,
                            (s, tf),
                        )
                        row = cur.fetchone()
                        if (
                            row is None
                            or (datetime.now() - row[0]).total_seconds() > cfg["update_freq"]
                        ):
                            need_update.append((s, tf))
        finally:
            self.db.release_connection(conn)

        if not need_update:
            logger.info("✅ Все таймфреймы свежие — загрузка не требуется")
            return

        async with aiohttp.ClientSession(headers={"User-Agent": "Mozilla/5.0"}) as session:
            tasks = [self.fetch_candles(session, sym, tf) for sym, tf in need_update]
            results = await asyncio.gather(*tasks)

            for symbol, tf, candles in results:
                if candles:
                    self.db.upsert_candles(symbol, tf, candles)
                    logger.info(f"✅ Обновлены свечи: {symbol} {tf} ({len(candles)})")
        # ---- Сохраняем в БД ----
        self.bulk_upsert_candles(results)

    # -------------------------------------------------
    # 3. Массовая вставка/обновление свечей
    # -------------------------------------------------
    def bulk_upsert_candles(self, results):
        conn = self.db.get_connection()
        now = datetime.now()
        try:
            with conn.cursor() as cur:
                for symbol, timeframe, candles in results:
                    if not candles:
                        continue
                    cur.execute(
                        """
                        INSERT INTO collected_candles (symbol, timeframe, candles, last_updated)
                        VALUES (%s, %s, %s, %s)
                        ON CONFLICT (symbol, timeframe)
                        DO UPDATE
                            SET candles      = EXCLUDED.candles,
                                last_updated = EXCLUDED.last_updated
                        """,
                        (symbol, timeframe, json.dumps(candles), now),
                    )
            conn.commit()
            logger.info(f"💾 Загружены свечи для {len([r for r in results if r[2]])} комбинаций symbol/timeframe")
        except Exception as e:
            logger.error(f"❌ Ошибка сохранения свечей: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/data_manager.py

from database.database import DatabaseManager
import pandas as pd
from datetime import datetime

db = DatabaseManager()

def get_symbols():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("SELECT DISTINCT symbol FROM collected_candles")
            return [row[0] for row in cur.fetchall()]
    finally:
        db.release_connection(conn)

def get_candles(symbol, timeframe):
    try:
        candles = db.get_candles(symbol, timeframe)
        if not candles:
            return pd.DataFrame()
        df = pd.DataFrame(candles)
        df['date'] = pd.to_datetime(df['time'], unit='ms')
        df.set_index('date', inplace=True)
        return df.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})
    finally:
        pass

def get_levels(symbol, timeframe):
    all_levels = db.get_levels()
    filtered = [lvl for lvl in all_levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]
    return filtered


# Добавьте метод для массовой вставки:
def bulk_upsert_candles(self, data):
    """Массовая вставка данных"""
    conn = self.get_connection()
    try:
        with conn.cursor() as cur:
            # Используем COPY для высокой производительности
            from psycopg2.extras import Json
            from io import StringIO

            buffer = StringIO()
            for symbol, timeframe, candles in data:
                buffer.write(f"{symbol}\t{timeframe}\t{Json(candles)}\n")

            buffer.seek(0)
            cur.copy_from(buffer, 'collected_candles',
                          columns=('symbol', 'timeframe', 'candles'),
                          sep='\t')

            conn.commit()
    finally:
        self.release_connection(conn)


def get_signals(symbol, timeframe):
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("""SELECT signal_type, price, time FROM signals WHERE symbol = %s AND timeframe = %s ORDER BY time DESC LIMIT 10""",
                        (symbol, timeframe))
            return cur.fetchall()
    finally:
        db.release_connection(conn)

def get_alerts():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM alerts ORDER BY created_at DESC LIMIT 100")
            columns = [desc[0] for desc in cur.description]
            rows = cur.fetchall()
            return pd.DataFrame(rows, columns=columns)
    finally:
        db.release_connection(conn)

def get_signals_table():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("""SELECT symbol, timeframe, signal_type, price, time, indicator FROM signals ORDER BY time DESC LIMIT 100""")
            rows = cur.fetchall()
            df = pd.DataFrame(rows, columns=["symbol", "timeframe", "signal_type", "price", "time", "indicator"])
            df['time'] = pd.to_datetime(df['time'], unit='ms').dt.strftime("%Y-%m-%d %H:%M:%S")
            return df
    finally:
        db.release_connection(conn)

def clear_database():
    db.truncate_all_tables()



# services/deep_an.py

import aiohttp
import logging
from datetime import datetime, timedelta
from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class MarketCapTracker:
    def __init__(self):
        self.db = DatabaseManager()

    async def fetch_total_market_cap(self):
        url = "https://api.coingecko.com/api/v3/global"
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        total = data["data"]["total_market_cap"]["usd"]
                        logger.info(f"🌐 Капитализация: ${total:,.2f}")
                        self.save_market_cap(total)
                        self.delete_old_data()  # очищаем старые значения
                    else:
                        logger.warning(f"❌ Ошибка CoinGecko: {response.status}")
        except Exception as e:
            logger.error(f"❌ Ошибка получения капитализации: {e}")

    def save_market_cap(self, total_cap):
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO market_cap (total_cap, fetched_at)
                    VALUES (%s, %s)
                """, (total_cap, datetime.now()))
            conn.commit()
        except Exception as e:
            logger.error(f"❌ Ошибка сохранения капитализации: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    def delete_old_data(self):
        """Удаление данных старше 30 дней"""
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    DELETE FROM market_cap
                    WHERE fetched_at < NOW() - INTERVAL '30 days'
                """)
            conn.commit()
            logger.info("🧹 Старые записи капитализации удалены")
        except Exception as e:
            logger.error(f"❌ Ошибка удаления старых записей: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    def get_last_month_caps(self):
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT total_cap, fetched_at
                    FROM market_cap
                    WHERE fetched_at >= NOW() - INTERVAL '30 days'
                    ORDER BY fetched_at ASC
                """)
                return cur.fetchall()
        except Exception as e:
            logger.error(f"❌ Ошибка чтения капитализации: {e}")
            return []
        finally:
            self.db.releas



# services/derivatives_engine.py

import aiohttp
import asyncio
import logging
from asyncio import Semaphore

from database.database import DatabaseManager

logger = logging.getLogger(__name__)
BINANCE_FAPI = "https://fapi.binance.com"


class DerivativesEngine:
    def __init__(self):
        self.db = DatabaseManager()

    async def _fetch_json(self, url, params=None, retries=3):
        for attempt in range(retries):
            try:
                async with aiohttp.ClientSession() as s:
                    async with s.get(url, params=params, timeout=7) as r:
                        if r.status == 200:
                            return await r.json()
                        else:
                            logger.warning(f"⚠️ Ошибка ответа {r.status} от {url} для {params}")
                            return None
            except Exception as e:
                logger.error(f"❌ Ошибка подключения к {url} для {params}: {e}")
                await asyncio.sleep(1 + attempt)  # задержка перед повтором
        return None

    async def update_metrics(self, symbol: str):
        # Удаляем лишние символы, если есть
        symbol = symbol.replace("/", "")

        oi = await self._fetch_json(f"{BINANCE_FAPI}/fapi/v1/openInterest", {"symbol": symbol})
        if oi is None:
            logger.warning(f"⚠️ Ошибка openInterest для {symbol} — пропускаем")
            return

        fr = await self._fetch_json(f"{BINANCE_FAPI}/fapi/v1/fundingRate", {"symbol": symbol, "limit": 1})
        if not fr or not isinstance(fr, list) or "fundingRate" not in fr[0]:
            logger.warning(f"⚠️ Ошибка fundingRate для {symbol} — пропускаем")
            return

        records = [
            dict(symbol=symbol, timeframe="1h", indicator_type="OI", value=oi["openInterest"]),
            dict(symbol=symbol, timeframe="1h", indicator_type="FUND_RATE", value=fr[0]["fundingRate"]),
        ]
        self._save(records)

    async def _usdt_symbols(self, quote="USDT") -> list[str]:
        conn = self.db.get_connection()
        with conn, conn.cursor() as cur:
            cur.execute("SELECT symbol FROM pairs_cache WHERE symbol ILIKE %s", (f"%{quote}",))
            return [row[0] for row in cur.fetchall()]

    async def update_metrics_for_all(self):
        symbols = await self._usdt_symbols()
        sem = Semaphore(5)

        async def _guarded(sym):
            async with sem:
                await self.update_metrics(sym)

        await asyncio.gather(*[_guarded(s) for s in symbols])

    def _save(self, records):
        conn = self.db.get_connection()
        try:
            sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, NOW())
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value, created_at = EXCLUDED.created_at
            """
            with conn.cursor() as cur:
                for r in records:
                    cur.execute(sql, (
                        r["symbol"],
                        r["timeframe"],
                        r["indicator_type"],
                        str(r["value"])
                    ))
            conn.commit()
        except Exception as e:
            logger.error(f"❌ Ошибка сохранения деривативов: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/enter_exit_engine.py





# services/fibo_engine.py

import logging
import pandas as pd
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

FIBO_LEVELS = [0.236, 0.382, 0.5, 0.618, 0.786]

class FiboEngine:
    def __init__(self):
        self.db = DatabaseManager()

    def calculate_for_pair(self, symbol, timeframe):
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            return None

        df = pd.DataFrame(candles)
        df["high"] = pd.to_numeric(df["high"])
        df["low"] = pd.to_numeric(df["low"])

        high = df["high"].max()
        low = df["low"].min()

        fibo = [high - (high - low) * level for level in FIBO_LEVELS]

        return {
            "high": high,
            "low": low,
            "fibo_levels": dict(zip(FIBO_LEVELS, fibo))
        }



# services/identifier.py

import aiohttp
import asyncio
import logging
from datetime import datetime
from database.database import DatabaseManager
from config.constants import BINANCE_TICKER_URL


logger = logging.getLogger(__name__)

class PairIdentifier:
    def __init__(self):
        self.db = DatabaseManager()

    async def fetch_all_usdt_pairs(self):
        try:
            async with aiohttp.ClientSession(headers={"User-Agent": "Mozilla/5.0"}) as session:
                async with session.get(BINANCE_TICKER_URL, timeout=10) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        pairs = [item["symbol"] for item in data if item["symbol"].endswith("USDT")]
                        logger.info(f"📥 Получено {len(pairs)} USDT-пар с Binance")
                        return pairs
                    else:
                        logger.error(f"❌ Binance API error: {resp.status}")
                        return []
        except Exception as e:
            logger.error(f"❌ Ошибка получения пар с Binance: {e}")
            return []

    async def update_pairs_cache(self):
        pairs = await self.fetch_all_usdt_pairs()
        if not pairs:
            logger.warning("⚠️ Пары не получены — кэш не обновлён")
            return

        now = datetime.now()
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("TRUNCATE TABLE pairs_cache RESTART IDENTITY")
                insert = "INSERT INTO pairs_cache (symbol, volume, first_seen, last_seen) VALUES (%s, %s, %s, %s)"
                for pair in pairs:
                    cur.execute(insert, (pair, 0.0, now, now))
            conn.commit()
            logger.info(f"✅ Кэш пар обновлён: {len(pairs)} записей")
        except Exception as e:
            logger.error(f"❌ Ошибка при обновлении кэша пар: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/indicator_engine.py

import logging
from datetime import datetime


import numpy as np
import pandas as pd

from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class IndicatorEngine:
    def __init__(self):
        self.db = DatabaseManager()

    def compute_indicators(self):
        """Вычисляет и сохраняет полный набор индикаторов для каждой пары-таймфрейма."""
        all_candles = self.db.get_all_candles()
        indicators: list[dict] = []


        for (symbol, tf), candles in all_candles.items():
            # Нужна хотя бы 200-дневная история для EMA-200
            if len(candles) < 200:
                continue

            df = pd.DataFrame(candles)
            df["close"] = pd.to_numeric(df["close"])
            df["high"] = pd.to_numeric(df["high"])
            df["low"] = pd.to_numeric(df["low"])

            # ── базовые расчёты ───────────────────────────────────────────────────
            rsi = self._rsi(df["close"])
            macd_line, macd_sig, _ = self._macd(df["close"])
            macd_hist = macd_line - macd_sig  # ← добавь эту строку
            ema20 = df["close"].ewm(span=20, adjust=False).mean()
            ema50 = df["close"].ewm(span=50, adjust=False).mean()
            ema200 = df["close"].ewm(span=200, adjust=False).mean()
            bb_up, bb_mid, bb_lo = self._bollinger_bands(df["close"])
            stoch_k, stoch_d = self._stochastic(df)

            # ── объём / ликвидность ───────────────────────────────
            obv = self._obv(df["close"], df["volume"])
            vwap = self._vwap(df)  # 20-периодная
            poc = self._vpvr_poc(df)  # VPVR POC за N свечей

            # ── сила тренда и волатильность ───────────────────────
            atr = self._atr(df)  # 14-p ATR
            adx = self._adx(df)  # 14-p ADX

            # ── super-trend (по ATR) ──────────────────────────────
            supertrend = self._supertrend(df, atr)


            # # === Индикаторы ===
            # rsi = self._rsi(df)
            # macd_line, macd_sig, macd = self._macd(df)
            # ema20 = self._ema(df, 20)
            # ema50 = self._ema(df, 50)
            # ema200 = self._ema(df, 200)
            # bb_up, bb_mid, bb_lo = self._bollinger_bands(df["close"])
            # stoch_k, stoch_d = self._stochastic(df)
            # obv = self._obv(df["close"], df["volume"])
            # vwap = self._vwap(df)
            # poc = self._vpvr_poc(df)
            # atr = self._atr(df)
            # adx = self._adx(df)
            # supertrend = self._supertrend(df, atr)

            last_close = df["close"].iloc[-1]
            recommendation = self._recommend(
                last_close=last_close,
                ema20=ema20.iloc[-1],
                rsi_val=rsi.iloc[-1],
                macd_val=macd_line.iloc[-1],
                macd_sig=macd_sig.iloc[-1],
                macd_hist=macd_hist.iloc[-1],  # ← добавь эту строку
                bb_middle=bb_mid.iloc[-1]
            )

            indicators.append(dict(
                symbol=symbol,
                timeframe=tf,
                rsi=rsi.iloc[-1],
                macd=macd_hist.iloc[-1],  # можно оставить старое имя macd
                macd_hist=macd_hist.iloc[-1],  # ← добавь эту строку
                ema20=ema20.iloc[-1],
                ema50=ema50.iloc[-1],
                ema200=ema200.iloc[-1],
                bb_upper=bb_up.iloc[-1],
                bb_lower=bb_lo.iloc[-1],
                stoch_k=stoch_k.iloc[-1],
                stoch_d=stoch_d.iloc[-1],
                obv=obv.iloc[-1],
                vwap=vwap.iloc[-1],
                poc=poc if not hasattr(poc, "iloc") else float(poc.iloc[-1]),
                atr=atr.iloc[-1],
                adx=adx.iloc[-1],
                supertrend=supertrend.iloc[-1],
                recommendation=recommendation,
            ))

            indicators_to_save = [
                {"type": "RSI", "value": rsi.iloc[-1]},
                {"type": "MACD", "value": macd_hist.iloc[-1]},
                {"type": "EMA50", "value": ema50.iloc[-1]},
                {"type": "EMA200", "value": ema200.iloc[-1]},
                {"type": "BB_UPPER", "value": bb_up.iloc[-1]},
                {"type": "BB_LOWER", "value": bb_lo.iloc[-1]},
                {"type": "STOCH_K", "value": stoch_k.iloc[-1]},
                {"type": "STOCH_D", "value": stoch_d.iloc[-1]},
                {"type": "ATR", "value": atr.iloc[-1]},
                {"type": "ADX", "value": adx.iloc[-1]},
                {"type": "VWAP", "value": vwap.iloc[-1]},
                {"type": "POC", "value": poc if not hasattr(poc, "iloc") else float(poc.iloc[-1])}
            ]




        self._save_indicators(indicators)
        return indicators

    def _ema(self, df, period):
        return df["close"].ewm(span=period, adjust=False).mean()

    def _rsi(self, series, period=14):
        delta = series.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=period).mean()
        avg_loss = loss.rolling(window=period).mean()
        rs = avg_gain / avg_loss
        return 100 - (100 / (1 + rs))

    def _macd(self, series, fast=12, slow=26, signal=9):
        ema_fast = series.ewm(span=fast, adjust=False).mean()
        ema_slow = series.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        macd_hist = macd_line - signal_line
        return macd_line, signal_line, macd_hist

    def _bollinger_bands(self, series, period=20):
        middle = series.rolling(window=period).mean()
        std = series.rolling(window=period).std()
        upper = middle + 2 * std
        lower = middle - 2 * std
        return upper, middle, lower

    def _recommend(
            self,
            last_close: float,
            ema20: float,
            rsi_val: float,
            macd_val: float,
            macd_sig: float,
            macd_hist: float,  # ← добавили
            bb_middle: float
    ) -> str:
        """Простая heursitics-рекоммендация."""
        long_ok = macd_val > macd_sig and macd_hist > 0
        short_ok = macd_val < macd_sig and macd_hist < 0

        if ema20 > bb_middle and 50 < rsi_val < 70 and long_ok and last_close > bb_middle:
            return "ПОКУПАТЬ"
        if ema20 < bb_middle and 30 < rsi_val < 50 and short_ok and last_close < bb_middle:
            return "ПРОДАВАТЬ"
        return "НАБЛЮДАТЬ"

    def _stochastic(self, df, k_period=14, d_period=3):
        low_min = df["low"].rolling(window=k_period).min()
        high_max = df["high"].rolling(window=k_period).max()
        k = 100 * (df["close"] - low_min) / (high_max - low_min)
        d = k.rolling(window=d_period).mean()
        return k, d

    def _obv(self, close, volume):
        direction = np.sign(close.diff().fillna(0))
        return (volume * direction).cumsum()

    def _vwap(self, df, period=20):
        pv = (df["high"] + df["low"] + df["close"]) / 3 * df["volume"]
        return pv.rolling(period).sum() / df["volume"].rolling(period).sum()

    def _vpvr_poc(self, df, bins=24):
        hist, edges = np.histogram(df["close"], bins=bins, weights=df["volume"])
        idx = hist.argmax()
        return (edges[idx] + edges[idx + 1]) / 2

    def _atr(self, df, period=14):
        tr = pd.concat([
            df["high"] - df["low"],
            (df["high"] - df["close"].shift()).abs(),
            (df["low"] - df["close"].shift()).abs()
        ], axis=1).max(axis=1)
        return tr.rolling(period).mean()

    def _adx(self, df, period=14):
        up = df["high"].diff()
        dn = -df["low"].diff()
        plus_dm = np.where((up > dn) & (up > 0), up, 0.0)
        minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)
        tr = self._atr(df, 1)  # true range дневной
        plus_di = 100 * pd.Series(plus_dm).ewm(span=period).mean() / tr
        minus_di = 100 * pd.Series(minus_dm).ewm(span=period).mean() / tr
        dx = (abs(plus_di - minus_di) / (plus_di + minus_di)).fillna(0) * 100
        return dx.ewm(span=period).mean()

    def _supertrend(self, df, atr, factor=3):
        hl2 = (df["high"] + df["low"]) / 2
        upper = hl2 + factor * atr
        lower = hl2 - factor * atr
        trend = pd.Series(index=df.index, dtype=bool)
        trend.iloc[0] = True
        for i in range(1, len(df)):
            if df["close"].iloc[i] > upper.iloc[i - 1]:
                trend.iloc[i] = True
            elif df["close"].iloc[i] < lower.iloc[i - 1]:
                trend.iloc[i] = False
            else:
                trend.iloc[i] = trend.iloc[i - 1]
                upper.iloc[i] = min(upper.iloc[i], upper.iloc[i - 1]) if trend.iloc[i] else upper.iloc[i]
                lower.iloc[i] = max(lower.iloc[i], lower.iloc[i - 1]) if not trend.iloc[i] else lower.iloc[i]
        return trend

    def _save_indicators(self, records: list[dict]):
        """Сохраняет рассчитанные индикаторы в таблицу `indicators`."""
        if not records:
            return

        import numpy as np  # нужен для проверки np.floating

        conn = self.db.get_connection()
        insert_sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value,
                          created_at = EXCLUDED.created_at;
        """

        names = [
            "RSI", "MACD", "MACD_HIST", "EMA20", "EMA50", "EMA200",
            "BB_UPPER", "BB_LOWER", "STOCH_K", "STOCH_D", "RECOMMENDATION", "OBV", "VWAP", "VPVR_POC", "ATR", "ADX", "SUPERTREND"
        ]

        try:
            with conn.cursor() as cur:
                for rec in records:
                    for name in names:
                        key = "recommendation" if name == "RECOMMENDATION" else name.lower()
                        val = rec.get(key)
                        if val is None:
                            continue

                        # numpy → float | строка → str
                        if isinstance(val, (float, int, np.floating)):
                            val_db = float(val)
                        else:
                            val_db = str(val)

                        cur.execute(
                            insert_sql,
                            (rec["symbol"], rec["timeframe"], name, val_db)
                        )
            conn.commit()
        except Exception as e:
            conn.rollback()
            logger.error(f"❌ Ошибка сохранения индикаторов: {e}", exc_info=True)
        finally:
            self.db.release_connection(conn)



# services/level_engine.py

import logging
from datetime import datetime
import numpy as np
import pandas as pd

from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class LevelAnalyzer:
    def __init__(self):
        self.db = DatabaseManager()
        self.configs = {
            "15m": {"pivot_period": 3, "min_strength": 2, "max_pivot_points": 50, "max_channel_width_percent": 8},
            "1h": {"pivot_period": 5, "min_strength": 3, "max_pivot_points": 40, "max_channel_width_percent": 6},
            "4h": {"pivot_period": 7, "min_strength": 4, "max_pivot_points": 30, "max_channel_width_percent": 5},
            "1d": {"pivot_period": 10, "min_strength": 5, "max_pivot_points": 20, "max_channel_width_percent": 4},
        }

    def analyze_levels(self):
        all_candles = self.db.get_all_candles()
        levels = []

        for (symbol, tf), candles in all_candles.items():
            if tf not in self.configs or len(candles) < 100:
                continue

            df = pd.DataFrame(candles)
            df["close"] = pd.to_numeric(df["close"])
            df["high"] = pd.to_numeric(df["high"])
            df["low"] = pd.to_numeric(df["low"])

            cfg = self.configs[tf]
            df = self._detect_pivots(df, cfg["pivot_period"])
            channels = self._cluster_levels(df, cfg)

            for ch in channels:
                levels.append({
                    "symbol": symbol,
                    "timeframe": tf,
                    "price": ch["price"],
                    "type": ch["type"],
                    "strength": ch["strength"],
                    "upper": ch["upper"],
                    "lower": ch["lower"],
                    "distance": ch["distance"],
                    "touched": 0,
                    "broken": False,
                    "last_touched": datetime.now().timestamp()
                })

        merged = self._merge_levels(levels)
        self.db.save_levels(merged)
        return merged

    def _detect_pivots(self, df, period):
        df["ph"] = df["high"].rolling(window=2 * period + 1, center=True).apply(
            lambda x: x[period] if x[period] == x.max() else np.nan, raw=True)
        df["pl"] = df["low"].rolling(window=2 * period + 1, center=True).apply(
            lambda x: x[period] if x[period] == x.min() else np.nan, raw=True)
        return df

    def _cluster_levels(self, df, cfg):
        points = []
        for i, row in df.iterrows():
            if not np.isnan(row["ph"]):
                points.append((row["ph"], "resistance"))
            elif not np.isnan(row["pl"]):
                points.append((row["pl"], "support"))

        points = points[-cfg["max_pivot_points"]:]
        avg_price = df["close"].tail(50).mean()
        channel_width = avg_price * cfg["max_channel_width_percent"] / 100
        used, clusters = set(), []

        for i, (price, ptype) in enumerate(points):
            if i in used:
                continue
            cluster = [(price, ptype)]
            for j in range(i + 1, len(points)):
                if abs(price - points[j][0]) <= channel_width:
                    cluster.append(points[j])
                    used.add(j)
            if len(cluster) >= cfg["min_strength"]:
                prices = [p[0] for p in cluster]
                level_type = "resistance" if sum(1 for p in cluster if p[1] == "resistance") > len(cluster) / 2 else "support"
                clusters.append({
                    "price": np.mean(prices),
                    "type": level_type,
                    "strength": len(cluster),
                    "upper": max(prices),
                    "lower": min(prices),
                    "distance": abs(np.mean(prices) - df["close"].iloc[-1]) / df["close"].iloc[-1]
                })

        # EMA уровни (если достаточно свечей)
        if len(df) >= 200:
            for span, label in [(50, "ema50"), (200, "ema200")]:
                ema = df["close"].ewm(span=span, adjust=False).mean().iloc[-1]
                clusters.append({
                    "price": ema,
                    "type": label,
                    "strength": 5 if label == "ema50" else 6,
                    "upper": ema,
                    "lower": ema,
                    "distance": abs(ema - df["close"].iloc[-1]) / df["close"].iloc[-1]
                })

        return clusters

    def _merge_levels(self, levels):
        merged = {}
        for lvl in levels:
            key = f"{lvl['symbol']}_{lvl['timeframe']}_{lvl['price']:.8f}"
            if key in merged:
                merged[key]["strength"] = max(merged[key]["strength"], lvl["strength"])
                merged[key]["touched"] += 1
                merged[key]["last_touched"] = datetime.now().timestamp()
            else:
                merged[key] = lvl
        return list(merged.values())



# services/sentiment_engine.py

import aiohttp
import asyncio
import logging

from database.database import DatabaseManager

BINANCE_FAPI = "https://fapi.binance.com"
logger = logging.getLogger(__name__)


class SentimentEngine:
    def __init__(self):
        self.db = DatabaseManager()

    async def _fetch_json(self, url, params=None, timeout=7):
        try:
            async with aiohttp.ClientSession() as sess:
                async with sess.get(url, params=params, timeout=timeout) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.warning(f"⚠️ Ошибка ответа {resp.status} от {url} для {params}")
        except Exception as e:
            logger.error(f"❌ Ошибка подключения к {url} для {params}: {e}")
        return None

    def _save(self, rows):
        conn = self.db.get_connection()
        try:
            sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, NOW())
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value, created_at = EXCLUDED.created_at
            """
            with conn.cursor() as cur:
                for r in rows:
                    cur.execute(sql, (
                        r["symbol"],
                        r["timeframe"],
                        r["indicator_type"],
                        str(r["value"])
                    ))
            conn.commit()
        except Exception as e:
            logger.error(f"❌ Ошибка сохранения сентимента: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    async def _usdt_symbols(self, quote="USDT"):
        conn = self.db.get_connection()
        with conn, conn.cursor() as cur:
            cur.execute("SELECT symbol FROM pairs_cache WHERE symbol ILIKE %s", (f"%{quote}",))
            return [row[0] for row in cur.fetchall()]

    async def update_for_all(self, quote="USDT", interval="5m", max_concurrent=10):
        symbols = await self._usdt_symbols(quote)
        if not symbols:
            logger.warning("SentimentEngine: не найдено ни одной пары с USDT")
            return

        sem = asyncio.Semaphore(max_concurrent)

        async def _guarded(sym):
            async with sem:
                await self.update(symbol=sym, interval=interval)

        await asyncio.gather(*[_guarded(s) for s in symbols])

    async def update(self, symbol="BTCUSDT", interval="5m"):
        symbol = symbol.replace("/", "").upper()
        url = f"{BINANCE_FAPI}/futures/data/globalLongShortAccountRatio"
        data = await self._fetch_json(url, {
            "symbol": symbol,
            "period": interval,
            "limit": 1
        })

        if not data:
            return

        rec = data[0]
        longs = float(rec["longAccount"])
        shorts = float(rec["shortAccount"])
        ratio = 100 * longs / (longs + shorts)

        rows = [
            {"symbol": symbol, "timeframe": interval, "indicator_type": "LONGS_RATIO", "value": ratio},
            {"symbol": symbol, "timeframe": interval, "indicator_type": "SHORTS_RATIO", "value": 100 - ratio},
        ]
        self._save(rows)



# services/signal_engine.py

import logging
import pandas as pd
from database.database import DatabaseManager
from services.fibo_engine import FiboEngine
from services.signal_score import SignalScorer
from services.alert_engine import AlertSystem

logger = logging.getLogger(__name__)

class SignalEngine:
    def __init__(self):
        self.db = DatabaseManager()
        self.fibo = FiboEngine()
        self.scorer = SignalScorer()

    def generate_signals(self):
        """Формирует сигналы на основе пришедших алертов и текущих данных."""
        logger.info("📊 Генерация сигналов из алертов и свечей...")



        alerts = AlertSystem().check_alerts()
        if not alerts:
            logger.warning("⚠️ Нет алертов для анализа")
            return

        all_candles = self.db.get_all_candles()
        all_levels = self.db.get_levels()
        signals = []


        for alert in alerts:
            signal_type = alert.get("signal_type") or alert.get("type")
            if not signal_type:
                logger.debug(f"⛔️ Пропуск алерта без типа: {symbol} {tf}")
                continue
            try:
                symbol = alert["symbol"]
                tf = alert["timeframe"]
                if (candles := all_candles.get((symbol, tf))) is None or len(candles) < 50:
                    continue

                df = pd.DataFrame(candles)
                df["close"] = pd.to_numeric(df["close"])
                close_price = df["close"].iloc[-1]

                # ── все индикаторы из БД ───────────────────────────────────────
                db_ind = self.db.get_indicators(symbol, tf)
                get = lambda k: float(db_ind[k]) if db_ind.get(k) is not None else None

                indicators = {
                    "rsi": get("RSI"),
                    "macd": get("MACD"),
                    "macd_hist": get("MACD"),
                    "ema50": get("EMA50"),
                    "ema200": get("EMA200"),
                    "bb_upper": get("BB_UPPER"),
                    "bb_lower": get("BB_LOWER"),
                    "stoch_k": get("STOCH_K"),
                    "stoch_d": get("STOCH_D"),
                    "atr": get("ATR"),
                    "adx": get("ADX"),
                    "vwap": get("VWAP"),
                    "poc": get("POC"),
                }

                # ── оценка сигнала ─────────────────────────────────────────────
                trend_data = self.db.get_trend(symbol)
                fibo = self.fibo.calculate_for_pair(symbol, tf)
                levels = [lvl for lvl in all_levels if lvl["symbol"] == symbol and lvl["timeframe"] == tf]
                market_cap_data = self.db.get_market_cap()

                def calculate_bb_position(price, upper, lower):
                    """Возвращает позицию цены внутри полос Боллинджера от 0 до 1"""
                    if upper is None or lower is None or upper == lower:
                        return None
                    return (price - lower) / (upper - lower)

                bb_pos = calculate_bb_position(close_price, indicators["bb_upper"], indicators["bb_lower"])

                signal_meta = {
                    "symbol": symbol,
                    "timeframe": tf,
                    "signal_type": signal_type,
                    "price": alert.get("price"),
                    "current_price": close_price,
                    "rsi": indicators["rsi"],
                    "macd": indicators["macd"],
                    "ema50": indicators["ema50"],
                    "ema200": indicators["ema200"],
                    "bb_position": bb_pos,
                    "stoch_k": indicators["stoch_k"],
                    "stoch_d": indicators["stoch_d"],
                    "atr": indicators["atr"],
                    "adx": indicators["adx"],
                    "vwap": indicators["vwap"],
                    "poc": indicators["poc"],
                }

                result = self.scorer.evaluate(
                    trend_data,
                    levels,
                    indicators,
                    fibo["fibo_levels"] if fibo else {},
                    market_cap_data,
                    signal_meta
                )

                # ── формируем подробности ──────────────────────────────────────
                det = [
                    f"Индикатор: Текущая цена: {close_price:.6f}",
                    f"Индикатор: RSI: {indicators['rsi']:.2f}" if indicators["rsi"] is not None else None,
                    f"Индикатор: MACD гист.: {indicators['macd_hist']:.6f}" if indicators["macd_hist"] is not None else None,
                    f"Индикатор: EMA-50: {indicators['ema50']:.6f}" if indicators["ema50"] is not None else None,
                    f"Индикатор: EMA-200: {indicators['ema200']:.6f}" if indicators["ema200"] is not None else None,
                    (
                        f"Индикатор: Bollinger Bands: верх {indicators['bb_upper']:.6f}, "
                        f"низ {indicators['bb_lower']:.6f}"
                    ) if indicators["bb_upper"] is not None and indicators["bb_lower"] is not None else None,
                    (
                        f"Индикатор: Stochastic %K={indicators['stoch_k']:.2f}, "
                        f"%D={indicators['stoch_d']:.2f}"
                    ) if indicators["stoch_k"] is not None and indicators["stoch_d"] is not None else None,
                ]
                # убираем None и добавляем детали из Scorer
                details = [d for d in det if d] + result["details"]

                # ── добавляем сигнал в список ──────────────────────────────────
                signals.append({
                    "symbol": symbol,
                    "timeframe": tf,
                    "signal_type":    signal_type,
                    "current_price": close_price,
                    "recommendation": result["recommendation"],
                    "score": result["score"],
                    "created_at": alert.get("created_at"),
                    "details": "\n".join(details),
                    "rsi": indicators["rsi"],
                    "macd": indicators["macd_hist"],
                    "ema50": indicators["ema50"],
                    "ema200": indicators["ema200"],
                    "bb_position": None,  # при желании можно посчитать
                    "stoch_k": indicators["stoch_k"],
                    "stoch_d": indicators["stoch_d"],
                })

            except Exception as e:
                logger.error(f"❌ Ошибка при анализе {alert.get('symbol')} {alert.get('timeframe')}: {e}", exc_info=True)

        # ── сохранение ─────────────────────────────────────────────────────────
        if signals:
            # ── dedup по ключу (symbol, timeframe, signal_type) ───────────────
            deduped: dict[tuple, dict] = {}
            for sig in signals:
                key = (sig["symbol"], sig["timeframe"], sig["signal_type"])
                # если встречается повтор, оставляем тот, у которого score выше
                if key not in deduped or sig["score"] > deduped[key]["score"]:
                    deduped[key] = sig

            signals = list(deduped.values())
            self.db.save_signals(signals)
            logger.info(f"✅ Всего сигналов сохранено: {len(signals)}")
        else:
            logger.info("📭 Новых сигналов не найдено")

        return signals



# services/signal_score.py

import logging

logger = logging.getLogger(__name__)

class SignalScorer:
    def __init__(self):
        pass

    def evaluate(
            self,
            trend_data: dict | None,
            levels: list[dict],
            indicators: dict,
            fibo_levels: list[dict] | dict,
            market_cap_data: dict | None,
            signal: dict,
    ) -> dict:
        def to_float(x):
            """Пытается превратить значение в float, иначе возвращает None."""
            try:
                return float(x)
            except (TypeError, ValueError):
                return None

        rsi = to_float(indicators.get("rsi"))
        macd_h = to_float(indicators.get("macd_hist"))
        ema50 = to_float(indicators.get("ema50"))
        ema200 = to_float(indicators.get("ema200"))
        """
        Рассчитывает итоговый score и формирует текстовые детали по сигналу.
        Возвращает: {"score": int, "recommendation": str, "details": list[str]}
        """
        score = 0
        details: list[str] = []

        symbol = signal["symbol"]
        timeframe = signal["timeframe"]
        signal_type = signal["signal_type"]

        atr = indicators.get("atr")
        adx = indicators.get("adx")
        supertrend = indicators.get("supertrend")
        oi = indicators.get("oi")
        fund_rate = indicators.get("fund_rate")
        vwap = indicators.get("vwap")
        poc = indicators.get("vpvr_poc")
        sentiment = indicators.get("longs_ratio")  # или другой ключ

        # ── безопасно получаем цену ───────────────────────────────────────────
        try:
            price = float(signal.get("price") or signal["current_price"])
        except (KeyError, TypeError, ValueError):
            raise ValueError(
                f"Не удалось определить цену для {symbol} {timeframe} ({signal_type})"
            )

        current_price = float(signal["current_price"])

        # ── вспомогательные форматтеры ────────────────────────────────────────
        fmt_pct = lambda v: f"{v:+.2f}%"
        fmt_dir = lambda d: "выше уровня" if d > 0 else "ниже уровня"

        # ── 1. Тренд ──────────────────────────────────────────────────────────
        if trend_data:
            direction = trend_data.get("direction", "").upper()
            if direction == "BULLISH" and signal_type == "long":
                score += 20
                details.append("✅ Тренд: BULLISH")
            elif direction == "BEARISH" and signal_type == "short":
                score += 20
                details.append("✅ Тренд: BEARISH")
            elif direction:
                details.append(f"⚠️ Тренд: {direction}")

        # ── 2. Близость к уровням S/R ─────────────────────────────────────────
        for lvl in levels:
            if lvl["symbol"] != symbol or lvl["timeframe"] != timeframe:
                continue
            delta = (current_price - float(lvl["price"])) / current_price * 100
            if abs(delta) < 0.5:  # ±0.5 %
                score += 15
                details.append(
                    f"📈 {lvl['type'].capitalize()}: {lvl['price']:.6f} | "
                    f"Цена {fmt_dir(delta)} на {fmt_pct(delta)}"
                )

            # ── 3. Фибоначчи ─────────────────────────────────────────────────────
            if isinstance(fibo_levels, dict):
                # формат {"0.236": 108132.90, ...}
                for level_name, price_val in fibo_levels.items():
                    try:
                        price_val = float(price_val)
                    except (TypeError, ValueError):
                        continue
                    delta = (current_price - price_val) / current_price * 100
                    if abs(delta) < 0.8:  # ±0.8 %
                        score += 10
                        details.append(
                            f"🔢 Фибоначчи {level_name}: {price_val:.6f} | "
                            f"Цена {fmt_dir(delta)} на {fmt_pct(delta)}"
                        )
            else:
                # формат [{"symbol": ..., "timeframe": ..., "level": ..., "price": ...}, ...]
                for fl in fibo_levels or []:
                    if fl.get("symbol") != symbol or fl.get("timeframe") != timeframe:
                        continue
                    try:
                        price_val = float(fl["price"])
                    except (TypeError, ValueError, KeyError):
                        continue
                    delta = (current_price - price_val) / current_price * 100
                    if abs(delta) < 0.8:
                        score += 10
                        details.append(
                            f"🔢 Фибоначчи {fl['level']}: {price_val:.6f} | "
                            f"Цена {fmt_dir(delta)} на {fmt_pct(delta)}"
                        )

        # ── 4. RSI / MACD / EMA / Stochastic / Bollinger ─────────────────────

        if rsi is not None:
            if (signal_type == "long" and rsi < 30) or (signal_type == "short" and rsi > 70):
                score += 10
                details.append(f"🎯 RSI: {rsi:.1f} (сильный сигнал)")
            else:
                details.append(f"ℹ️ RSI: {rsi:.1f}")

        macd_h = indicators.get("macd_hist")
        if macd_h is not None:
            if (signal_type == "long" and macd_h > 0) or (signal_type == "short" and macd_h < 0):
                score += 8
                details.append(f"🎯 MACD гистограмма: {macd_h:+.6f}")
            else:
                details.append(f"ℹ️ MACD гистограмма: {macd_h:+.6f}")

            # ── ATR: дальность стопа / тейка ───────────────────────
            atr = indicators.get("atr")
            if atr is not None:
                r_multiple = abs(current_price - price) / atr
                details.append(f"ℹ️ ATR: {atr:.6f}  |  {r_multiple:.1f} R до уровня")

            # ── Open Interest & Funding ────────────────────────────
            oi = indicators.get("oi")
            fnd = indicators.get("fund_rate")
            if oi is not None:
                details.append(f"ℹ️ Open Interest: {float(oi):,.0f}")
            if fnd is not None and abs(float(fnd)) > 0.0004:
                score += 4
                details.append(f"💸 Funding rate: {float(fnd):.4%}")

            # ── ADX / SuperTrend  __________________________________
            adx = indicators.get("adx")
            st = indicators.get("supertrend")
            if adx is not None and adx > 25:
                score += 5
                details.append(f"✅ ADX {adx:.1f} (сильный тренд)")
            if st is not None and ((st and signal_type == "long") or (not st and signal_type == "short")):
                score += 6
                details.append("✅ SuperTrend в ту же сторону")

            # --- VWAP: сравнение с ценой ---
            vwap = signal.get("vwap")
            price = signal.get("current_price")
            if vwap and price:
                diff = price - vwap
                pct = 100 * diff / vwap
                side = "выше" if diff > 0 else "ниже"
                details.append(f"📉 VWAP: {vwap:.6f} | Цена {side} на {pct:+.2f}%")

            # --- POC: point of control ---
            poc = signal.get("poc")
            if poc and price:
                diff = price - poc
                pct = 100 * diff / poc
                side = "выше" if diff > 0 else "ниже"
                details.append(f"📍 POC: {poc:.6f} | Цена {side} на {pct:+.2f}%")


        # EMA-50 / EMA-200
        for ema_key, pts in [("ema50", 5), ("ema200", 5)]:
            ema_val = indicators.get(ema_key)
            if ema_val is None:
                continue
            delta = (current_price - ema_val) / current_price * 100
            if (signal_type == "long" and delta > 0) or (signal_type == "short" and delta < 0):
                score += pts
            details.append(
                f"ℹ️ {ema_key.upper()}: {ema_val:.6f} | "
                f"Цена {fmt_dir(delta)} на {fmt_pct(delta)}"
            )

        # Stochastic
        if indicators.get("stoch_k") is not None and indicators.get("stoch_d") is not None:
            st_k = indicators["stoch_k"]
            st_d = indicators["stoch_d"]
            if (signal_type == "long" and st_k < 20 and st_d < 20) or (
                    signal_type == "short" and st_k > 80 and st_d > 80
            ):
                score += 6
                details.append(f"🎯 Stochastic %K={st_k:.1f} %D={st_d:.1f}")
            else:
                details.append(f"ℹ️ Stochastic %K={st_k:.1f} %D={st_d:.1f}")

        # Bollinger Bands
        if indicators.get("bb_upper") and indicators.get("bb_lower"):
            bb_up = indicators["bb_upper"]
            bb_lo = indicators["bb_lower"]
            band_pct = (current_price - bb_lo) / (bb_up - bb_lo) * 100
            details.append(f"ℹ️ Bollinger Bands позиция: {band_pct:.1f}%")

            # ── 5. Рыночная капитализация ───────────────────────────────────────
            cap_change = None
            if market_cap_data:
                if isinstance(market_cap_data, dict):
                    cap_change = market_cap_data.get("percent_change_24h")
                elif isinstance(market_cap_data, list) and market_cap_data:
                    # берём первую запись или среднее — зависит от вашей логики
                    first = market_cap_data[0]
                    if isinstance(first, dict):
                        cap_change = first.get("percent_change_24h")

            if cap_change is not None:
                try:
                    cap_change = float(cap_change)
                except (TypeError, ValueError):
                    cap_change = None

            if cap_change is not None and abs(cap_change) > 2:
                score += 3
                details.append(f"💰 Капитализация 24 ч: {fmt_pct(cap_change)}")

        # ── финальная рекомендация ───────────────────────────────────────────
        recommendation = (
            "Сильный сигнал" if score >= 40 else
            "Умеренный сигнал" if score >= 25 else
            "Слабый сигнал"
        )

        return {
            "score": score,
            "recommendation": recommendation,
            "details": details,
        }



# services/trend_engine.py

import pandas as pd
from datetime import datetime
from database.database import DatabaseManager
import logging

logger = logging.getLogger(__name__)


class TrendAnalyzer:
    def __init__(self):
        self.db = DatabaseManager()

    def analyze_trends(self):
        candles = self.db.get_all_candles()
        trends = {}

        for (symbol, tf), data in candles.items():
            if len(data) < 200:
                continue

            df = pd.DataFrame(data)
            df["close"] = pd.to_numeric(df["close"])
            ema50 = df["close"].ewm(span=50, adjust=False).mean().iloc[-1]
            ema200 = df["close"].ewm(span=200, adjust=False).mean().iloc[-1]
            direction = "bullish" if ema50 > ema200 else "bearish"

            trends[symbol] = {
                "direction": direction,
                "ema50": ema50,
                "ema200": ema200,
                "last_updated": datetime.now().timestamp()
            }

        self.db.save_trends(trends)



# services/worker.py

import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}

from database.database import DatabaseManager
from services.signal_score import SignalScorer
from services.fibo_engine import FiboEngine
from services.signal_engine import SignalEngine

logger = logging.getLogger(__name__)


class SignalWorker:
    def __init__(self):
        self.db = DatabaseManager()
        self.scorer = SignalScorer()
        self.fibo = FiboEngine()
        self.signal_engine = SignalEngine()


    # ---------- public -----------------------------------------------------

    def process_all_pairs(self):
        logger.info("⚙️ Обработка всех пар для генерации сигналов")
        pairs = self.db.get_symbols_from_cache()

        pairs = [s for s in pairs if not any(stable in s for stable in EXCLUDED_STABLES)]
        timeframes = ["1d", "4h", "1h", "15m"]
        tasks = [(symbol, tf) for symbol in pairs for tf in timeframes]

        results = []

        trend_cache = {t["symbol"]: t for t in self.db.get_all_trends()}
        levels_cache = self.db.get_levels()
        market_cap_data = self.db.get_market_cap()

        with ThreadPoolExecutor(max_workers=20) as executor:
            futures = {
                executor.submit(
                    self.analyze_pair,
                    symbol,
                    tf,
                    trend_cache,
                    levels_cache,
                    market_cap_data,
                ): (symbol, tf)
                for symbol, tf in tasks
            }

            for future in as_completed(futures):
                result = future.result()
                if result:
                    results.append(result)

        # результирующий плоский список
        flat_results = [
            item
            for sub in results
            if isinstance(sub, list)
            for item in sub
            if isinstance(item, dict)
            and {"symbol", "timeframe", "signal_type"} <= item.keys()
        ]

        if flat_results:
            self.db.save_signals(flat_results)
            logger.info(f"✅ Сигналы сохранены в базу: {len(flat_results)}")
        else:
            logger.info("📭 Нет сигналов для сохранения")

        return flat_results

    # ---------- private ----------------------------------------------------

    def analyze_pair(
        self,
        symbol: str,
        timeframe: str,
        trend_cache: dict,
        levels_cache: list,
        market_cap_data: dict,
    ):
        start = time.time()

        # ── индикаторы ────────────────────────────────────────────────────
        raw = self.db.get_indicators(symbol, timeframe)

        def _as_float(val):
            """Вернёт float, если значение похоже на число; иначе None."""
            if val in (None, ""):
                return None
            try:
                return float(val)
            except (ValueError, TypeError):
                return None

        indicators = {k.lower(): _as_float(v) for k, v in raw.items()}

        try:
            candles = self.db.get_candles(symbol, timeframe)
            if not candles or len(candles) < 30:
                return None

            current_price = candles[-1]["close"]
            trend_data = trend_cache.get(symbol, {})
            levels = [
                lvl
                for lvl in levels_cache
                if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe
            ]
            fibo = self.fibo.calculate_for_pair(symbol, timeframe)

            results = []

            # --- PATCH BEGIN -----------------------------------------------------------
            # соберём общие для любого типа сигнала данные
            base_payload = {
                "SYMBOL": symbol,  # <= оставьте как нужно БД
                "TIMEFRAME": timeframe,
                "PRICE": current_price,
                "CURRENT_PRICE": current_price,

                # индикаторы –  в том регистре, как названы колонки signals
                "RSI": indicators.get("rsi"),
                "MACD": indicators.get("macd_hist"),
                "STOCH_K": indicators.get("stoch_k"),
                "STOCH_D": indicators.get("stoch_d"),
                "ATR": indicators.get("atr"),
                "ADX": indicators.get("adx"),
                "OI": indicators.get("oi"),
                "FUND_RATE": indicators.get("fund_rate"),
                "SUPERTREND": indicators.get("supertrend"),
                "VWAP": indicators.get("vwap"),
                "POC": indicators.get("vpvr_poc"),
            }
            for signal_type in ("long", "short"):
                signal = {
                    "symbol": symbol,
                    "timeframe": timeframe,
                    "signal_type": signal_type,
                    "price": current_price,
                    "current_price": current_price,
                }

                result = self.scorer.evaluate(
                    trend_data,
                    levels,
                    indicators,
                    fibo["fibo_levels"] if fibo else {},
                    market_cap_data,
                    signal,
                )

                if result and result["score"] >= 30:
                    # 👉 приводим details к строке с переводами строк
                    if isinstance(result["details"], (list, set, tuple)):
                        result["details"] = "\n".join(result["details"])

                    # мёрджим payload → гарантируем, что в БД уйдут все колонки
                    result |= base_payload | {"SIGNAL_TYPE": signal_type}

                    results.append(result)

            return results if results else None

        finally:
            duration = time.time() - start
            logger.debug(f"⏱ {symbol} {timeframe} анализ за {duration:.2f} сек")



