# main.py

# main.py ‚Äî —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ gui
import sys
import os
# os.environ["QT_QPA_PLATFORM"] = "wayland-egl"  # –∏–ª–∏ "wayland-egl"
os.environ["XDG_SESSION_TYPE"] = "x11"

from PyQt5.QtWidgets import QApplication
from gui.app import create_main_window
from config.settings import Settings

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = create_main_window()
    window.mainloop()
    sys.exit(app.exec_())



# reverse.py

import os

def parse_bot_final(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    file_blocks = {}
    current_file = None
    current_lines = []

    for line in lines:
        if line.startswith("# ") and line.strip().endswith(".py"):
            if current_file:
                file_blocks[current_file] = ''.join(current_lines).strip() + '\n'
            current_file = line.strip()[2:]  # —É–¥–∞–ª—è–µ–º "# " –≤ –Ω–∞—á–∞–ª–µ
            current_lines = []
        else:
            if current_file:
                current_lines.append(line)

    if current_file and current_lines:
        file_blocks[current_file] = ''.join(current_lines).strip() + '\n'

    return file_blocks


def write_files_from_blocks(blocks):
    for file_path, content in blocks.items():
        dir_name = os.path.dirname(file_path)
        if dir_name:
            os.makedirs(dir_name, exist_ok=True)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"‚úÖ –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω —Ñ–∞–π–ª: {file_path}")


if __name__ == "__main__":
    bot_final_path = "bot_final.txt"
    if not os.path.exists(bot_final_path):
        print("‚ùå –§–∞–π–ª bot_final.txt –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        file_blocks = parse_bot_final(bot_final_path)
        write_files_from_blocks(file_blocks)
        print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –∏–∑ bot_final.txt")



# run_full.py

import asyncio
import logging
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
import os
from services.worker           import SignalWorker
from services.identifier        import PairIdentifier
from services.collector         import DataCollector
from services.level_engine      import LevelAnalyzer
from services.indicator_engine  import IndicatorEngine
from services.trend_engine      import TrendAnalyzer
from services.signal_engine     import SignalEngine
from services.deep_an           import MarketCapTracker
from database.database          import DatabaseManager



logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def wait_for_candles(target=50, timeout=10):
    """–ë–ª–æ–∫–∏—Ä—É–µ—Ç –ø–æ—Ç–æ–∫ –¥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ —á–∏—Å–ª–∞ —Å–≤–µ—á–µ–π."""
    db = DatabaseManager()
    for _ in range(timeout):
        if any(len(c) >= target for c in db.get_all_candles().values()):
            logger.info("‚úÖ –°–≤–µ—á–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return True
        logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–≤–µ—á–µ–π...")
        time.sleep(1)
    logger.warning("‚ùå –°–≤–µ—á–∏ –Ω–µ –ø–æ—è–≤–∏–ª–∏—Å—å –∑–∞ –æ—Ç–≤–µ–¥—ë–Ω–Ω–æ–µ –≤—Ä–µ–º—è")
    return False

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def update_market_data():
    # ‚ë† —Å–ø–µ—Ä–≤–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º pairs_cache
    await PairIdentifier().update_pairs_cache()

    # ‚ë° –∑–∞—Ç–µ–º —É–∂–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
    await asyncio.gather(
        # DerivativesEngine().update_metrics_for_all(),   # —Ç—Ä–µ–±—É–µ—Ç pairs_cache
        # SentimentEngine().update_for_all(),             #   ‚Äî//‚Äî
        DataCollector().update_all_timeframes(),        #   ‚Äî//‚Äî
        MarketCapTracker().fetch_total_market_cap(),
    )

def analyze():
    LevelAnalyzer().analyze_levels()
    IndicatorEngine().compute_indicators()
    TrendAnalyzer().analyze_trends()

def run_worker():
    return SignalWorker().process_all_pairs()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def main():
    logger.info("üöÄ –ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫: –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ + –æ—Ü–µ–Ω–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤")
    DatabaseManager().clear_old_candles()

    # –®–∞–≥ 1. —Å–µ—Ç–µ–≤—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    await update_market_data()

    # –®–∞–≥ 2. –∂–¥—ë–º –ø–æ—è–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(None, wait_for_candles)

    # –®–∞–≥ 3. –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (CPU)
    with ThreadPoolExecutor() as pool:
        await loop.run_in_executor(pool, analyze)

        # –®–∞–≥ 4. –≥–µ–Ω–µ—Ä–∞—Ü–∏—è ¬´—Å—ã—Ä—ã—Ö¬ª —Å–∏–≥–Ω–∞–ª–æ–≤ (AlertSystem –≤–Ω—É—Ç—Ä–∏)
        SignalEngine().generate_signals()

        # –®–∞–≥ 5. ¬´–≥–ª—É–±–æ–∫–∞—è¬ª –æ—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        signals = await loop.run_in_executor(pool, run_worker)

    if signals:
        logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª—ë–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(signals)} –∑–∞–ø–∏—Å–µ–π")
    else:
        logger.info("‚ö†Ô∏è –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ—Å–ª–µ –æ—Ü–µ–Ω–∫–∏")



# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if __name__ == "__main__":
    DatabaseManager.init_schema_once()
    asyncio.run(main())



# run_tasks.py

import asyncio
import logging
from concurrent.futures import ThreadPoolExecutor

from services.identifier      import PairIdentifier
from services.collector       import DataCollector
from services.level_engine    import LevelAnalyzer
from services.indicator_engine import IndicatorEngine
from services.trend_engine    import TrendAnalyzer
from services.alert_engine    import AlertSystem
from services.deep_an         import MarketCapTracker
from database.database        import DatabaseManager

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def update_market_data():
    # ‚ë† —Å–ø–µ—Ä–≤–∞ –∑–∞–ø–æ–ª–Ω—è–µ–º pairs_cache
    await PairIdentifier().update_pairs_cache()

    # ‚ë° –∑–∞—Ç–µ–º —É–∂–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≤—Å—ë –æ—Å—Ç–∞–ª—å–Ω–æ–µ
    await asyncio.gather(
        # DerivativesEngine().update_metrics_for_all(),   # —Ç—Ä–µ–±—É–µ—Ç pairs_cache
        # SentimentEngine().update_for_all(),             #   ‚Äî//‚Äî
        DataCollector().update_all_timeframes(),        #   ‚Äî//‚Äî
        MarketCapTracker().fetch_total_market_cap(),
    )

def sync_tasks():
    """CPU-bound –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ –ø—É–ª–µ –ø–æ—Ç–æ–∫–æ–≤."""
    LevelAnalyzer().analyze_levels()
    IndicatorEngine().compute_indicators()
    TrendAnalyzer().analyze_trends()
    AlertSystem().check_alerts()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
async def main():
    logger.info("üöÄ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ä—ã–Ω–∫–∞ (–±–µ–∑ —Å–∏–≥–Ω–∞–ª–æ–≤)")
    DatabaseManager().clear_old_candles()

    # ‚ë† —Å–µ—Ç–µ–≤—ã–µ –∑–∞–¥–∞—á–∏
    await update_market_data()

    # ‚ë° —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ / —Ç—è–∂—ë–ª—ã–µ –∑–∞–¥–∞—á–∏
    loop = asyncio.get_running_loop()
    with ThreadPoolExecutor() as pool:
        await loop.run_in_executor(pool, sync_tasks)

    logger.info("‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã (–±–µ–∑ —Å–∏–≥–Ω–∞–ª–æ–≤)")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if __name__ == "__main__":
    asyncio.run(main())



# run_worker.py

import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
from services.worker import SignalWorker

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def main():
    logger.info("üìä –ó–∞–ø—É—Å–∫ –ø–µ—Ä–µ—Å—á—ë—Ç–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –ø–æ —Ç–µ–∫—É—â–∏–º –¥–∞–Ω–Ω—ã–º")
    loop = asyncio.get_running_loop()

    def run_signals():
        worker = SignalWorker()
        return worker.process_all_pairs()

    with ThreadPoolExecutor() as pool:
        results = await loop.run_in_executor(pool, run_signals)

    if results:
        logger.info(f"‚úÖ –°–∏–≥–Ω–∞–ª—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã: {len(results)}")
        for signal in results:
            logger.info(f"üü¢ {signal['symbol']} {signal['timeframe']} ‚Äî {signal['signal_type']} @ {signal['current_price']:.4f}")
    else:
        logger.info("‚ö†Ô∏è –ù–∏ –æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ –Ω–µ –ø—Ä–æ—à–ª–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")

if __name__ == "__main__":
    asyncio.run(main())



# gui/_init_.py





# gui/app.py

import tkinter as tk
from tkinter import ttk
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import subprocess
from gui.chart_drawer import ChartDrawer
from gui.indicators_drawer import IndicatorDrawer
from gui.tables_drawer import TableDrawer
from database.database import DatabaseManager
import logging
logger = logging.getLogger(__name__)


def create_main_window():
    def run_analysis():
        try:
            ttk.Label(control_frame, text="‚è≥ –ê–Ω–∞–ª–∏–∑...").pack(side=tk.LEFT, padx=5)
            subprocess.run(["python", "run_full.py"], check=True)
            update_chart()
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–Ω–∞–ª–∏–∑–∞: {e}")

    root = tk.Tk()
    root.title("Crypto Market")
    root.geometry("1500x900")

    db = DatabaseManager()
    symbols = db.get_symbols_from_cache()
    timeframes = ["1d", "4h", "1h", "15m"]

    chart_drawer = ChartDrawer()
    tables = TableDrawer(root)

    symbol_var = tk.StringVar()
    tf_var = tk.StringVar()
    show_levels = tk.BooleanVar(value=True)
    show_indicators = tk.BooleanVar(value=True)
    show_signals = tk.BooleanVar(value=True)
    show_trend = tk.BooleanVar(value=True)
    show_stochastic = tk.BooleanVar(value=False)
    show_fibo = tk.BooleanVar(value=False)

    control_frame = ttk.Frame(root)
    control_frame.pack(fill=tk.X, pady=10, padx=10)
    ttk.Checkbutton(control_frame, text="Stochastic", variable=show_stochastic, command=lambda: update_chart()).pack(
        side=tk.LEFT, padx=5)

    ttk.Label(control_frame, text="–ü–∞—Ä–∞:").pack(side=tk.LEFT)
    symbol_combo = ttk.Combobox(control_frame, textvariable=symbol_var, values=symbols, width=15)
    symbol_combo.pack(side=tk.LEFT, padx=5)

    ttk.Label(control_frame, text="–¢–∞–π–º—Ñ—Ä–µ–π–º:").pack(side=tk.LEFT, padx=(10, 0))
    tf_combo = ttk.Combobox(control_frame, textvariable=tf_var, values=timeframes, width=5)
    tf_combo.pack(side=tk.LEFT, padx=5)

    ttk.Checkbutton(control_frame, text="–£—Ä–æ–≤–Ω–∏", variable=show_levels, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã", variable=show_indicators, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="–°–∏–≥–Ω–∞–ª—ã", variable=show_signals, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="–¢—Ä–µ–Ω–¥", variable=show_trend, command=lambda: update_chart()).pack(side=tk.LEFT, padx=5)
    ttk.Checkbutton(control_frame, text="–§–∏–±–æ–Ω–∞—á—á–∏", variable=show_fibo, command=lambda: update_chart()).pack(
        side=tk.LEFT, padx=5)

    ttk.Button(control_frame, text="–û–±–Ω–æ–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫", command=lambda: update_chart()).pack(side=tk.LEFT, padx=10)
    ttk.Button(control_frame, text="–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑", command=run_analysis).pack(side=tk.LEFT, padx=10)
    ttk.Button(control_frame, text="–°–∏–≥–Ω–∞–ª—ã", command=lambda: tables.draw_signals_table(on_select=handle_select)).pack(side=tk.LEFT)
    ttk.Button(control_frame, text="–ê–ª–µ—Ä—Ç—ã", command=lambda: tables.draw_alerts_table(on_select=handle_select)).pack(side=tk.LEFT)
    ttk.Button(control_frame, text="–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É", command=lambda: db.truncate_all_tables() or update_chart()).pack(side=tk.RIGHT, padx=5)

    fig_frame = ttk.Frame(root)
    fig_frame.pack(fill=tk.BOTH, expand=True)

    fig_canvas = None


    def update_chart():
        nonlocal fig_canvas
        symbol = symbol_var.get()
        tf = tf_var.get()
        if not symbol or not tf:
            return

        fig, ax = chart_drawer.draw_candles(
            symbol,
            tf,
            show_levels=show_levels.get(),
            show_indicators=show_indicators.get(),
            show_signals=show_signals.get(),
            show_trend=show_trend.get(),
            show_stochastic = show_stochastic.get(),
            show_fibo = show_fibo.get()
        )
        if not fig:
            return

        for w in fig_frame.winfo_children():
            w.destroy()

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        control_btn_frame = tk.Frame(fig_frame)
        control_btn_frame.pack(side=tk.TOP, pady=5)

        tk.Button(control_btn_frame, text="<", width=3, command=chart_drawer.pan_left).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text=">", width=3, command=chart_drawer.pan_right).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text="+", width=3, command=chart_drawer.zoom_in).pack(side=tk.LEFT, padx=2)
        tk.Button(control_btn_frame, text="-", width=3, command=chart_drawer.zoom_out).pack(side=tk.LEFT, padx=2)

        fig_canvas = FigureCanvasTkAgg(fig, master=fig_frame)
        fig_canvas.draw()
        fig_canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)



    def handle_select(symbol, timeframe):
        symbol_combo.set(symbol)
        tf_combo.set(timeframe)
        root.after(100, update_chart)

    if symbols:
        symbol_var.set(symbols[0])
    tf_var.set("4h")
    update_chart()

    symbol_combo.bind("<<ComboboxSelected>>", lambda e: update_chart())
    tf_combo.bind("<<ComboboxSelected>>", lambda e: update_chart())

    return root



# gui/chart_drawer.py

# chart_drawer.py ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å —É—Ä–æ–≤–Ω—è–º–∏ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏/–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ —Å—Ç–æ—Ö–∞—Å—Ç–∏–∫–µ

import matplotlib.pyplot as plt
import pandas as pd
import mplfinance as mpf
import logging

from database.database import DatabaseManager
from gui.indicators_drawer import IndicatorDrawer
from gui.levels_drawer import LevelDrawer
from gui.signals_drawer import SignalDrawer
from gui.fibo_drawer import FiboDrawer

logger = logging.getLogger(__name__)


class ChartDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.fig = None
        self.ax = None

    def draw_candles(self, symbol, timeframe,
                     show_levels=True, show_indicators=True,
                     show_signals=True, show_trend=True,
                     show_stochastic=False, show_fibo=False):

        candles = self.db.get_candles(symbol, timeframe)
        if not candles:
            logger.warning(f"‚ùå –ù–µ—Ç —Å–≤–µ—á–µ–π –¥–ª—è {symbol} {timeframe}")
            return None, None

        df = pd.DataFrame(candles)
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df.set_index("date", inplace=True)
        df = df.sort_index()
        df.rename(columns={
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume"
        }, inplace=True)

        offset_hours = 10
        last_index = df.index[-1]
        future_index = pd.date_range(start=last_index, periods=offset_hours, freq="1h")
        df = df.reindex(df.index.union(future_index))

        apds = []
        drawer = IndicatorDrawer()

        if show_indicators:
            indicators = drawer.get_indicator_series(df)
            colors = drawer.colors
            for name, series in indicators.items():
                apds.append(mpf.make_addplot(series, color=colors.get(name, "gray"),
                                             width=1.2, linestyle="-" if "EMA" in name else "--"))

        if show_levels:
            levels = self.db.get_levels()
            levels = [lvl for lvl in levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]
            for lvl in levels:
                line = pd.Series(lvl["price"], index=df.index)
                apds.append(mpf.make_addplot(line,
                                             color=LevelDrawer().colors.get(lvl["type"], "gray"),
                                             linestyle="--", width=2))

        if show_signals:
            sig_drawer = SignalDrawer()
            df_signals = sig_drawer.get_signal_points(symbol, timeframe, df.index)

            if not df_signals.empty:
                long_series = pd.Series(index=df.index, dtype=float)
                short_series = pd.Series(index=df.index, dtype=float)

                for i, row in df_signals.iterrows():
                    if row["type"] == "long":
                        long_series.at[i] = row["price"]
                    elif row["type"] == "short":
                        short_series.at[i] = row["price"]

                if not long_series.dropna().empty:
                    apds.append(mpf.make_addplot(long_series, type='scatter', marker='^',
                                                 markersize=100, color='green'))
                if not short_series.dropna().empty:
                    apds.append(mpf.make_addplot(short_series, type='scatter', marker='v',
                                                 markersize=100, color='red'))

        if show_stochastic:
            k, d = drawer._stochastic(df)
            apds.append(mpf.make_addplot(k, panel=1, color='blue', ylabel='Stoch'))
            apds.append(mpf.make_addplot(d, panel=1, color='orange'))

            # –î–æ–±–∞–≤–∏–º —É—Ä–æ–≤–Ω–∏ –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏
            overbought = pd.Series(80, index=df.index)
            oversold = pd.Series(20, index=df.index)
            apds.append(mpf.make_addplot(overbought, panel=1, color='green', linestyle='--'))
            apds.append(mpf.make_addplot(oversold, panel=1, color='red', linestyle='--'))

        if show_fibo:
            fibo_drawer = FiboDrawer()
            fibo_drawer.draw_fibo(apds, df, symbol, timeframe)

        self.fig, axes = mpf.plot(
            df,
            type='candle',
            addplot=apds,
            returnfig=True,
            panel_ratios=(8, 2) if show_stochastic else (1,),
            volume=False,
            figsize=(20, 10),
            xrotation=20,
            tight_layout=True,  # –¥–æ–±–∞–≤–∏–º –∞–≤—Ç–æ-—É–ø–ª–æ—Ç–Ω–µ–Ω–∏–µ
            # style="yahoo"  # –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è —Ç–µ–º–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è
        )

        self.ax = axes[0] if isinstance(axes, list) else axes

        if show_fibo:
            fibo_drawer.draw_fibo_labels(df, symbol, timeframe, ax=self.ax)

        if show_trend:
            self._draw_trend_box(self.ax, symbol)


        return self.fig, self.ax

    def _draw_trend_box(self, ax, symbol):
        trend_data = self.db.get_trend(symbol)
        if not trend_data:
            return

        trend = trend_data.get("direction", "").upper()
        color = "green" if trend == "BULLISH" else "red"
        text = f"Trend: {trend}"

        ax.text(
            0.99, 0.99, text,
            transform=ax.transAxes,
            fontsize=10,
            color="white",
            bbox=dict(facecolor=color, alpha=0.7, boxstyle="round,pad=0.3"),
            horizontalalignment='right',
            verticalalignment='top'
        )

    def pan_left(self):
        if not self.ax: return
        dx = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.1
        self.ax.set_xlim(self.ax.get_xlim()[0] - dx, self.ax.get_xlim()[1] - dx)
        self.fig.canvas.draw_idle()

    def pan_right(self):
        if not self.ax: return
        dx = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.1
        self.ax.set_xlim(self.ax.get_xlim()[0] + dx, self.ax.get_xlim()[1] + dx)
        self.fig.canvas.draw_idle()

    def zoom_in(self):
        if not self.ax: return
        center = sum(self.ax.get_xlim()) / 2
        width = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 0.8
        self.ax.set_xlim(center - width / 2, center + width / 2)
        self.fig.canvas.draw_idle()

    def zoom_out(self):
        if not self.ax: return
        center = sum(self.ax.get_xlim()) / 2
        width = (self.ax.get_xlim()[1] - self.ax.get_xlim()[0]) * 1.2
        self.ax.set_xlim(center - width / 2, center + width / 2)
        self.fig.canvas.draw_idle()



# gui/fibo_drawer.py

import logging
import pandas as pd
import mplfinance as mpf
from services.fibo_engine import FiboEngine

logger = logging.getLogger(__name__)

class FiboDrawer:
    def __init__(self):
        self.fibo_engine = FiboEngine()  # 1 —Ä–∞–∑ —Å–æ–∑–¥–∞—ë–º

    def draw_fibo(self, apds, df, symbol, timeframe):
        try:
            fibo_data = self.fibo_engine.calculate_for_pair(symbol, timeframe)
            if not fibo_data:
                return

            for level_val in fibo_data["fibo_levels"].values():
                line = pd.Series(level_val, index=df.index)
                apds.append(mpf.make_addplot(
                    line,
                    color="purple",
                    linestyle="--",
                    width=1.5
                ))

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –§–∏–±–æ–Ω–∞—á—á–∏: {e}")

    def draw_fibo_labels(self, df, symbol, timeframe, ax):
        try:
            fibo_data = self.fibo_engine.calculate_for_pair(symbol, timeframe)
            if not fibo_data:
                return

            levels = fibo_data["fibo_levels"]
            x_pos = df.index[-1]

            for level_name, level_val in levels.items():
                ax.text(
                    x_pos,
                    level_val,
                    f"{level_name:.3f}",
                    color="purple",
                    fontsize=8,
                    verticalalignment="bottom",
                    horizontalalignment="right",
                    alpha=0.7
                )
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π –§–∏–±–æ–Ω–∞—á—á–∏: {e}")



# gui/indicators_drawer.py

import pandas as pd
import logging
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class IndicatorDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.colors = {
            "EMA20": "#FFD54F",
            "EMA50": "#64B5F6",
            "EMA200": "#AB47BC",
            "BB_UPPER": "#FF5252",
            "BB_LOWER": "#448AFF"
        }

    def get_indicators_data(self, symbol, timeframe):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è"""
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            return None

        df = pd.DataFrame(candles)
        df["close"] = pd.to_numeric(df["close"], errors="coerce")
        df = df.dropna(subset=["close"])

        if df.empty:
            return None

        try:
            # –í—ã—á–∏—Å–ª—è–µ–º –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            ema20 = df["close"].ewm(span=20, adjust=False).mean()
            ema50 = df["close"].ewm(span=50, adjust=False).mean()
            ema200 = df["close"].ewm(span=200, adjust=False).mean()

            bb_mid = df["close"].rolling(window=20).mean()
            bb_std = df["close"].rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫
            all_values = []
            all_values.extend(ema20.dropna().tolist())
            all_values.extend(ema50.dropna().tolist())
            all_values.extend(ema200.dropna().tolist())
            all_values.extend(bb_upper.dropna().tolist())
            all_values.extend(bb_lower.dropna().tolist())

            return all_values
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return None

    def get_indicator_series(self, df):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å Series –¥–ª—è make_addplot"""
        try:
            close = pd.to_numeric(df["Close"], errors="coerce")
            ema20 = close.ewm(span=20, adjust=False).mean()
            ema50 = close.ewm(span=50, adjust=False).mean()
            ema200 = close.ewm(span=200, adjust=False).mean()

            bb_mid = close.rolling(window=20).mean()
            bb_std = close.rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            return {
                "EMA20": ema20,
                "EMA50": ema50,
                "EMA200": ema200,
                "BB_UPPER": bb_upper,
                "BB_LOWER": bb_lower
            }
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ get_indicator_series: {e}")
            return {}

    def draw_indicators(self, ax, symbol, timeframe):
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            logger.warning(f"üìâ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ {symbol} {timeframe}")
            return

        df = pd.DataFrame(candles)
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df.set_index("date", inplace=True)
        df.sort_index(inplace=True)

        df = df[df["close"].notnull()]
        if df.empty:
            logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –ø—Ä–∏–≥–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (close) –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ {symbol}")
            return

        try:
            close = pd.to_numeric(df["close"], errors="coerce")
            ema20 = close.ewm(span=20, adjust=False).mean()
            ema50 = close.ewm(span=50, adjust=False).mean()
            ema200 = close.ewm(span=200, adjust=False).mean()

            bb_mid = close.rolling(window=20).mean()
            bb_std = close.rolling(window=20).std()
            bb_upper = bb_mid + 2 * bb_std
            bb_lower = bb_mid - 2 * bb_std

            df_ind = pd.DataFrame({
                "ema20": ema20,
                "ema50": ema50,
                "ema200": ema200,
                "bb_upper": bb_upper,
                "bb_lower": bb_lower
            }, index=df.index).dropna()

            if df_ind.empty:
                logger.warning(f"‚ö†Ô∏è –í—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ dropna –¥–ª—è {symbol}")
                return

            # –û—Ç–ª–∞–¥–∫–∞
            logger.debug(f"üìä –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è {symbol}: —Ç–æ—á–µ–∫={len(df_ind)}")
            logger.debug(f"EMA20 min={df_ind['ema20'].min()}, max={df_ind['ema20'].max()}")

            ax.plot(df_ind.index, df_ind["ema20"], label="EMA20", color=self.colors["EMA20"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["ema50"], label="EMA50", color=self.colors["EMA50"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["ema200"], label="EMA200", color=self.colors["EMA200"], linewidth=1.2, alpha=0.6)
            ax.plot(df_ind.index, df_ind["bb_upper"], linestyle="--", color=self.colors["BB_UPPER"], label="BB Upper", alpha=0.3)
            ax.plot(df_ind.index, df_ind["bb_lower"], linestyle="--", color=self.colors["BB_LOWER"], label="BB Lower", alpha=0.3)

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –æ—Ç—Ä–∏—Å–æ–≤–∫–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è {symbol}: {e}")

    def draw_stochastic(self, fig, df):
        from matplotlib.gridspec import GridSpec

        k, d = self._stochastic(df)
        if k.isnull().all() or d.isnull().all():
            return

        gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.05)
        ax_main = fig.axes[0]
        ax_stoch = fig.add_subplot(gs[1], sharex=ax_main)

        ax_stoch.plot(df.index, k, label="%K", color="blue", linewidth=1)
        ax_stoch.plot(df.index, d, label="%D", color="orange", linewidth=1)
        ax_stoch.axhline(80, color="green", linestyle="--", alpha=0.4)
        ax_stoch.axhline(20, color="red", linestyle="--", alpha=0.4)
        ax_stoch.set_ylim(0, 100)
        ax_stoch.set_yticks([0, 20, 50, 80, 100])
        ax_stoch.set_ylabel("Stoch")
        ax_stoch.legend(loc="upper left", fontsize=8)

    def _stochastic(self, df, k_period=14, d_period=3):
        low_min = df["Low"].rolling(window=k_period).min()
        high_max = df["High"].rolling(window=k_period).max()
        k = 100 * (df["Close"] - low_min) / (high_max - low_min)
        d = k.rolling(window=d_period).mean()
        return k, d



# gui/levels_drawer.py

import logging
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class LevelDrawer:
    def __init__(self):
        self.db = DatabaseManager()
        self.colors = {
            "support": "#00C853",
            "resistance": "#FF6D00",
            "ema50": "#1E88E5",
            "ema200": "#9C27B0",
        }

    def draw_levels(self, ax, symbol, timeframe):
        levels = self.db.get_levels()
        levels = [lvl for lvl in levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]

        for level in levels:
            y = float(level["price"])
            t = level["type"]
            color = self.colors.get(t, "gray")
            strength = level.get("strength", 1)
            touched = level.get("touched", 0)
            broken = level.get("broken", False)

            linestyle = ":" if broken else "--" if touched < 2 else "-"
            linewidth = max(1, min(4, strength))

            ax.axhline(y=y, color=color, linestyle=linestyle, linewidth=linewidth, alpha=0.8, clip_on=True)

            try:
                ax.text(
                    ax.get_xlim()[0], y,
                    f"{y:.4f}",
                    fontsize=8,
                    color=color,
                    verticalalignment="bottom",
                    horizontalalignment="right"
                )
            except:
                continue



# gui/main_layout.py

import tkinter as tk
from tkinter import ttk


class MainLayout:
    def __init__(self, root, symbols, timeframes):
        self.root = root
        self.symbols = symbols
        self.timeframes = timeframes

        # State variables
        self.symbol_var = tk.StringVar()
        self.tf_var = tk.StringVar()
        self.show_levels = tk.BooleanVar(value=True)
        self.show_indicators = tk.BooleanVar(value=True)
        self.show_signals = tk.BooleanVar(value=True)

        # Placeholders for callbacks
        self.on_update = None
        self.on_signals = None
        self.on_alerts = None
        self.on_clear_db = None

        self.control_frame = ttk.Frame(root)
        self.control_frame.pack(fill=tk.X, pady=10, padx=10)

        self._create_controls()

        self.chart_frame = ttk.Frame(root)
        self.chart_frame.pack(fill=tk.BOTH, expand=True)

    def _create_controls(self):
        ttk.Label(self.control_frame, text="–ü–∞—Ä–∞:").pack(side=tk.LEFT)
        self.symbol_combo = ttk.Combobox(self.control_frame, textvariable=self.symbol_var, values=self.symbols, width=15)
        self.symbol_combo.pack(side=tk.LEFT, padx=5)

        ttk.Label(self.control_frame, text="–¢–∞–π–º—Ñ—Ä–µ–π–º:").pack(side=tk.LEFT, padx=(10, 0))
        self.tf_combo = ttk.Combobox(self.control_frame, textvariable=self.tf_var, values=self.timeframes, width=5)
        self.tf_combo.pack(side=tk.LEFT, padx=5)

        # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª–∏
        ttk.Checkbutton(self.control_frame, text="–£—Ä–æ–≤–Ω–∏", variable=self.show_levels).pack(side=tk.LEFT, padx=5)
        ttk.Checkbutton(self.control_frame, text="–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã", variable=self.show_indicators).pack(side=tk.LEFT, padx=5)
        ttk.Checkbutton(self.control_frame, text="–°–∏–≥–Ω–∞–ª—ã", variable=self.show_signals).pack(side=tk.LEFT, padx=5)

        # –ö–Ω–æ–ø–∫–∏
        ttk.Button(self.control_frame, text="–û–±–Ω–æ–≤–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫", command=self._call_update).pack(side=tk.LEFT, padx=10)
        ttk.Button(self.control_frame, text="–°–∏–≥–Ω–∞–ª—ã", command=self._call_signals).pack(side=tk.LEFT)
        ttk.Button(self.control_frame, text="–ê–ª–µ—Ä—Ç—ã", command=self._call_alerts).pack(side=tk.LEFT)
        ttk.Button(self.control_frame, text="–û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É", command=self._call_clear_db).pack(side=tk.RIGHT, padx=5)

    # --- Callback proxies ---
    def _call_update(self):
        if self.on_update:
            self.on_update()

    def _call_signals(self):
        if self.on_signals:
            self.on_signals()

    def _call_alerts(self):
        if self.on_alerts:
            self.on_alerts()

    def _call_clear_db(self):
        if self.on_clear_db:
            self.on_clear_db()



# gui/signals_drawer.py

import logging
import pandas as pd
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class SignalDrawer:
    def __init__(self):
        self.db = DatabaseManager()

    def get_signal_points(self, symbol, timeframe, index_range):
        try:
            conn = self.db.get_connection()
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT signal_type, price, time
                    FROM signals
                    WHERE symbol = %s AND timeframe = %s
                    ORDER BY time DESC
                    LIMIT 50
                """, (symbol, timeframe))
                signals = cur.fetchall()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")
            return pd.DataFrame()
        finally:
            self.db.release_connection(conn)

        if not signals:
            return pd.DataFrame()

        df = pd.DataFrame(signals, columns=["type", "price", "time"])
        df["date"] = pd.to_datetime(df["time"], unit="ms")
        df = df.set_index("date").sort_index()

        df = df[df.index.isin(index_range)]

        return df



# gui/tables_drawer.py

import tkinter as tk
from tkinter import ttk, messagebox
import logging
from datetime import datetime
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

class TableDrawer:
    def __init__(self, master):
        self.signals_map = {}
        self.master = master
        self.db = DatabaseManager()

    def draw_signals_table(self, on_select=None):
        win = tk.Toplevel(self.master)
        win.title("–°–∏–≥–Ω–∞–ª—ã")
        win.geometry("1200x600")

        # ‚ë† —Å–ø–∏—Å–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ (–¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
        self.columns = [
            "symbol", "timeframe", "signal_type", "current_price",
            "recommendation", "score", "created_at",
            "rsi", "macd", "stoch_k", "stoch_d",
            "atr", "adx", "oi", "fund_rate",
            "supertrend", "vwap", "poc", "sentiment",
            "details"                                     # –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
        ]

        # ‚ë° –æ–±—ë—Ä—Ç–∫–∞ + scrollbar
        frame = tk.Frame(win); frame.pack(fill=tk.BOTH, expand=True)
        xscroll = tk.Scrollbar(frame, orient=tk.HORIZONTAL)
        xscroll.pack(side=tk.BOTTOM, fill=tk.X)

        # ‚ë¢ —Å–æ–∑–¥–∞—ë–º Treeview –î–û –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
        self.tree = ttk.Treeview(frame,
                                 columns=self.columns,
                                 show="headings",
                                 xscrollcommand=xscroll.set)
        self.tree.pack(fill=tk.BOTH, expand=True)
        xscroll.config(command=self.tree.xview)

        # ‚ë£ –∑–∞–≥–æ–ª–æ–≤–∫–∏ / —à–∏—Ä–∏–Ω—ã
        for col in self.columns:
            self.tree.heading(col, text=col.upper(),
                              command=lambda c=col: self.sort_by_column(c, False))
            self.tree.column(col, anchor="w", width=140, stretch=True)

        ttk.Button(win, text="–û–±–Ω–æ–≤–∏—Ç—å",
                   command=self._refresh_signals).pack(pady=5)

        # ‚ë§ callbacks
        if on_select:
            self.tree.bind("<<TreeviewSelect>>",
                           lambda e: self._handle_select(on_select))
        self.tree.bind("<Double-1>", self._on_double_click)

        self._refresh_signals()   # –ø–µ—Ä–≤–∞—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∞

    # ------------ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã -----------------------------
    def _refresh_signals(self):
        for row in self.tree.get_children():
            self.tree.delete(row)

        try:
            for rec in self.db.get_signals():
                key = (rec["symbol"], rec["timeframe"], rec["signal_type"])
                self.signals_map[key] = rec["details"]

                # –ø–æ—Ä—è–¥–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π —Å—Ç—Ä–æ–≥–æ = self.columns
                self.tree.insert("", "end", values=[
                    rec.get("symbol"),
                    rec.get("timeframe"),
                    rec.get("signal_type"),
                    float(rec.get("current_price", 0)),
                    rec.get("recommendation"),
                    float(rec.get("score", 0)),
                    datetime.fromtimestamp(rec["created_at"]).strftime("%Y-%m-%d %H:%M"),
                    round(rec.get("rsi", 0), 1)   if rec.get("rsi") else "",
                    round(rec.get("macd", 0), 4)  if rec.get("macd") else "",
                    round(rec.get("stoch_k", 0), 1) if rec.get("stoch_k") else "",
                    round(rec.get("stoch_d", 0), 1) if rec.get("stoch_d") else "",
                    round(rec.get("atr", 0), 6)  if rec.get("atr") else "",
                    round(rec.get("adx", 0), 1)  if rec.get("adx") else "",
                    round(rec.get("oi", 0))      if rec.get("oi") else "",
                    round(rec.get("fund_rate", 0), 6) if rec.get("fund_rate") else "",
                    rec.get("supertrend"),
                    round(rec.get("vwap", 0), 6) if rec.get("vwap") else "",
                    round(rec.get("poc", 0), 6)  if rec.get("poc") else "",
                    round(rec.get("sentiment", 0), 1) if rec.get("sentiment") else "",
                    "‚Ä¶"           # details –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –æ–∫–Ω–µ; –∑–¥–µ—Å—å placeholder
                ])
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–∏–≥–Ω–∞–ª–æ–≤: {e}")

    # ------------ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ -------------------------------------
    def sort_by_column(self, col, reverse):
        data = [(self.tree.set(k, col), k) for k in self.tree.get_children("")]
        try:
            data.sort(key=lambda t: float(t[0]), reverse=reverse)
        except ValueError:
            data.sort(key=lambda t: str(t[0]), reverse=reverse)

        for idx, (_, k) in enumerate(data):
            self.tree.move(k, "", idx)

        self.tree.heading(col,
                          command=lambda: self.sort_by_column(col, not reverse))

    # ------------ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ callbacks ----------------------
    def _handle_select(self, on_select):
        sel = self.tree.selection()
        if sel:
            vals = self.tree.item(sel[0])["values"]
            on_select(vals[0], vals[1])       # symbol, timeframe

    def _on_double_click(self, _event):
        sel = self.tree.selection()
        if not sel:
            return
        vals = self.tree.item(sel[0], "values")
        key  = (vals[0], vals[1], vals[2])    # symbol, timeframe, type
        details = self.signals_map.get(key, [])
        if isinstance(details, str):
            import ast
            try: details = ast.literal_eval(details)
            except: pass

        top = tk.Toplevel(self.tree)
        top.title(f"–î–µ—Ç–∞–ª–∏ —Å–∏–≥–Ω–∞–ª–∞: {vals[0]} ({vals[1]})")
        txt = tk.Text(top, wrap=tk.WORD)
        txt.insert(tk.END,
                   "\n".join(details) if isinstance(details, list) else str(details))
        txt.config(state=tk.NORMAL)
        txt.pack(expand=True, fill=tk.BOTH)
        tk.Button(top, text="–ó–∞–∫—Ä—ã—Ç—å", command=top.destroy).pack(pady=5)



# ai/_init_.py





# strategies/_init_.py





# strategies/risk_profiles.py





# config/_init_.py





# config/constants.py

import os

# config/constants.py (–¥–æ–±–∞–≤—å)
BINANCE_TICKER_URL = "https://api.binance.com/api/v3/ticker/24hr"

DB_CONFIG = {
    "dbname": os.getenv("DB_NAME", "postgres"),
    "user": os.getenv("DB_USER", "postgres"),
    "password": os.getenv("DB_PASSWORD", "123"),
    "host": os.getenv("DB_HOST", "localhost"),
    "port": os.getenv("DB_PORT", "5432"),
}

CANDLE_SETTINGS = {
    "1d": {"interval": "1d", "limit": 900, "update_freq": 86400},
    "4h": {"interval": "4h", "limit": 800, "update_freq": 14400},
    "1h": {"interval": "1h", "limit": 700, "update_freq": 3600},
    "15m": {"interval": "15m", "limit": 500, "update_freq": 900},
}



# config/settings.py

class Settings:
    def __init__(self):
        self.exchange = "Binance"
        self.api_key = ""
        self.api_secret = ""
        self.leverage = 1
        self.stop_loss = 0.0
        self.take_profit = 0.0



# database/_init_.py





# database/database.py

import os
import logging
import psycopg2
from psycopg2 import pool
from datetime import datetime, timedelta
from psycopg2.extras import execute_values
import json
import numpy as np
from datetime import datetime
import time
import re
MAX_CONN = 50

from config.constants import DB_CONFIG  # —Ç–µ–ø–µ—Ä—å —Ç–∞–∫

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



class DatabaseManager:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, "_initialized"):
            return
        self._initialized = True

        self.db_config = {
            'dbname': os.getenv('DB_NAME', 'postgres'),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', '123'),
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', '5432')
        }

        self.connection_pool = psycopg2.pool.ThreadedConnectionPool(
            minconn=10,
            maxconn=30,
            **self.db_config
        )

        logger.debug("‚úÖ –£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î")

    @classmethod
    def init_schema_once(cls):
        instance = cls()
        instance._create_tables()
        instance._create_indexes()
        logger.info("‚úÖ –ë–∞–∑–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –æ–¥–∏–Ω —Ä–∞–∑")
        return instance
        # –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã
        self._create_tables()
        self._create_indexes()
        logger.info("–¢–∞–±–ª–∏—Ü—ã —Å–æ–∑–¥–∞–Ω—ã/–ø—Ä–æ–≤–µ—Ä–µ–Ω—ã")

    def get_connection(self):
        return self.connection_pool.getconn()

    def release_connection(self, conn):
        self.connection_pool.putconn(conn)

    def _create_tables(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü, –æ—á–∏—Å—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –∫–æ–Ω—Ü–µ"""
        # --- –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ç–∞–±–ª–∏—Ü ---
        start_time = time.time()
        ddl_queries = [
            # –¢–∞–±–ª–∏—Ü–∞ collected_candles
            """
            CREATE TABLE IF NOT EXISTS collected_candles (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                candles JSONB NOT NULL,
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE (symbol, timeframe)
            );
            """,

            # –¢–∞–±–ª–∏—Ü–∞ levels
            """
            CREATE TABLE IF NOT EXISTS levels (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                price DECIMAL(20,8) NOT NULL,
                type VARCHAR(10) NOT NULL,
                strength INT NOT NULL,
                upper DECIMAL(20,8),
                lower DECIMAL(20,8),
                distance DECIMAL(10,4),
                touched INT DEFAULT 0,
                broken BOOLEAN DEFAULT FALSE,
                last_touched TIMESTAMP,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # –¢–∞–±–ª–∏—Ü–∞ alerts
            """
            CREATE TABLE IF NOT EXISTS alerts (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20),
                level_price DECIMAL(20,8),
                current_price DECIMAL(20,8),
                type VARCHAR(20),
                distance DECIMAL(10,4),
                strength INT,
                timeframe VARCHAR(10),
                source VARCHAR(20),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE alerts
            ADD COLUMN IF NOT EXISTS source VARCHAR(20);
            """,

            # –¢–∞–±–ª–∏—Ü–∞ pairs_cache
            """
            CREATE TABLE IF NOT EXISTS pairs_cache (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                volume DECIMAL(20,8) NOT NULL,
                first_seen TIMESTAMP,
                last_seen TIMESTAMP,
                missing_periods INT DEFAULT 0
            );
            """,

            # –¢–∞–±–ª–∏—Ü–∞ trend_cache
            """
            CREATE TABLE IF NOT EXISTS trend_cache (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL UNIQUE,
                direction VARCHAR(10) NOT NULL,
                ema50 DECIMAL(20,8),
                ema200 DECIMAL(20,8),
                last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # –¢–∞–±–ª–∏—Ü–∞ indicators
            """
            CREATE TABLE IF NOT EXISTS indicators (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                indicator_type VARCHAR(20) NOT NULL,
                value DECIMAL(20,8),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE IF EXISTS indicators
            ALTER COLUMN value TYPE VARCHAR(50)
            USING value::VARCHAR(50);
            """,
            # –í –º–µ—Ç–æ–¥ _create_tables, –≤ —Å–ø–∏—Å–æ–∫ ddl_queries –¥–æ–±–∞–≤—å—Ç–µ:
            """
            CREATE TABLE IF NOT EXISTS market_cap (
                id SERIAL PRIMARY KEY,
                total_cap DECIMAL(20,2) NOT NULL,
                fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,

            # –¢–∞–±–ª–∏—Ü–∞ signals
            """
            CREATE TABLE IF NOT EXISTS signals (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(20) NOT NULL,
                timeframe VARCHAR(5) NOT NULL,
                signal_type VARCHAR(10) NOT NULL,
                price DECIMAL(20,8) NOT NULL,
                time BIGINT NOT NULL,
                indicator VARCHAR(50),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """,
            """
            ALTER TABLE signals
            ADD COLUMN IF NOT EXISTS score INT,
            ADD COLUMN IF NOT EXISTS details TEXT,
            ADD COLUMN IF NOT EXISTS recommendation VARCHAR(50),
            ADD COLUMN IF NOT EXISTS current_price DECIMAL(20,8),
            ADD COLUMN IF NOT EXISTS rsi DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS macd DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS ema50 DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS ema200 DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS bb_position DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS stoch_k DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS stoch_d DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS atr DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS adx DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS vwap DOUBLE PRECISION,
            ADD COLUMN IF NOT EXISTS poc DOUBLE PRECISION;

            """,
        ]

        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for i, query in enumerate(ddl_queries):
                    table_name = self._extract_table_name(query)
                    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    logger.info(f"[{timestamp}] ‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
                    cur.execute(query)
            conn.commit()
            duration = round(time.time() - start_time, 2)
            logger.info(
                f"[{datetime.now().strftime('%H:%M:%S')}] ‚úÖ –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(ddl_queries)} —Ç–∞–±–ª–∏—Ü –∑–∞ {duration} —Å–µ–∫.")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç–∞–±–ª–∏—Ü: {e}", exc_info=True)
            conn.rollback()
        finally:
            self.release_connection(conn)

    def _extract_table_name(self, query: str) -> str:
        import re
        match = re.search(r"(CREATE|ALTER)\s+TABLE(?: IF NOT EXISTS)?\s+(\w+)", query, re.IGNORECASE)
        return match.group(2) if match else "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    def _create_indexes(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_candles_symbol_timeframe ON collected_candles (symbol, timeframe);",
            "CREATE INDEX IF NOT EXISTS idx_candles_last_updated ON collected_candles (last_updated);",
            "CREATE INDEX IF NOT EXISTS idx_levels_symbol_timeframe ON levels (symbol, timeframe);",
            "CREATE UNIQUE INDEX IF NOT EXISTS idx_signals_unique ON signals (symbol, timeframe, signal_type, time);"
            "CREATE INDEX IF NOT EXISTS idx_levels_price ON levels (price);"
            "CREATE INDEX IF NOT EXISTS idx_indicators_sym_tf ON indicators(symbol, timeframe);"
        ]
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for idx in indexes:
                    cur.execute(idx)
            conn.commit()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def upsert_candles(self, symbol, timeframe, new_candles):
        logger.debug(f"üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–µ–π {symbol} {timeframe}")
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Å–≤–µ—á–∏
                cur.execute("""
                            SELECT candles
                            FROM collected_candles
                            WHERE symbol = %s
                              AND timeframe = %s
                            """, (symbol, timeframe))
                result = cur.fetchone()
                # –£–±–∏—Ä–∞–µ–º json.loads, —Ç–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω—ã
                current_candles = result[0] if result else []
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π
                existing_times = {candle['time'] for candle in current_candles}
                filtered_new = [
                    candle for candle in new_candles
                    if candle['time'] not in existing_times
                ]
                if not filtered_new:
                    logger.debug("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è")
                    return len(current_candles)
                # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
                merged = current_candles + filtered_new
                merged.sort(key=lambda x: x['time'])
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
                max_candles = {
                    '1d': 900,
                    '4h': 800,
                    '1h': 700,
                    '15m': 500
                }.get(timeframe, 500)
                if len(merged) > max_candles:
                    merged = merged[-max_candles:]
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–ª–∏ –≤—Å—Ç–∞–≤–∫–∞
                if result:
                    cur.execute("""
                                UPDATE collected_candles
                                SET candles      = %s,
                                    last_updated = CURRENT_TIMESTAMP
                                WHERE symbol = %s
                                  AND timeframe = %s
                                """, (json.dumps(merged), symbol, timeframe))
                else:
                    cur.execute("""
                                INSERT INTO collected_candles (symbol, timeframe, candles)
                                VALUES (%s, %s, %s)
                                """, (symbol, timeframe, json.dumps(merged)))
                conn.commit()
                return len(merged)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–≤–µ—á–µ–π {symbol} {timeframe}: {e}", exc_info=True)
            conn.rollback()
            return 0
        finally:
            self.release_connection(conn)

    def get_candles(self, symbol, timeframe):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤–µ—á–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—ã –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                            SELECT candles
                            FROM collected_candles
                            WHERE symbol = %s
                              AND timeframe = %s
                            """, (symbol, timeframe))
                result = cur.fetchone()
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–∞–ø—Ä—è–º—É—é
                return result[0] if result else []
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ—á–µ–π {symbol} {timeframe}: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_all_candles(self, timeframe=None):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–≤–µ—á–µ–π (–ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º)"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                if timeframe:
                    cur.execute("""
                                SELECT symbol, timeframe, candles
                                FROM collected_candles
                                WHERE timeframe = %s
                                """, (timeframe,))
                else:
                    cur.execute("SELECT symbol, timeframe, candles FROM collected_candles")
                result = cur.fetchall()
                # –£–±–∏—Ä–∞–µ–º json.loads, —Ç–∞–∫ –∫–∞–∫ –¥–∞–Ω–Ω—ã–µ —É–∂–µ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω—ã
                return {(row[0], row[1]): row[2] for row in result}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Å–≤–µ—á–µ–π: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def clear_old_candles(self):
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö —Å–≤–µ—á–µ–π —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç NULL"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # –û—á–∏—â–∞–µ–º 1d —Å—Ç–∞—Ä—à–µ 3 –º–µ—Å—è—Ü–µ–≤
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '3 months') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe = '1d'
                """)

                # –û—á–∏—â–∞–µ–º 4h –∏ 1h —Å—Ç–∞—Ä—à–µ 1 –º–µ—Å—è—Ü–∞
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '1 month') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe IN ('4h', '1h')
                """)

                # –û—á–∏—â–∞–µ–º 15m —Å—Ç–∞—Ä—à–µ 2 –Ω–µ–¥–µ–ª—å
                cur.execute("""
                    UPDATE collected_candles
                    SET candles = COALESCE((
                        SELECT jsonb_agg(c)
                        FROM jsonb_array_elements(candles) AS c
                        WHERE (c ->> 'time')::BIGINT > EXTRACT(EPOCH FROM NOW() - INTERVAL '2 weeks') * 1000
                    ), '[]'::jsonb)
                    WHERE timeframe = '15m'
                """)

            conn.commit()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Å–≤–µ—á–µ–π: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def save_levels(self, levels):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –≤ –ë–î"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —É—Ä–æ–≤–Ω–∏
                cur.execute("DELETE FROM levels")
                # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ
                insert_query = """
                               INSERT INTO levels
                               (symbol, timeframe, price, type, strength,
                                upper, lower, distance, touched, broken, last_touched)
                               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) \
                               """
                for level in levels:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy.float64 –≤ float
                    price = float(level['price'])
                    distance = float(level.get('distance', 0.0))  # –î–æ–±–∞–≤–∏—Ç—å
                    cur.execute(insert_query, (
                        level['symbol'],
                        level['timeframe'],
                        price,
                        level['type'],
                        int(level['strength']),
                        float(level.get('upper')) if level.get('upper') else None,
                        float(level.get('lower')) if level.get('lower') else None,
                        distance,  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
                        int(level.get('touched', 0)),
                        bool(level.get('broken', False)),
                        datetime.fromtimestamp(level['last_touched']) if level.get('last_touched') else None
                    ))
                conn.commit()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_levels(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω–µ–π –∏–∑ –ë–î"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT * FROM levels")
                columns = [desc[0] for desc in cur.description]
                return [dict(zip(columns, row)) for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É—Ä–æ–≤–Ω–µ–π: {e}")
            return []
        finally:
            self.release_connection(conn)

    def _get_unique_symbols(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä –∏–∑ –ë–î"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                cur.execute("SELECT DISTINCT symbol FROM collected_candles")
                symbols = [row[0] for row in cur.fetchall()]
                return symbols
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_symbols_from_cache(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—Ä–≥–æ–≤—ã—Ö –ø–∞—Ä –∏–∑ –∫—ç—à–∞"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                cur.execute("SELECT symbol FROM pairs_cache")
                return [row[0] for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä –∏–∑ –∫—ç—à–∞: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_all_trends(self):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("SELECT symbol, direction, ema50, ema200 FROM trend_cache")
                rows = cur.fetchall()
                return [
                    {"symbol": row[0], "direction": row[1], "ema50": float(row[2]), "ema200": float(row[3])}
                    for row in rows
                ]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            return []
        finally:
            self.release_connection(conn)

    def get_trend(self, symbol: str):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT direction, ema50, ema200
                    FROM trend_cache
                    WHERE symbol = %s
                    ORDER BY last_updated DESC
                    LIMIT 1
                """, (symbol,))
                row = cur.fetchone()
                if row:
                    return {
                        "direction": row[0],
                        "ema50": float(row[1]),
                        "ema200": float(row[2])
                    }
                return {}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞ –¥–ª—è {symbol}: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def save_trends(self, trends):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ –≤ –ë–î"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º UPSERT –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–ª–∏ –≤—Å—Ç–∞–≤–∫–∏
                insert_query = """
                               INSERT INTO trend_cache (symbol, direction, ema50, ema200, last_updated)
                               VALUES (%s, %s, %s, %s, TO_TIMESTAMP(%s)) ON CONFLICT (symbol)
                    DO \
                               UPDATE SET
                                   direction = EXCLUDED.direction, \
                                   ema50 = EXCLUDED.ema50, \
                                   ema200 = EXCLUDED.ema200, \
                                   last_updated = EXCLUDED.last_updated \
                               """
                for symbol, data in trends.items():
                    cur.execute(insert_query, (
                        symbol,
                        data['direction'],
                        float(data['ema50']),
                        float(data['ema200']),
                        data['last_updated']
                    ))
                conn.commit()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_current_price(self, symbol, timeframe):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è"""
        candles = self.get_candles(symbol, timeframe)
        if candles:
            return candles[-1]['close']
        return None

    def save_alerts(self, alerts):
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for alert in alerts:
                    cur.execute("""
                                INSERT INTO alerts (symbol, level_price, current_price, type, distance, strength,
                                                    timeframe, source)
                                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                                """, (
                                    alert["symbol"],
                                    alert["level_price"],
                                    alert["current_price"],
                                    alert["type"],
                                    alert["distance"],
                                    alert["strength"],
                                    alert["timeframe"],
                                    alert.get("source", "level")
                                ))
            conn.commit()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–ª–µ—Ä—Ç–æ–≤: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)

    def get_alerts(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∞–ª–µ—Ä—Ç–æ–≤"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT symbol, level_price AS price, type AS signal_type, timeframe
                    FROM alerts
                    ORDER BY created_at DESC
                    LIMIT 200
                """)
                columns = [desc[0] for desc in cur.description]
                return [dict(zip(columns, row)) for row in cur.fetchall()]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–ª–µ—Ä—Ç–æ–≤: {e}")
            return []
        finally:
            self.release_connection(conn)

    def save_signals(self, signals):
        if not signals:
            logger.info("üì≠ –ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return

        query = """
        INSERT INTO signals (
            symbol, timeframe, signal_type, price,
            recommendation, score, details, current_price, time,
            rsi, macd, ema50, ema200, bb_position, stoch_k, stoch_d,
            atr, adx, vwap, poc
        )
        VALUES %s
        ON CONFLICT (symbol, timeframe, signal_type, time) DO UPDATE
        SET current_price = EXCLUDED.current_price,
            recommendation = EXCLUDED.recommendation,
            score = EXCLUDED.score,
            details = EXCLUDED.details,
            rsi = EXCLUDED.rsi,
            macd = EXCLUDED.macd,
            ema50 = EXCLUDED.ema50,
            ema200 = EXCLUDED.ema200,
            bb_position = EXCLUDED.bb_position,
            stoch_k = EXCLUDED.stoch_k,
            stoch_d = EXCLUDED.stoch_d,
            atr = EXCLUDED.atr,
            adx = EXCLUDED.adx,
            vwap = EXCLUDED.vwap,
            poc = EXCLUDED.poc
        """

        for s in signals:
            for key in ["current_price", "rsi", "macd", "ema50", "ema200", "bb_position", "stoch_k", "stoch_d"]:
                if isinstance(s.get(key), np.generic):
                    s[key] = float(s[key])

        values = [
            (
                s["symbol"],
                s["timeframe"],
                s["signal_type"],
                float(s.get("price", s.get("current_price", 0.0))),
                s.get("recommendation", ""),
                int(s.get("score", 0)),
                s.get("details", ""),
                float(s.get("current_price", 0.0)),
                int(time.time() * 1000),
                s.get("rsi"),
                s.get("macd"),
                s.get("ema50"),
                s.get("ema200"),
                s.get("bb_position"),
                s.get("stoch_k"),
                s.get("stoch_d"),
                s.get("atr"),
                s.get("adx"),
                s.get("vwap"),
                s.get("poc"),
            )
            for s in signals
        ]

        conn = self.connection_pool.getconn()
        try:
            with conn.cursor() as cur:
                execute_values(cur, query, values)
            conn.commit()
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        finally:
            self.connection_pool.putconn(conn)


    def get_signals(self, limit=100):
        query = """
        SELECT symbol, timeframe, signal_type, current_price, recommendation, score,
               details, time, rsi, macd, ema50, ema200, bb_position, stoch_k, stoch_d
        FROM signals
        ORDER BY time DESC
        LIMIT %s
        """
        conn = self.connection_pool.getconn()
        try:
            with conn.cursor() as cur:
                cur.execute(query, (limit,))
                rows = cur.fetchall()
        finally:
            self.connection_pool.putconn(conn)

        result = []
        for row in rows:
            result.append({
                "symbol": row[0],
                "timeframe": row[1],
                "signal_type": row[2],
                "current_price": row[3],
                "recommendation": row[4],
                "score": row[5],
                "details": row[6],
                "created_at": int(row[7]) // 1000,
                "rsi": row[8],
                "macd": row[9],
                "ema50": row[10],
                "ema200": row[11],
                "bb_position": row[12],
                "stoch_k": row[13],
                "stoch_d": row[14],
            })
        return result

    def get_indicators(self, symbol, timeframe):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ –ø–∞—Ä–µ –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º—É"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT indicator_type, value
                    FROM indicators
                    WHERE symbol = %s AND timeframe = %s
                    ORDER BY created_at DESC
                """, (symbol, timeframe))
                rows = cur.fetchall()
                return {row[0]: row[1] for row in rows}
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}")
            return {}
        finally:
            self.release_connection(conn)

    def get_market_cap(self, days=30):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π"""
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT total_cap, fetched_at
                    FROM market_cap
                    WHERE fetched_at >= NOW() - INTERVAL '%s days'
                    ORDER BY fetched_at ASC
                """, (days,))
                return cur.fetchall()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return []
        finally:
            self.release_connection(conn)

    def truncate_all_tables(self):
        """–û—á–∏—Å—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü"""
        logger.info("‚è≥ –ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏ —Ç–∞–±–ª–∏—Ü...")
        tables = [
            "collected_candles", "levels", "alerts",
            "pairs_cache", "trend_cache", "indicators", "signals"
        ]
        conn = self.get_connection()
        try:
            with conn.cursor() as cur:
                for table in tables:
                    cur.execute(f"TRUNCATE TABLE {table};")
                    logger.debug(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ {table} –æ—á–∏—â–µ–Ω–∞")
            conn.commit()
            logger.info("‚úÖ –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–∞–±–ª–∏—Ü: {e}")
            conn.rollback()
        finally:
            self.release_connection(conn)



# database/schema.py





# trading/_init_.py





# trading/executor.py





# trading/order.py





# services/_init_.py





# services/alert_engine.py

import logging
from datetime import datetime

from database.database import DatabaseManager

EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}
logger = logging.getLogger(__name__)


class AlertSystem:
    def __init__(self):
        self.db = DatabaseManager()

    def check_alerts(self, distance_threshold=1.0):
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–ª–µ—Ä—Ç–æ–≤ –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ —É—Ä–æ–≤–Ω—è–º.
        """
        levels = self.db.get_levels()
        alerts = []

        for lvl in levels:
            symbol = lvl["symbol"]
            timeframe = lvl["timeframe"]
            price_level = float(lvl["price"])

            # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç–µ–π–±–ª–∫–æ–∏–Ω—ã
            if any(stable in symbol for stable in EXCLUDED_STABLES):
                continue

            current_price = self.db.get_current_price(symbol, timeframe)
            if current_price is None:
                continue

            distance_pct = abs(current_price - price_level) / price_level * 100
            if distance_pct > distance_threshold:
                continue

            alert = {
                "symbol": symbol,
                "timeframe": timeframe,
                "level_price": price_level,
                "current_price": current_price,
                "type": lvl["type"],
                "strength": lvl["strength"],
                "distance": distance_pct,
                "source": "level",
                "created_at": datetime.now()
            }

            alerts.append(alert)

        logger.info(f"üîî –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–ª–µ—Ä—Ç–æ–≤: {len(alerts)}")
        self.db.save_alerts(alerts)
        return alerts



# services/cache.py

from database.database import DatabaseManager

def build_candle_cache():
    db = DatabaseManager()
    symbols = db.get_symbols_from_cache()
    timeframes = ["15m", "1h", "4h", "1d"]

    cache = {}
    for symbol in symbols:
        for tf in timeframes:
            candles = db.get_candles(symbol, tf)
            if candles:
                cache[(symbol, tf)] = candles
    return cache



# services/collector.py

import asyncio
import aiohttp
import logging
import json
from datetime import datetime

from database.database import DatabaseManager
from config.constants import BINANCE_TICKER_URL, CANDLE_SETTINGS

logger = logging.getLogger(__name__)

TIMEFRAMES = ["1d", "4h", "1h", "15m"]
EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}


class DataCollector:
    def __init__(self):
        self.db = DatabaseManager()

    # -------------------------------------------------
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ—á–µ–π –¥–ª—è –æ–¥–Ω–æ–π –ø–∞—Ä—ã-—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
    # -------------------------------------------------
    async def fetch_candles(self, session, symbol: str, interval: str):
        url = f"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit=500"
        try:
            async with session.get(url, timeout=10) as resp:
                if resp.status != 200:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {symbol} {interval}: {resp.status}")
                    return symbol, interval, []

                data = await resp.json()
                candles = [
                    {
                        "time":   int(c[0]),
                        "open":   float(c[1]),
                        "high":   float(c[2]),
                        "low":    float(c[3]),
                        "close":  float(c[4]),
                        "volume": float(c[5])
                    }
                    for c in data
                ]
                return symbol, interval, candles

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è {symbol} {interval}: {e}")
            return symbol, interval, []

    # -------------------------------------------------
    # 2. –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: –æ–±–Ω–æ–≤–ª—è–µ–º –í–°–ï —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã
    # -------------------------------------------------
    async def update_all_timeframes(self):
        symbols = self.db.get_symbols_from_cache()
        if not symbols:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
            return

        # –ò—Å–∫–ª—é—á–∞–µ–º —Å—Ç–µ–π–±–ª–∫–æ–∏–Ω—ã
        symbols = [s for s in symbols if not any(stable in s for stable in EXCLUDED_STABLES)]

        need_update = []
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                for s in symbols:
                    for tf, cfg in CANDLE_SETTINGS.items():
                        cur.execute(
                            """
                            SELECT last_updated
                              FROM collected_candles
                             WHERE symbol = %s
                               AND timeframe = %s
                            """,
                            (s, tf),
                        )
                        row = cur.fetchone()
                        if (
                            row is None
                            or (datetime.now() - row[0]).total_seconds() > cfg["update_freq"]
                        ):
                            need_update.append((s, tf))
        finally:
            self.db.release_connection(conn)

        if not need_update:
            logger.info("‚úÖ –í—Å–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã —Å–≤–µ–∂–∏–µ ‚Äî –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
            return

        async with aiohttp.ClientSession(headers={"User-Agent": "Mozilla/5.0"}) as session:
            tasks = [self.fetch_candles(session, sym, tf) for sym, tf in need_update]
            results = await asyncio.gather(*tasks)

            for symbol, tf, candles in results:
                if candles:
                    self.db.upsert_candles(symbol, tf, candles)
                    logger.info(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω—ã —Å–≤–µ—á–∏: {symbol} {tf} ({len(candles)})")
        # ---- –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î ----
        self.bulk_upsert_candles(results)

    # -------------------------------------------------
    # 3. –ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–≤–µ—á–µ–π
    # -------------------------------------------------
    def bulk_upsert_candles(self, results):
        conn = self.db.get_connection()
        now = datetime.now()
        try:
            with conn.cursor() as cur:
                for symbol, timeframe, candles in results:
                    if not candles:
                        continue
                    cur.execute(
                        """
                        INSERT INTO collected_candles (symbol, timeframe, candles, last_updated)
                        VALUES (%s, %s, %s, %s)
                        ON CONFLICT (symbol, timeframe)
                        DO UPDATE
                            SET candles      = EXCLUDED.candles,
                                last_updated = EXCLUDED.last_updated
                        """,
                        (symbol, timeframe, json.dumps(candles), now),
                    )
            conn.commit()
            logger.info(f"üíæ –ó–∞–≥—Ä—É–∂–µ–Ω—ã —Å–≤–µ—á–∏ –¥–ª—è {len([r for r in results if r[2]])} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π symbol/timeframe")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–µ—á–µ–π: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/data_manager.py

from database.database import DatabaseManager
import pandas as pd
from datetime import datetime

db = DatabaseManager()

def get_symbols():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("SELECT DISTINCT symbol FROM collected_candles")
            return [row[0] for row in cur.fetchall()]
    finally:
        db.release_connection(conn)

def get_candles(symbol, timeframe):
    try:
        candles = db.get_candles(symbol, timeframe)
        if not candles:
            return pd.DataFrame()
        df = pd.DataFrame(candles)
        df['date'] = pd.to_datetime(df['time'], unit='ms')
        df.set_index('date', inplace=True)
        return df.rename(columns={'open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})
    finally:
        pass

def get_levels(symbol, timeframe):
    all_levels = db.get_levels()
    filtered = [lvl for lvl in all_levels if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe]
    return filtered


# –î–æ–±–∞–≤—å—Ç–µ –º–µ—Ç–æ–¥ –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –≤—Å—Ç–∞–≤–∫–∏:
def bulk_upsert_candles(self, data):
    """–ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    conn = self.get_connection()
    try:
        with conn.cursor() as cur:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º COPY –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            from psycopg2.extras import Json
            from io import StringIO

            buffer = StringIO()
            for symbol, timeframe, candles in data:
                buffer.write(f"{symbol}\t{timeframe}\t{Json(candles)}\n")

            buffer.seek(0)
            cur.copy_from(buffer, 'collected_candles',
                          columns=('symbol', 'timeframe', 'candles'),
                          sep='\t')

            conn.commit()
    finally:
        self.release_connection(conn)


def get_signals(symbol, timeframe):
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("""SELECT signal_type, price, time FROM signals WHERE symbol = %s AND timeframe = %s ORDER BY time DESC LIMIT 10""",
                        (symbol, timeframe))
            return cur.fetchall()
    finally:
        db.release_connection(conn)

def get_alerts():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM alerts ORDER BY created_at DESC LIMIT 100")
            columns = [desc[0] for desc in cur.description]
            rows = cur.fetchall()
            return pd.DataFrame(rows, columns=columns)
    finally:
        db.release_connection(conn)

def get_signals_table():
    try:
        conn = db.get_connection()
        with conn.cursor() as cur:
            cur.execute("""SELECT symbol, timeframe, signal_type, price, time, indicator FROM signals ORDER BY time DESC LIMIT 100""")
            rows = cur.fetchall()
            df = pd.DataFrame(rows, columns=["symbol", "timeframe", "signal_type", "price", "time", "indicator"])
            df['time'] = pd.to_datetime(df['time'], unit='ms').dt.strftime("%Y-%m-%d %H:%M:%S")
            return df
    finally:
        db.release_connection(conn)

def clear_database():
    db.truncate_all_tables()



# services/deep_an.py

import aiohttp
import logging
from datetime import datetime, timedelta
from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class MarketCapTracker:
    def __init__(self):
        self.db = DatabaseManager()

    async def fetch_total_market_cap(self):
        url = "https://api.coingecko.com/api/v3/global"
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        total = data["data"]["total_market_cap"]["usd"]
                        logger.info(f"üåê –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è: ${total:,.2f}")
                        self.save_market_cap(total)
                        self.delete_old_data()  # –æ—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    else:
                        logger.warning(f"‚ùå –û—à–∏–±–∫–∞ CoinGecko: {response.status}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

    def save_market_cap(self, total_cap):
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    INSERT INTO market_cap (total_cap, fetched_at)
                    VALUES (%s, %s)
                """, (total_cap, datetime.now()))
            conn.commit()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    def delete_old_data(self):
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π"""
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    DELETE FROM market_cap
                    WHERE fetched_at < NOW() - INTERVAL '30 days'
                """)
            conn.commit()
            logger.info("üßπ –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ —É–¥–∞–ª–µ–Ω—ã")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    def get_last_month_caps(self):
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT total_cap, fetched_at
                    FROM market_cap
                    WHERE fetched_at >= NOW() - INTERVAL '30 days'
                    ORDER BY fetched_at ASC
                """)
                return cur.fetchall()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return []
        finally:
            self.db.releas



# services/derivatives_engine.py

import aiohttp
import asyncio
import logging
from asyncio import Semaphore

from database.database import DatabaseManager

logger = logging.getLogger(__name__)
BINANCE_FAPI = "https://fapi.binance.com"


class DerivativesEngine:
    def __init__(self):
        self.db = DatabaseManager()

    async def _fetch_json(self, url, params=None, retries=3):
        for attempt in range(retries):
            try:
                async with aiohttp.ClientSession() as s:
                    async with s.get(url, params=params, timeout=7) as r:
                        if r.status == 200:
                            return await r.json()
                        else:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ {r.status} –æ—Ç {url} –¥–ª—è {params}")
                            return None
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {url} –¥–ª—è {params}: {e}")
                await asyncio.sleep(1 + attempt)  # –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
        return None

    async def update_metrics(self, symbol: str):
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, –µ—Å–ª–∏ –µ—Å—Ç—å
        symbol = symbol.replace("/", "")

        oi = await self._fetch_json(f"{BINANCE_FAPI}/fapi/v1/openInterest", {"symbol": symbol})
        if oi is None:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ openInterest –¥–ª—è {symbol} ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return

        fr = await self._fetch_json(f"{BINANCE_FAPI}/fapi/v1/fundingRate", {"symbol": symbol, "limit": 1})
        if not fr or not isinstance(fr, list) or "fundingRate" not in fr[0]:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ fundingRate –¥–ª—è {symbol} ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return

        records = [
            dict(symbol=symbol, timeframe="1h", indicator_type="OI", value=oi["openInterest"]),
            dict(symbol=symbol, timeframe="1h", indicator_type="FUND_RATE", value=fr[0]["fundingRate"]),
        ]
        self._save(records)

    async def _usdt_symbols(self, quote="USDT") -> list[str]:
        conn = self.db.get_connection()
        with conn, conn.cursor() as cur:
            cur.execute("SELECT symbol FROM pairs_cache WHERE symbol ILIKE %s", (f"%{quote}",))
            return [row[0] for row in cur.fetchall()]

    async def update_metrics_for_all(self):
        symbols = await self._usdt_symbols()
        sem = Semaphore(5)

        async def _guarded(sym):
            async with sem:
                await self.update_metrics(sym)

        await asyncio.gather(*[_guarded(s) for s in symbols])

    def _save(self, records):
        conn = self.db.get_connection()
        try:
            sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, NOW())
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value, created_at = EXCLUDED.created_at
            """
            with conn.cursor() as cur:
                for r in records:
                    cur.execute(sql, (
                        r["symbol"],
                        r["timeframe"],
                        r["indicator_type"],
                        str(r["value"])
                    ))
            conn.commit()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–µ—Ä–∏–≤–∞—Ç–∏–≤–æ–≤: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/enter_exit_engine.py





# services/fibo_engine.py

import logging
import pandas as pd
from database.database import DatabaseManager

logger = logging.getLogger(__name__)

FIBO_LEVELS = [0.236, 0.382, 0.5, 0.618, 0.786]

class FiboEngine:
    def __init__(self):
        self.db = DatabaseManager()

    def calculate_for_pair(self, symbol, timeframe):
        candles = self.db.get_candles(symbol, timeframe)
        if not candles or len(candles) < 50:
            return None

        df = pd.DataFrame(candles)
        df["high"] = pd.to_numeric(df["high"])
        df["low"] = pd.to_numeric(df["low"])

        high = df["high"].max()
        low = df["low"].min()

        fibo = [high - (high - low) * level for level in FIBO_LEVELS]

        return {
            "high": high,
            "low": low,
            "fibo_levels": dict(zip(FIBO_LEVELS, fibo))
        }



# services/identifier.py

import aiohttp
import asyncio
import logging
from datetime import datetime
from database.database import DatabaseManager
from config.constants import BINANCE_TICKER_URL


logger = logging.getLogger(__name__)

class PairIdentifier:
    def __init__(self):
        self.db = DatabaseManager()

    async def fetch_all_usdt_pairs(self):
        try:
            async with aiohttp.ClientSession(headers={"User-Agent": "Mozilla/5.0"}) as session:
                async with session.get(BINANCE_TICKER_URL, timeout=10) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        pairs = [item["symbol"] for item in data if item["symbol"].endswith("USDT")]
                        logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–æ {len(pairs)} USDT-–ø–∞—Ä —Å Binance")
                        return pairs
                    else:
                        logger.error(f"‚ùå Binance API error: {resp.status}")
                        return []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä —Å Binance: {e}")
            return []

    async def update_pairs_cache(self):
        pairs = await self.fetch_all_usdt_pairs()
        if not pairs:
            logger.warning("‚ö†Ô∏è –ü–∞—Ä—ã –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã ‚Äî –∫—ç—à –Ω–µ –æ–±–Ω–æ–≤–ª—ë–Ω")
            return

        now = datetime.now()
        conn = self.db.get_connection()
        try:
            with conn.cursor() as cur:
                cur.execute("TRUNCATE TABLE pairs_cache RESTART IDENTITY")
                insert = "INSERT INTO pairs_cache (symbol, volume, first_seen, last_seen) VALUES (%s, %s, %s, %s)"
                for pair in pairs:
                    cur.execute(insert, (pair, 0.0, now, now))
            conn.commit()
            logger.info(f"‚úÖ –ö—ç—à –ø–∞—Ä –æ–±–Ω–æ–≤–ª—ë–Ω: {len(pairs)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫—ç—à–∞ –ø–∞—Ä: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)



# services/indicator_engine.py

import logging
from datetime import datetime


import numpy as np
import pandas as pd

from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class IndicatorEngine:
    def __init__(self):
        self.db = DatabaseManager()

    def compute_indicators(self):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã-—Ç–∞–π–º—Ñ—Ä–µ–π–º–∞."""
        all_candles = self.db.get_all_candles()
        indicators: list[dict] = []


        for (symbol, tf), candles in all_candles.items():
            # –ù—É–∂–Ω–∞ —Ö–æ—Ç—è –±—ã 200-–¥–Ω–µ–≤–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è EMA-200
            if len(candles) < 200:
                continue

            df = pd.DataFrame(candles)
            df["close"] = pd.to_numeric(df["close"])
            df["high"] = pd.to_numeric(df["high"])
            df["low"] = pd.to_numeric(df["low"])

            # ‚îÄ‚îÄ –±–∞–∑–æ–≤—ã–µ —Ä–∞—Å—á—ë—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            rsi = self._rsi(df["close"])
            macd_line, macd_sig, _ = self._macd(df["close"])
            macd_hist = macd_line - macd_sig  # ‚Üê –¥–æ–±–∞–≤—å —ç—Ç—É —Å—Ç—Ä–æ–∫—É
            ema20 = df["close"].ewm(span=20, adjust=False).mean()
            ema50 = df["close"].ewm(span=50, adjust=False).mean()
            ema200 = df["close"].ewm(span=200, adjust=False).mean()
            bb_up, bb_mid, bb_lo = self._bollinger_bands(df["close"])
            stoch_k, stoch_d = self._stochastic(df)

            # ‚îÄ‚îÄ –æ–±—ä—ë–º / –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            obv = self._obv(df["close"], df["volume"])
            vwap = self._vwap(df)  # 20-–ø–µ—Ä–∏–æ–¥–Ω–∞—è
            poc = self._vpvr_poc(df)  # VPVR POC –∑–∞ N —Å–≤–µ—á–µ–π

            # ‚îÄ‚îÄ —Å–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            atr = self._atr(df)  # 14-p ATR
            adx = self._adx(df)  # 14-p ADX

            # ‚îÄ‚îÄ super-trend (–ø–æ ATR) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            supertrend = self._supertrend(df, atr)


            # # === –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ===
            # rsi = self._rsi(df)
            # macd_line, macd_sig, macd = self._macd(df)
            # ema20 = self._ema(df, 20)
            # ema50 = self._ema(df, 50)
            # ema200 = self._ema(df, 200)
            # bb_up, bb_mid, bb_lo = self._bollinger_bands(df["close"])
            # stoch_k, stoch_d = self._stochastic(df)
            # obv = self._obv(df["close"], df["volume"])
            # vwap = self._vwap(df)
            # poc = self._vpvr_poc(df)
            # atr = self._atr(df)
            # adx = self._adx(df)
            # supertrend = self._supertrend(df, atr)

            last_close = df["close"].iloc[-1]
            recommendation = self._recommend(
                last_close=last_close,
                ema20=ema20.iloc[-1],
                rsi_val=rsi.iloc[-1],
                macd_val=macd_line.iloc[-1],
                macd_sig=macd_sig.iloc[-1],
                macd_hist=macd_hist.iloc[-1],  # ‚Üê –¥–æ–±–∞–≤—å —ç—Ç—É —Å—Ç—Ä–æ–∫—É
                bb_middle=bb_mid.iloc[-1]
            )

            indicators.append(dict(
                symbol=symbol,
                timeframe=tf,
                rsi=rsi.iloc[-1],
                macd=macd_hist.iloc[-1],  # –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å —Å—Ç–∞—Ä–æ–µ –∏–º—è macd
                macd_hist=macd_hist.iloc[-1],  # ‚Üê –¥–æ–±–∞–≤—å —ç—Ç—É —Å—Ç—Ä–æ–∫—É
                ema20=ema20.iloc[-1],
                ema50=ema50.iloc[-1],
                ema200=ema200.iloc[-1],
                bb_upper=bb_up.iloc[-1],
                bb_lower=bb_lo.iloc[-1],
                stoch_k=stoch_k.iloc[-1],
                stoch_d=stoch_d.iloc[-1],
                obv=obv.iloc[-1],
                vwap=vwap.iloc[-1],
                poc=poc if not hasattr(poc, "iloc") else float(poc.iloc[-1]),
                atr=atr.iloc[-1],
                adx=adx.iloc[-1],
                supertrend=supertrend.iloc[-1],
                recommendation=recommendation,
            ))

            indicators_to_save = [
                {"type": "RSI", "value": rsi.iloc[-1]},
                {"type": "MACD", "value": macd_hist.iloc[-1]},
                {"type": "EMA50", "value": ema50.iloc[-1]},
                {"type": "EMA200", "value": ema200.iloc[-1]},
                {"type": "BB_UPPER", "value": bb_up.iloc[-1]},
                {"type": "BB_LOWER", "value": bb_lo.iloc[-1]},
                {"type": "STOCH_K", "value": stoch_k.iloc[-1]},
                {"type": "STOCH_D", "value": stoch_d.iloc[-1]},
                {"type": "ATR", "value": atr.iloc[-1]},
                {"type": "ADX", "value": adx.iloc[-1]},
                {"type": "VWAP", "value": vwap.iloc[-1]},
                {"type": "POC", "value": poc if not hasattr(poc, "iloc") else float(poc.iloc[-1])}
            ]




        self._save_indicators(indicators)
        return indicators

    def _ema(self, df, period):
        return df["close"].ewm(span=period, adjust=False).mean()

    def _rsi(self, series, period=14):
        delta = series.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=period).mean()
        avg_loss = loss.rolling(window=period).mean()
        rs = avg_gain / avg_loss
        return 100 - (100 / (1 + rs))

    def _macd(self, series, fast=12, slow=26, signal=9):
        ema_fast = series.ewm(span=fast, adjust=False).mean()
        ema_slow = series.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        macd_hist = macd_line - signal_line
        return macd_line, signal_line, macd_hist

    def _bollinger_bands(self, series, period=20):
        middle = series.rolling(window=period).mean()
        std = series.rolling(window=period).std()
        upper = middle + 2 * std
        lower = middle - 2 * std
        return upper, middle, lower

    def _recommend(
            self,
            last_close: float,
            ema20: float,
            rsi_val: float,
            macd_val: float,
            macd_sig: float,
            macd_hist: float,  # ‚Üê –¥–æ–±–∞–≤–∏–ª–∏
            bb_middle: float
    ) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è heursitics-—Ä–µ–∫–æ–º–º–µ–Ω–¥–∞—Ü–∏—è."""
        long_ok = macd_val > macd_sig and macd_hist > 0
        short_ok = macd_val < macd_sig and macd_hist < 0

        if ema20 > bb_middle and 50 < rsi_val < 70 and long_ok and last_close > bb_middle:
            return "–ü–û–ö–£–ü–ê–¢–¨"
        if ema20 < bb_middle and 30 < rsi_val < 50 and short_ok and last_close < bb_middle:
            return "–ü–†–û–î–ê–í–ê–¢–¨"
        return "–ù–ê–ë–õ–Æ–î–ê–¢–¨"

    def _stochastic(self, df, k_period=14, d_period=3):
        low_min = df["low"].rolling(window=k_period).min()
        high_max = df["high"].rolling(window=k_period).max()
        k = 100 * (df["close"] - low_min) / (high_max - low_min)
        d = k.rolling(window=d_period).mean()
        return k, d

    def _obv(self, close, volume):
        direction = np.sign(close.diff().fillna(0))
        return (volume * direction).cumsum()

    def _vwap(self, df, period=20):
        pv = (df["high"] + df["low"] + df["close"]) / 3 * df["volume"]
        return pv.rolling(period).sum() / df["volume"].rolling(period).sum()

    def _vpvr_poc(self, df, bins=24):
        hist, edges = np.histogram(df["close"], bins=bins, weights=df["volume"])
        idx = hist.argmax()
        return (edges[idx] + edges[idx + 1]) / 2

    def _atr(self, df, period=14):
        tr = pd.concat([
            df["high"] - df["low"],
            (df["high"] - df["close"].shift()).abs(),
            (df["low"] - df["close"].shift()).abs()
        ], axis=1).max(axis=1)
        return tr.rolling(period).mean()

    def _adx(self, df, period=14):
        up = df["high"].diff()
        dn = -df["low"].diff()
        plus_dm = np.where((up > dn) & (up > 0), up, 0.0)
        minus_dm = np.where((dn > up) & (dn > 0), dn, 0.0)
        tr = self._atr(df, 1)  # true range –¥–Ω–µ–≤–Ω–æ–π
        plus_di = 100 * pd.Series(plus_dm).ewm(span=period).mean() / tr
        minus_di = 100 * pd.Series(minus_dm).ewm(span=period).mean() / tr
        dx = (abs(plus_di - minus_di) / (plus_di + minus_di)).fillna(0) * 100
        return dx.ewm(span=period).mean()

    def _supertrend(self, df, atr, factor=3):
        hl2 = (df["high"] + df["low"]) / 2
        upper = hl2 + factor * atr
        lower = hl2 - factor * atr
        trend = pd.Series(index=df.index, dtype=bool)
        trend.iloc[0] = True
        for i in range(1, len(df)):
            if df["close"].iloc[i] > upper.iloc[i - 1]:
                trend.iloc[i] = True
            elif df["close"].iloc[i] < lower.iloc[i - 1]:
                trend.iloc[i] = False
            else:
                trend.iloc[i] = trend.iloc[i - 1]
                upper.iloc[i] = min(upper.iloc[i], upper.iloc[i - 1]) if trend.iloc[i] else upper.iloc[i]
                lower.iloc[i] = max(lower.iloc[i], lower.iloc[i - 1]) if not trend.iloc[i] else lower.iloc[i]
        return trend

    def _save_indicators(self, records: list[dict]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Ç–∞–±–ª–∏—Ü—É `indicators`."""
        if not records:
            return

        import numpy as np  # –Ω—É–∂–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ np.floating

        conn = self.db.get_connection()
        insert_sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value,
                          created_at = EXCLUDED.created_at;
        """

        names = [
            "RSI", "MACD", "MACD_HIST", "EMA20", "EMA50", "EMA200",
            "BB_UPPER", "BB_LOWER", "STOCH_K", "STOCH_D", "RECOMMENDATION", "OBV", "VWAP", "VPVR_POC", "ATR", "ADX", "SUPERTREND"
        ]

        try:
            with conn.cursor() as cur:
                for rec in records:
                    for name in names:
                        key = "recommendation" if name == "RECOMMENDATION" else name.lower()
                        val = rec.get(key)
                        if val is None:
                            continue

                        # numpy ‚Üí float | —Å—Ç—Ä–æ–∫–∞ ‚Üí str
                        if isinstance(val, (float, int, np.floating)):
                            val_db = float(val)
                        else:
                            val_db = str(val)

                        cur.execute(
                            insert_sql,
                            (rec["symbol"], rec["timeframe"], name, val_db)
                        )
            conn.commit()
        except Exception as e:
            conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤: {e}", exc_info=True)
        finally:
            self.db.release_connection(conn)



# services/level_engine.py

import logging
from datetime import datetime
import numpy as np
import pandas as pd

from database.database import DatabaseManager

logger = logging.getLogger(__name__)


class LevelAnalyzer:
    def __init__(self):
        self.db = DatabaseManager()
        self.configs = {
            "15m": {"pivot_period": 3, "min_strength": 2, "max_pivot_points": 50, "max_channel_width_percent": 8},
            "1h": {"pivot_period": 5, "min_strength": 3, "max_pivot_points": 40, "max_channel_width_percent": 6},
            "4h": {"pivot_period": 7, "min_strength": 4, "max_pivot_points": 30, "max_channel_width_percent": 5},
            "1d": {"pivot_period": 10, "min_strength": 5, "max_pivot_points": 20, "max_channel_width_percent": 4},
        }

    def analyze_levels(self):
        all_candles = self.db.get_all_candles()
        levels = []

        for (symbol, tf), candles in all_candles.items():
            if tf not in self.configs or len(candles) < 100:
                continue

            df = pd.DataFrame(candles)
            df["close"] = pd.to_numeric(df["close"])
            df["high"] = pd.to_numeric(df["high"])
            df["low"] = pd.to_numeric(df["low"])

            cfg = self.configs[tf]
            df = self._detect_pivots(df, cfg["pivot_period"])
            channels = self._cluster_levels(df, cfg)

            for ch in channels:
                levels.append({
                    "symbol": symbol,
                    "timeframe": tf,
                    "price": ch["price"],
                    "type": ch["type"],
                    "strength": ch["strength"],
                    "upper": ch["upper"],
                    "lower": ch["lower"],
                    "distance": ch["distance"],
                    "touched": 0,
                    "broken": False,
                    "last_touched": datetime.now().timestamp()
                })

        merged = self._merge_levels(levels)
        self.db.save_levels(merged)
        return merged

    def _detect_pivots(self, df, period):
        df["ph"] = df["high"].rolling(window=2 * period + 1, center=True).apply(
            lambda x: x[period] if x[period] == x.max() else np.nan, raw=True)
        df["pl"] = df["low"].rolling(window=2 * period + 1, center=True).apply(
            lambda x: x[period] if x[period] == x.min() else np.nan, raw=True)
        return df

    def _cluster_levels(self, df, cfg):
        points = []
        for i, row in df.iterrows():
            if not np.isnan(row["ph"]):
                points.append((row["ph"], "resistance"))
            elif not np.isnan(row["pl"]):
                points.append((row["pl"], "support"))

        points = points[-cfg["max_pivot_points"]:]
        avg_price = df["close"].tail(50).mean()
        channel_width = avg_price * cfg["max_channel_width_percent"] / 100
        used, clusters = set(), []

        for i, (price, ptype) in enumerate(points):
            if i in used:
                continue
            cluster = [(price, ptype)]
            for j in range(i + 1, len(points)):
                if abs(price - points[j][0]) <= channel_width:
                    cluster.append(points[j])
                    used.add(j)
            if len(cluster) >= cfg["min_strength"]:
                prices = [p[0] for p in cluster]
                level_type = "resistance" if sum(1 for p in cluster if p[1] == "resistance") > len(cluster) / 2 else "support"
                clusters.append({
                    "price": np.mean(prices),
                    "type": level_type,
                    "strength": len(cluster),
                    "upper": max(prices),
                    "lower": min(prices),
                    "distance": abs(np.mean(prices) - df["close"].iloc[-1]) / df["close"].iloc[-1]
                })

        # EMA —É—Ä–æ–≤–Ω–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–≤–µ—á–µ–π)
        if len(df) >= 200:
            for span, label in [(50, "ema50"), (200, "ema200")]:
                ema = df["close"].ewm(span=span, adjust=False).mean().iloc[-1]
                clusters.append({
                    "price": ema,
                    "type": label,
                    "strength": 5 if label == "ema50" else 6,
                    "upper": ema,
                    "lower": ema,
                    "distance": abs(ema - df["close"].iloc[-1]) / df["close"].iloc[-1]
                })

        return clusters

    def _merge_levels(self, levels):
        merged = {}
        for lvl in levels:
            key = f"{lvl['symbol']}_{lvl['timeframe']}_{lvl['price']:.8f}"
            if key in merged:
                merged[key]["strength"] = max(merged[key]["strength"], lvl["strength"])
                merged[key]["touched"] += 1
                merged[key]["last_touched"] = datetime.now().timestamp()
            else:
                merged[key] = lvl
        return list(merged.values())



# services/sentiment_engine.py

import aiohttp
import asyncio
import logging

from database.database import DatabaseManager

BINANCE_FAPI = "https://fapi.binance.com"
logger = logging.getLogger(__name__)


class SentimentEngine:
    def __init__(self):
        self.db = DatabaseManager()

    async def _fetch_json(self, url, params=None, timeout=7):
        try:
            async with aiohttp.ClientSession() as sess:
                async with sess.get(url, params=params, timeout=timeout) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ {resp.status} –æ—Ç {url} –¥–ª—è {params}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ {url} –¥–ª—è {params}: {e}")
        return None

    def _save(self, rows):
        conn = self.db.get_connection()
        try:
            sql = """
            INSERT INTO indicators (symbol, timeframe, indicator_type, value, created_at)
            VALUES (%s, %s, %s, %s, NOW())
            ON CONFLICT (symbol, timeframe, indicator_type)
            DO UPDATE SET value = EXCLUDED.value, created_at = EXCLUDED.created_at
            """
            with conn.cursor() as cur:
                for r in rows:
                    cur.execute(sql, (
                        r["symbol"],
                        r["timeframe"],
                        r["indicator_type"],
                        str(r["value"])
                    ))
            conn.commit()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞: {e}")
            conn.rollback()
        finally:
            self.db.release_connection(conn)

    async def _usdt_symbols(self, quote="USDT"):
        conn = self.db.get_connection()
        with conn, conn.cursor() as cur:
            cur.execute("SELECT symbol FROM pairs_cache WHERE symbol ILIKE %s", (f"%{quote}",))
            return [row[0] for row in cur.fetchall()]

    async def update_for_all(self, quote="USDT", interval="5m", max_concurrent=10):
        symbols = await self._usdt_symbols(quote)
        if not symbols:
            logger.warning("SentimentEngine: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –ø–∞—Ä—ã —Å USDT")
            return

        sem = asyncio.Semaphore(max_concurrent)

        async def _guarded(sym):
            async with sem:
                await self.update(symbol=sym, interval=interval)

        await asyncio.gather(*[_guarded(s) for s in symbols])

    async def update(self, symbol="BTCUSDT", interval="5m"):
        symbol = symbol.replace("/", "").upper()
        url = f"{BINANCE_FAPI}/futures/data/globalLongShortAccountRatio"
        data = await self._fetch_json(url, {
            "symbol": symbol,
            "period": interval,
            "limit": 1
        })

        if not data:
            return

        rec = data[0]
        longs = float(rec["longAccount"])
        shorts = float(rec["shortAccount"])
        ratio = 100 * longs / (longs + shorts)

        rows = [
            {"symbol": symbol, "timeframe": interval, "indicator_type": "LONGS_RATIO", "value": ratio},
            {"symbol": symbol, "timeframe": interval, "indicator_type": "SHORTS_RATIO", "value": 100 - ratio},
        ]
        self._save(rows)



# services/signal_engine.py

import logging
import pandas as pd
from database.database import DatabaseManager
from services.fibo_engine import FiboEngine
from services.signal_score import SignalScorer
from services.alert_engine import AlertSystem

logger = logging.getLogger(__name__)

class SignalEngine:
    def __init__(self):
        self.db = DatabaseManager()
        self.fibo = FiboEngine()
        self.scorer = SignalScorer()

    def generate_signals(self):
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏—à–µ–¥—à–∏—Ö –∞–ª–µ—Ä—Ç–æ–≤ –∏ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –∞–ª–µ—Ä—Ç–æ–≤ –∏ —Å–≤–µ—á–µ–π...")



        alerts = AlertSystem().check_alerts()
        if not alerts:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –∞–ª–µ—Ä—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return

        all_candles = self.db.get_all_candles()
        all_levels = self.db.get_levels()
        signals = []


        for alert in alerts:
            signal_type = alert.get("signal_type") or alert.get("type")
            if not signal_type:
                logger.debug(f"‚õîÔ∏è –ü—Ä–æ–ø—É—Å–∫ –∞–ª–µ—Ä—Ç–∞ –±–µ–∑ —Ç–∏–ø–∞: {symbol} {tf}")
                continue
            try:
                symbol = alert["symbol"]
                tf = alert["timeframe"]
                if (candles := all_candles.get((symbol, tf))) is None or len(candles) < 50:
                    continue

                df = pd.DataFrame(candles)
                df["close"] = pd.to_numeric(df["close"])
                close_price = df["close"].iloc[-1]

                # ‚îÄ‚îÄ –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–∑ –ë–î ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                db_ind = self.db.get_indicators(symbol, tf)
                get = lambda k: float(db_ind[k]) if db_ind.get(k) is not None else None

                indicators = {
                    "rsi": get("RSI"),
                    "macd": get("MACD"),
                    "macd_hist": get("MACD"),
                    "ema50": get("EMA50"),
                    "ema200": get("EMA200"),
                    "bb_upper": get("BB_UPPER"),
                    "bb_lower": get("BB_LOWER"),
                    "stoch_k": get("STOCH_K"),
                    "stoch_d": get("STOCH_D"),
                    "atr": get("ATR"),
                    "adx": get("ADX"),
                    "vwap": get("VWAP"),
                    "poc": get("POC"),
                }

                # ‚îÄ‚îÄ –æ—Ü–µ–Ω–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                trend_data = self.db.get_trend(symbol)
                fibo = self.fibo.calculate_for_pair(symbol, tf)
                levels = [lvl for lvl in all_levels if lvl["symbol"] == symbol and lvl["timeframe"] == tf]
                market_cap_data = self.db.get_market_cap()

                def calculate_bb_position(price, upper, lower):
                    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–∑–∏—Ü–∏—é —Ü–µ–Ω—ã –≤–Ω—É—Ç—Ä–∏ –ø–æ–ª–æ—Å –ë–æ–ª–ª–∏–Ω–¥–∂–µ—Ä–∞ –æ—Ç 0 –¥–æ 1"""
                    if upper is None or lower is None or upper == lower:
                        return None
                    return (price - lower) / (upper - lower)

                bb_pos = calculate_bb_position(close_price, indicators["bb_upper"], indicators["bb_lower"])

                signal_meta = {
                    "symbol": symbol,
                    "timeframe": tf,
                    "signal_type": signal_type,
                    "price": alert.get("price"),
                    "current_price": close_price,
                    "rsi": indicators["rsi"],
                    "macd": indicators["macd"],
                    "ema50": indicators["ema50"],
                    "ema200": indicators["ema200"],
                    "bb_position": bb_pos,
                    "stoch_k": indicators["stoch_k"],
                    "stoch_d": indicators["stoch_d"],
                    "atr": indicators["atr"],
                    "adx": indicators["adx"],
                    "vwap": indicators["vwap"],
                    "poc": indicators["poc"],
                }

                result = self.scorer.evaluate(
                    trend_data,
                    levels,
                    indicators,
                    fibo["fibo_levels"] if fibo else {},
                    market_cap_data,
                    signal_meta
                )

                # ‚îÄ‚îÄ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                det = [
                    f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: –¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞: {close_price:.6f}",
                    f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: RSI: {indicators['rsi']:.2f}" if indicators["rsi"] is not None else None,
                    f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: MACD –≥–∏—Å—Ç.: {indicators['macd_hist']:.6f}" if indicators["macd_hist"] is not None else None,
                    f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: EMA-50: {indicators['ema50']:.6f}" if indicators["ema50"] is not None else None,
                    f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: EMA-200: {indicators['ema200']:.6f}" if indicators["ema200"] is not None else None,
                    (
                        f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: Bollinger Bands: –≤–µ—Ä—Ö {indicators['bb_upper']:.6f}, "
                        f"–Ω–∏–∑ {indicators['bb_lower']:.6f}"
                    ) if indicators["bb_upper"] is not None and indicators["bb_lower"] is not None else None,
                    (
                        f"–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä: Stochastic %K={indicators['stoch_k']:.2f}, "
                        f"%D={indicators['stoch_d']:.2f}"
                    ) if indicators["stoch_k"] is not None and indicators["stoch_d"] is not None else None,
                ]
                # —É–±–∏—Ä–∞–µ–º None –∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–µ—Ç–∞–ª–∏ –∏–∑ Scorer
                details = [d for d in det if d] + result["details"]

                # ‚îÄ‚îÄ –¥–æ–±–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –≤ —Å–ø–∏—Å–æ–∫ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                signals.append({
                    "symbol": symbol,
                    "timeframe": tf,
                    "signal_type":    signal_type,
                    "current_price": close_price,
                    "recommendation": result["recommendation"],
                    "score": result["score"],
                    "created_at": alert.get("created_at"),
                    "details": "\n".join(details),
                    "rsi": indicators["rsi"],
                    "macd": indicators["macd_hist"],
                    "ema50": indicators["ema50"],
                    "ema200": indicators["ema200"],
                    "bb_position": None,  # –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å
                    "stoch_k": indicators["stoch_k"],
                    "stoch_d": indicators["stoch_d"],
                })

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {alert.get('symbol')} {alert.get('timeframe')}: {e}", exc_info=True)

        # ‚îÄ‚îÄ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if signals:
            # ‚îÄ‚îÄ dedup –ø–æ –∫–ª—é—á—É (symbol, timeframe, signal_type) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            deduped: dict[tuple, dict] = {}
            for sig in signals:
                key = (sig["symbol"], sig["timeframe"], sig["signal_type"])
                # –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –ø–æ–≤—Ç–æ—Ä, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—Ç, —É –∫–æ—Ç–æ—Ä–æ–≥–æ score –≤—ã—à–µ
                if key not in deduped or sig["score"] > deduped[key]["score"]:
                    deduped[key] = sig

            signals = list(deduped.values())
            self.db.save_signals(signals)
            logger.info(f"‚úÖ –í—Å–µ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {len(signals)}")
        else:
            logger.info("üì≠ –ù–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        return signals



# services/signal_score.py

import logging

logger = logging.getLogger(__name__)

class SignalScorer:
    def __init__(self):
        pass

    def evaluate(
            self,
            trend_data: dict | None,
            levels: list[dict],
            indicators: dict,
            fibo_levels: list[dict] | dict,
            market_cap_data: dict | None,
            signal: dict,
    ) -> dict:
        def to_float(x):
            """–ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ float, –∏–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None."""
            try:
                return float(x)
            except (TypeError, ValueError):
                return None

        rsi = to_float(indicators.get("rsi"))
        macd_h = to_float(indicators.get("macd_hist"))
        ema50 = to_float(indicators.get("ema50"))
        ema200 = to_float(indicators.get("ema200"))
        """
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π score –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ –ø–æ —Å–∏–≥–Ω–∞–ª—É.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {"score": int, "recommendation": str, "details": list[str]}
        """
        score = 0
        details: list[str] = []

        symbol = signal["symbol"]
        timeframe = signal["timeframe"]
        signal_type = signal["signal_type"]

        atr = indicators.get("atr")
        adx = indicators.get("adx")
        supertrend = indicators.get("supertrend")
        oi = indicators.get("oi")
        fund_rate = indicators.get("fund_rate")
        vwap = indicators.get("vwap")
        poc = indicators.get("vpvr_poc")
        sentiment = indicators.get("longs_ratio")  # –∏–ª–∏ –¥—Ä—É–≥–æ–π –∫–ª—é—á

        # ‚îÄ‚îÄ –±–µ–∑–æ–ø–∞—Å–Ω–æ –ø–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—É ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        try:
            price = float(signal.get("price") or signal["current_price"])
        except (KeyError, TypeError, ValueError):
            raise ValueError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ü–µ–Ω—É –¥–ª—è {symbol} {timeframe} ({signal_type})"
            )

        current_price = float(signal["current_price"])

        # ‚îÄ‚îÄ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        fmt_pct = lambda v: f"{v:+.2f}%"
        fmt_dir = lambda d: "–≤—ã—à–µ —É—Ä–æ–≤–Ω—è" if d > 0 else "–Ω–∏–∂–µ —É—Ä–æ–≤–Ω—è"

        # ‚îÄ‚îÄ 1. –¢—Ä–µ–Ω–¥ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        if trend_data:
            direction = trend_data.get("direction", "").upper()
            if direction == "BULLISH" and signal_type == "long":
                score += 20
                details.append("‚úÖ –¢—Ä–µ–Ω–¥: BULLISH")
            elif direction == "BEARISH" and signal_type == "short":
                score += 20
                details.append("‚úÖ –¢—Ä–µ–Ω–¥: BEARISH")
            elif direction:
                details.append(f"‚ö†Ô∏è –¢—Ä–µ–Ω–¥: {direction}")

        # ‚îÄ‚îÄ 2. –ë–ª–∏–∑–æ—Å—Ç—å –∫ —É—Ä–æ–≤–Ω—è–º S/R ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        for lvl in levels:
            if lvl["symbol"] != symbol or lvl["timeframe"] != timeframe:
                continue
            delta = (current_price - float(lvl["price"])) / current_price * 100
            if abs(delta) < 0.5:  # ¬±0.5 %
                score += 15
                details.append(
                    f"üìà {lvl['type'].capitalize()}: {lvl['price']:.6f} | "
                    f"–¶–µ–Ω–∞ {fmt_dir(delta)} –Ω–∞ {fmt_pct(delta)}"
                )

            # ‚îÄ‚îÄ 3. –§–∏–±–æ–Ω–∞—á—á–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            if isinstance(fibo_levels, dict):
                # —Ñ–æ—Ä–º–∞—Ç {"0.236": 108132.90, ...}
                for level_name, price_val in fibo_levels.items():
                    try:
                        price_val = float(price_val)
                    except (TypeError, ValueError):
                        continue
                    delta = (current_price - price_val) / current_price * 100
                    if abs(delta) < 0.8:  # ¬±0.8 %
                        score += 10
                        details.append(
                            f"üî¢ –§–∏–±–æ–Ω–∞—á—á–∏ {level_name}: {price_val:.6f} | "
                            f"–¶–µ–Ω–∞ {fmt_dir(delta)} –Ω–∞ {fmt_pct(delta)}"
                        )
            else:
                # —Ñ–æ—Ä–º–∞—Ç [{"symbol": ..., "timeframe": ..., "level": ..., "price": ...}, ...]
                for fl in fibo_levels or []:
                    if fl.get("symbol") != symbol or fl.get("timeframe") != timeframe:
                        continue
                    try:
                        price_val = float(fl["price"])
                    except (TypeError, ValueError, KeyError):
                        continue
                    delta = (current_price - price_val) / current_price * 100
                    if abs(delta) < 0.8:
                        score += 10
                        details.append(
                            f"üî¢ –§–∏–±–æ–Ω–∞—á—á–∏ {fl['level']}: {price_val:.6f} | "
                            f"–¶–µ–Ω–∞ {fmt_dir(delta)} –Ω–∞ {fmt_pct(delta)}"
                        )

        # ‚îÄ‚îÄ 4. RSI / MACD / EMA / Stochastic / Bollinger ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

        if rsi is not None:
            if (signal_type == "long" and rsi < 30) or (signal_type == "short" and rsi > 70):
                score += 10
                details.append(f"üéØ RSI: {rsi:.1f} (—Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª)")
            else:
                details.append(f"‚ÑπÔ∏è RSI: {rsi:.1f}")

        macd_h = indicators.get("macd_hist")
        if macd_h is not None:
            if (signal_type == "long" and macd_h > 0) or (signal_type == "short" and macd_h < 0):
                score += 8
                details.append(f"üéØ MACD –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞: {macd_h:+.6f}")
            else:
                details.append(f"‚ÑπÔ∏è MACD –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞: {macd_h:+.6f}")

            # ‚îÄ‚îÄ ATR: –¥–∞–ª—å–Ω–æ—Å—Ç—å —Å—Ç–æ–ø–∞ / —Ç–µ–π–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            atr = indicators.get("atr")
            if atr is not None:
                r_multiple = abs(current_price - price) / atr
                details.append(f"‚ÑπÔ∏è ATR: {atr:.6f}  |  {r_multiple:.1f} R –¥–æ —É—Ä–æ–≤–Ω—è")

            # ‚îÄ‚îÄ Open Interest & Funding ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            oi = indicators.get("oi")
            fnd = indicators.get("fund_rate")
            if oi is not None:
                details.append(f"‚ÑπÔ∏è Open Interest: {float(oi):,.0f}")
            if fnd is not None and abs(float(fnd)) > 0.0004:
                score += 4
                details.append(f"üí∏ Funding rate: {float(fnd):.4%}")

            # ‚îÄ‚îÄ ADX / SuperTrend  __________________________________
            adx = indicators.get("adx")
            st = indicators.get("supertrend")
            if adx is not None and adx > 25:
                score += 5
                details.append(f"‚úÖ ADX {adx:.1f} (—Å–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥)")
            if st is not None and ((st and signal_type == "long") or (not st and signal_type == "short")):
                score += 6
                details.append("‚úÖ SuperTrend –≤ —Ç—É –∂–µ —Å—Ç–æ—Ä–æ–Ω—É")

            # --- VWAP: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ü–µ–Ω–æ–π ---
            vwap = signal.get("vwap")
            price = signal.get("current_price")
            if vwap and price:
                diff = price - vwap
                pct = 100 * diff / vwap
                side = "–≤—ã—à–µ" if diff > 0 else "–Ω–∏–∂–µ"
                details.append(f"üìâ VWAP: {vwap:.6f} | –¶–µ–Ω–∞ {side} –Ω–∞ {pct:+.2f}%")

            # --- POC: point of control ---
            poc = signal.get("poc")
            if poc and price:
                diff = price - poc
                pct = 100 * diff / poc
                side = "–≤—ã—à–µ" if diff > 0 else "–Ω–∏–∂–µ"
                details.append(f"üìç POC: {poc:.6f} | –¶–µ–Ω–∞ {side} –Ω–∞ {pct:+.2f}%")


        # EMA-50 / EMA-200
        for ema_key, pts in [("ema50", 5), ("ema200", 5)]:
            ema_val = indicators.get(ema_key)
            if ema_val is None:
                continue
            delta = (current_price - ema_val) / current_price * 100
            if (signal_type == "long" and delta > 0) or (signal_type == "short" and delta < 0):
                score += pts
            details.append(
                f"‚ÑπÔ∏è {ema_key.upper()}: {ema_val:.6f} | "
                f"–¶–µ–Ω–∞ {fmt_dir(delta)} –Ω–∞ {fmt_pct(delta)}"
            )

        # Stochastic
        if indicators.get("stoch_k") is not None and indicators.get("stoch_d") is not None:
            st_k = indicators["stoch_k"]
            st_d = indicators["stoch_d"]
            if (signal_type == "long" and st_k < 20 and st_d < 20) or (
                    signal_type == "short" and st_k > 80 and st_d > 80
            ):
                score += 6
                details.append(f"üéØ Stochastic %K={st_k:.1f} %D={st_d:.1f}")
            else:
                details.append(f"‚ÑπÔ∏è Stochastic %K={st_k:.1f} %D={st_d:.1f}")

        # Bollinger Bands
        if indicators.get("bb_upper") and indicators.get("bb_lower"):
            bb_up = indicators["bb_upper"]
            bb_lo = indicators["bb_lower"]
            band_pct = (current_price - bb_lo) / (bb_up - bb_lo) * 100
            details.append(f"‚ÑπÔ∏è Bollinger Bands –ø–æ–∑–∏—Ü–∏—è: {band_pct:.1f}%")

            # ‚îÄ‚îÄ 5. –†—ã–Ω–æ—á–Ω–∞—è –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            cap_change = None
            if market_cap_data:
                if isinstance(market_cap_data, dict):
                    cap_change = market_cap_data.get("percent_change_24h")
                elif isinstance(market_cap_data, list) and market_cap_data:
                    # –±–µ—Ä—ë–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –∏–ª–∏ —Å—Ä–µ–¥–Ω–µ–µ ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤–∞—à–µ–π –ª–æ–≥–∏–∫–∏
                    first = market_cap_data[0]
                    if isinstance(first, dict):
                        cap_change = first.get("percent_change_24h")

            if cap_change is not None:
                try:
                    cap_change = float(cap_change)
                except (TypeError, ValueError):
                    cap_change = None

            if cap_change is not None and abs(cap_change) > 2:
                score += 3
                details.append(f"üí∞ –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è 24 —á: {fmt_pct(cap_change)}")

        # ‚îÄ‚îÄ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        recommendation = (
            "–°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª" if score >= 40 else
            "–£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª" if score >= 25 else
            "–°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª"
        )

        return {
            "score": score,
            "recommendation": recommendation,
            "details": details,
        }



# services/trend_engine.py

import pandas as pd
from datetime import datetime
from database.database import DatabaseManager
import logging

logger = logging.getLogger(__name__)


class TrendAnalyzer:
    def __init__(self):
        self.db = DatabaseManager()

    def analyze_trends(self):
        candles = self.db.get_all_candles()
        trends = {}

        for (symbol, tf), data in candles.items():
            if len(data) < 200:
                continue

            df = pd.DataFrame(data)
            df["close"] = pd.to_numeric(df["close"])
            ema50 = df["close"].ewm(span=50, adjust=False).mean().iloc[-1]
            ema200 = df["close"].ewm(span=200, adjust=False).mean().iloc[-1]
            direction = "bullish" if ema50 > ema200 else "bearish"

            trends[symbol] = {
                "direction": direction,
                "ema50": ema50,
                "ema200": ema200,
                "last_updated": datetime.now().timestamp()
            }

        self.db.save_trends(trends)



# services/worker.py

import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
EXCLUDED_STABLES = {"USDC", "BUSD", "TUSD", "PAX", "USDP", "DAI", "FDUSD", "EUR", "UST", "USDD", "SUSD", "USDT", "XUSD"}

from database.database import DatabaseManager
from services.signal_score import SignalScorer
from services.fibo_engine import FiboEngine
from services.signal_engine import SignalEngine

logger = logging.getLogger(__name__)


class SignalWorker:
    def __init__(self):
        self.db = DatabaseManager()
        self.scorer = SignalScorer()
        self.fibo = FiboEngine()
        self.signal_engine = SignalEngine()


    # ---------- public -----------------------------------------------------

    def process_all_pairs(self):
        logger.info("‚öôÔ∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–∞—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤")
        pairs = self.db.get_symbols_from_cache()

        pairs = [s for s in pairs if not any(stable in s for stable in EXCLUDED_STABLES)]
        timeframes = ["1d", "4h", "1h", "15m"]
        tasks = [(symbol, tf) for symbol in pairs for tf in timeframes]

        results = []

        trend_cache = {t["symbol"]: t for t in self.db.get_all_trends()}
        levels_cache = self.db.get_levels()
        market_cap_data = self.db.get_market_cap()

        with ThreadPoolExecutor(max_workers=20) as executor:
            futures = {
                executor.submit(
                    self.analyze_pair,
                    symbol,
                    tf,
                    trend_cache,
                    levels_cache,
                    market_cap_data,
                ): (symbol, tf)
                for symbol, tf in tasks
            }

            for future in as_completed(futures):
                result = future.result()
                if result:
                    results.append(result)

        # —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫
        flat_results = [
            item
            for sub in results
            if isinstance(sub, list)
            for item in sub
            if isinstance(item, dict)
            and {"symbol", "timeframe", "signal_type"} <= item.keys()
        ]

        if flat_results:
            self.db.save_signals(flat_results)
            logger.info(f"‚úÖ –°–∏–≥–Ω–∞–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –±–∞–∑—É: {len(flat_results)}")
        else:
            logger.info("üì≠ –ù–µ—Ç —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")

        return flat_results

    # ---------- private ----------------------------------------------------

    def analyze_pair(
        self,
        symbol: str,
        timeframe: str,
        trend_cache: dict,
        levels_cache: list,
        market_cap_data: dict,
    ):
        start = time.time()

        # ‚îÄ‚îÄ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        raw = self.db.get_indicators(symbol, timeframe)

        def _as_float(val):
            """–í–µ—Ä–Ω—ë—Ç float, –µ—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ —á–∏—Å–ª–æ; –∏–Ω–∞—á–µ None."""
            if val in (None, ""):
                return None
            try:
                return float(val)
            except (ValueError, TypeError):
                return None

        indicators = {k.lower(): _as_float(v) for k, v in raw.items()}

        try:
            candles = self.db.get_candles(symbol, timeframe)
            if not candles or len(candles) < 30:
                return None

            current_price = candles[-1]["close"]
            trend_data = trend_cache.get(symbol, {})
            levels = [
                lvl
                for lvl in levels_cache
                if lvl["symbol"] == symbol and lvl["timeframe"] == timeframe
            ]
            fibo = self.fibo.calculate_for_pair(symbol, timeframe)

            results = []

            # --- PATCH BEGIN -----------------------------------------------------------
            # —Å–æ–±–µ—Ä—ë–º –æ–±—â–∏–µ –¥–ª—è –ª—é–±–æ–≥–æ —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞ –¥–∞–Ω–Ω—ã–µ
            base_payload = {
                "SYMBOL": symbol,  # <= –æ—Å—Ç–∞–≤—å—Ç–µ –∫–∞–∫ –Ω—É–∂–Ω–æ –ë–î
                "TIMEFRAME": timeframe,
                "PRICE": current_price,
                "CURRENT_PRICE": current_price,

                # –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ‚Äì  –≤ —Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ, –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ signals
                "RSI": indicators.get("rsi"),
                "MACD": indicators.get("macd_hist"),
                "STOCH_K": indicators.get("stoch_k"),
                "STOCH_D": indicators.get("stoch_d"),
                "ATR": indicators.get("atr"),
                "ADX": indicators.get("adx"),
                "OI": indicators.get("oi"),
                "FUND_RATE": indicators.get("fund_rate"),
                "SUPERTREND": indicators.get("supertrend"),
                "VWAP": indicators.get("vwap"),
                "POC": indicators.get("vpvr_poc"),
            }
            for signal_type in ("long", "short"):
                signal = {
                    "symbol": symbol,
                    "timeframe": timeframe,
                    "signal_type": signal_type,
                    "price": current_price,
                    "current_price": current_price,
                }

                result = self.scorer.evaluate(
                    trend_data,
                    levels,
                    indicators,
                    fibo["fibo_levels"] if fibo else {},
                    market_cap_data,
                    signal,
                )

                if result and result["score"] >= 30:
                    # üëâ –ø—Ä–∏–≤–æ–¥–∏–º details –∫ —Å—Ç—Ä–æ–∫–µ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ —Å—Ç—Ä–æ–∫
                    if isinstance(result["details"], (list, set, tuple)):
                        result["details"] = "\n".join(result["details"])

                    # –º—ë—Ä–¥–∂–∏–º payload ‚Üí –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤ –ë–î —É–π–¥—É—Ç –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏
                    result |= base_payload | {"SIGNAL_TYPE": signal_type}

                    results.append(result)

            return results if results else None

        finally:
            duration = time.time() - start
            logger.debug(f"‚è± {symbol} {timeframe} –∞–Ω–∞–ª–∏–∑ –∑–∞ {duration:.2f} —Å–µ–∫")



